<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Johnny-Zhao&#39;s TechBlog</title>
  
  <subtitle>KEEP FIGHTING</subtitle>
  <link href="https://zjncs.github.io/atom.xml" rel="self"/>
  
  <link href="https://zjncs.github.io/"/>
  <updated>2025-08-18T07:22:03.764Z</updated>
  <id>https://zjncs.github.io/</id>
  
  <author>
    <name>Johnny-Zhao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>llm神经网络深度学习</title>
    <link href="https://zjncs.github.io/2025/08/18/llm%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>https://zjncs.github.io/2025/08/18/llm%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-08-18T07:21:41.000Z</published>
    <updated>2025-08-18T07:22:03.764Z</updated>
    
    <content type="html"><![CDATA[<p><strong>下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这个自由层的节点数呢？目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。这种方法又叫做 Grid Search（网格搜索）。</strong></p><p>**　　了解了两层神经网络的结构以后，我们就可以看懂其它类似的结构图。例如 EasyPR 字符识别网络架构（下图）。**<img src="https://i-blog.csdnimg.cn/blog_migrate/1d3e42d157b2d6714982495a97feb882.png" alt="img"></p><p><strong>下面简单介绍一下两层神经网络的训练。</strong></p><p>**　　在 Rosenblat 提出的感知器模型中，模型中的参数可以被训练，但是使用的方法较为简单，并没有使用目前机器学习中通用的方法，这导致其扩展性与适用性非常有限。从两层神经网络开始，神经网络的研究人员开始使用机器学习相关的技术进行神经网络的训练。例如用大量的数据（1000-10000 左右），使用算法进行优化等等，从而使得模型训练可以获得性能与数据利用上的双重优势。**</p><p>**　　机器学习模型训练的目的，就是使得参数尽可能的与真实的模型逼近。具体做法是这样的。首先给所有参数赋上随机值。我们使用这些随机生成的参数值，来预测训练数据中的样本。样本的预测目标为 yp，真实目标为 y。那么，定义一个值 loss，计算公式如下。**</p><p><strong>loss &#x3D; (yp - y)2</strong></p><p>**　　这个值称之为**<strong>损失</strong>（loss），我们的目标就是使对所有训练数据的损失和尽可能的小。</p><p><strong>如果将先前的神经网络预测的矩阵公式带入到 yp 中（因为有 z&#x3D;yp），那么我们可以把损失写为关于参数（parameter）的函数，这个函数称之为****损失函数</strong>（loss function）。下面的问题就是求：如何优化参数，能够让损失函数的值最小。</p><p>**　　此时这个问题就被转化为一个优化问题。一个常用方法就是高等数学中的求导，但是这里的问题由于参数不止一个，求导后计算导数等于 0 的运算量很大，所以一般来说解决这个优化问题使用的是**<strong>梯度下降</strong>算法。</p><p>**梯度下降就是顺着函数 **<strong>下降最快的方向</strong>（即梯度的反方向）一步步走，直到找到函数的最低点（局部最小值或全局最小值）。</p><hr><h3 id="二、基本思想"><a href="#二、基本思想" class="headerlink" title="二、基本思想"></a>二、基本思想</h3><p><strong>假设有一个损失函数 J(θ)J(\theta)J(θ)，其中 θ\thetaθ 表示模型的参数。</strong> ** 我们想要找到使损失函数最小的参数 θ\thetaθ。**</p><p><strong>迭代公式为：</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818143508053.png" alt="image-20250818143508053"></p><p>**意思就是：**<strong>更新参数 θ 为 旧的 θ 减去学习率乘以梯度</strong>。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818143717968.png" alt="image-20250818143717968"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818143819978.png" alt="image-20250818143819978"></p><p><strong>梯度下降算法每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。</strong></p><p><strong>在神经网络模型中，由于结构复杂，每次计算梯度的代价很大。因此还需要使用****反向传播</strong>算法。反向传播算法是利用了神经网络的结构进行的计算。不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。</p><p>**　　反向传播算法可以直观的理解为下图。梯度的计算从后往前，一层层反向传播。前缀 E 代表着相对导数的意思。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/1b3510e880dd4843ae54ca80ff0adb0a.png" alt="img"></p><p><strong>反向传播（Backpropagation, BP）算法</strong></p><p><strong>在神经网络里高效计算梯度的方法</strong>。** ** 可以说：</p><ul><li><strong>梯度下降</strong> 是“怎么走路” → 不断沿着梯度的反方向更新参数。</li><li><strong>反向传播</strong> 是“怎么找到路” → 在复杂的神经网络里快速算出梯度。</li></ul><p><strong>在神经网络里，参数非常多（权重 www、偏置 bbb）。</strong> ** 我们需要知道每个参数对 <strong><strong>损失函数</strong> 的影响（即梯度），才能用梯度下降更新参数。</strong> ** 反向传播就是用 <strong>链式法则</strong> 把误差从输出层一步步传回输入层，计算所有参数的梯度。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818144205043.png" alt="image-20250818144205043"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818144253384.png" alt="image-20250818144253384"></p><p><strong>反向传播算法的启示是数学中的****链式法则</strong>。在此需要说明的是，尽管早期神经网络的研究人员努力从生物学中得到启发，但从 BP 算法开始，研究者们更多地从数学上寻求问题的最优解。不再盲目模拟人脑网络是神经网络研究走向成熟的标志。正如科学家们可以从鸟类的飞行中得到启发，但没有必要一定要完全模拟鸟类的飞行方式，也能制造可以飞天的飞机。</p><p>**　　优化问题只是训练中的一个部分。机器学习问题之所以称为学习问题，而不是优化问题，就是因为它不仅要求数据在训练集上求得一个较小的误差，在测试集上也要表现好。**</p><p><strong>因为模型最终是要部署到没有见过训练数据的真实场景。提升模型在测试集上的预测效果的主题叫做****泛化</strong>（generalization），相关方法被称作正则化（regularization）。神经网络中常用的泛化技术有<strong>权重衰减</strong>等。</p><h2 id="泛化（Generalization）"><a href="#泛化（Generalization）" class="headerlink" title="泛化（Generalization）"></a>泛化（Generalization）</h2><ul><li><strong>问题背景</strong>：我们训练模型的时候，模型是接触到训练数据的。但模型最终要应用在“没见过的新数据”上，比如测试集或真实环境的数据。</li><li><strong>泛化能力</strong>：指模型在新数据上的预测效果。如果一个模型在训练集上表现很好，但在测试集上表现很差，就说明 <strong>泛化能力差（过拟合）</strong>。</li></ul><p><strong>👉 所以目标是：不仅要在训练集上学得好，还要在测试集、真实环境中表现好。</strong></p><h2 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h2><ul><li><strong>概念</strong>：正则化就是一类方法，用来提升模型的泛化能力，避免过拟合。</li><li><strong>为什么过拟合</strong>：当神经网络参数太多时，它可能会“死记硬背”训练数据，而不是学到真正有用的规律。</li><li><strong>正则化的作用</strong>：通过“限制模型的复杂度”或“增加训练时的约束”，让模型学到更稳定的规律，而不是死记硬背。</li></ul><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818144807879.png" alt="image-20250818144807879"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818145158283.png" alt="image-20250818145158283"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818145229147.png" alt="image-20250818145229147"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818145248395.png" alt="image-20250818145248395"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818151116266.png" alt="image-20250818151116266"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818151133957.png" alt="image-20250818151133957"></p><p><strong>在被人摒弃的 10 年中，有几个学者仍然在坚持研究。这其中的棋手就是加拿大多伦多大学的 Geoffery Hinton 教授。</strong></p><p>**　　2006 年，Hinton 在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念。与传统的训练方式不同，“深度信念网络”有一个“**<strong>预训练</strong>”（pre-training）的过程，这可以方便的让神经网络中的权值找到一个接近最优解的值，之后再使用“<strong>微调</strong>”(fine-tuning)技术来对整个网络进行优化训练。这两个技术的运用大幅度减少了训练多层神经网络的时间。他给多层神经网络相关的学习方法赋予了一个新名词–“<strong>深度学习</strong>”。</p><p>** 　很快，深度学习在语音识别领域暂露头角。接着，2012 年，深度学习技术又在图像识别领域大展拳脚。Hinton 与他的学生在 ImageNet 竞赛中，用多层的卷积神经网络成功地对包含一千类别的一百万张图片进行了训练，取得了分类错误率 15% 的好成绩，这个成绩比第二名高了近 11 个百分点，充分证明了多层神经网络识别效果的优越性。**</p><p>**　　在这之后，关于深度神经网络的研究与应用不断涌现。**</p><p><strong>我们延续两层神经网络的方式来设计一个多层神经网络。</strong></p><p>**　　在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/446beb41a6c3180cbac3b9907e1d00b2.png" alt="img"></p><p><strong>多层神经网络中，输出也是按照一层一层的方式来计算。从最外面的层开始，算出所有单元的值以后，再继续计算更深一层。只有当前层所有单元的值都计算完毕以后，才会算下一层。有点像计算向前不断推进的感觉。所以这个过程叫做“正向传播”。</strong></p><p>**　　下面讨论一下多层神经网络中的参数。**</p><p>**　　首先我们看第一张图，可以看出**<strong>W</strong>(1)中有 6 个参数，<strong>W</strong>(2)中有 4 个参数，<strong>W</strong>(3)中有 6 个参数，所以整个神经网络中的参数有 16 个（这里我们不考虑偏置节点，下同）。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/5b22532fd29fc20b299488fa55e22890.png" alt="img"></p><p><strong>假设我们将中间层的节点数做一下调整。第一个中间层改为 3 个单元，第二个中间层改为 4 个单元。</strong></p><p>**　　经过调整以后，整个网络的参数变成了 33 个。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/66c2a2d5e23e80feed37dd9ae11bc2dd.png" alt="img"></p><p><strong>虽然层数保持不变，但是第二个神经网络的参数数量却是第一个神经网络的接近两倍之多，从而带来了更好的表示（represention）能力。表示能力是多层神经网络的一个重要性质，下面会做介绍。</strong></p><p>**　　在参数一致的情况下，我们也可以获得一个“更深”的网络。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/24a14120a978e9a49ce2b0a9de6ba895.png" alt="img"></p><p><strong>图 33 多层神经网络（更深的层次）</strong></p><hr><p>**　　上图的网络中，虽然参数数量仍然是 33，但却有 4 个中间层，是原来层数的接近两倍。这意味着一样的参数数量，可以用更深的层次去表达。**</p><p>**　　**<strong>3.效果</strong></p><p>**　　与两层层神经网络不同。多层神经网络中的层数增加了很多。**</p><p>**　　增加更多的层次有什么好处？更深入的表示特征，以及更强的函数模拟能力。**</p><p>**　　更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。**</p><p>**　　关于逐层特征学习的例子，可以参考下图。**<img src="https://i-blog.csdnimg.cn/blog_migrate/f10bcb5f682714d1b388506514784550.png" alt="img"></p><p><strong>在单层神经网络时，我们使用的激活函数是 sgn 函数。到了两层神经网络时，我们使用的最多的是 sigmoid 函数。而到了多层神经网络时，通过一系列的研究发现，ReLU 函数在训练多层神经网络时，更容易收敛，并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是 ReLU 函数。ReLU 函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是 y&#x3D;max(x,0)。简而言之，在 x 大于 0，输出就是输入，而在 x 小于 0 时，输出就保持为 0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。</strong></p><p>**　　在多层神经网络中，训练的主题仍然是优化和泛化。当使用足够强的计算芯片（例如 GPU 图形加速卡）时，梯度下降算法以及反向传播算法在多层神经网络中的训练中仍然工作的很好。目前学术界主要的研究既在于开发新的算法，也在于对这两个算法进行不断的优化，例如，增加了一种带动量因子（momentum）的梯度下降算法。　**</p><p>**　　在深度学习中，泛化技术变的比以往更加的重要。这主要是因为神经网络的层数增加了，参数也增加了，表示能力大幅度增强，很容易出现**<strong>过拟合现象</strong>。因此正则化技术就显得十分重要。目前，Dropout 技术，以及数据扩容（Data-Augmentation）技术是目前使用的最多的正则化技术。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
    <category term="论文" scheme="https://zjncs.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>llm-神经网络</title>
    <link href="https://zjncs.github.io/2025/08/14/llm-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://zjncs.github.io/2025/08/14/llm-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2025-08-14T05:47:33.000Z</published>
    <updated>2025-08-14T05:47:42.853Z</updated>
    
    <content type="html"><![CDATA[<p><strong>由于实习等一系列事情，leetcode 更新暂时延缓，只保留每日刷一道题，知识点学习暂且搁置</strong></p><p><strong>下面是 llm 前置知识，在这部分结束后，我将更新经典论文阅读。</strong></p><p><strong>神经网络：</strong></p><p><strong>让我们来看一个经典的神经网络。这是一个包含三个层次的神经网络。红色的是****输入层</strong>，绿色的是<strong>输出层</strong>，紫色的是<strong>中间层</strong>（也叫<strong>隐藏层</strong>）。输入层有 3 个输入单元，隐藏层有 4 个单元，输出层有 2 个单元。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/ec01486fd81a42733d3acef52a95c907.png" alt="img"></p><p><strong>在开始介绍前，有一些知识可以先记在心里：</strong></p><ol><li><strong>设计一个神经网络时，输入层与输出层的节点数往往是固定的，中间层则可以自由指定；</strong></li><li><strong>神经网络结构图中的拓扑与箭头代表着****预测</strong>过程时数据的流向，跟<strong>训练</strong>时的数据流有一定的区别；</li><li><strong>结构图里的关键不是圆圈（代表“神经元”），而是连接线（代表“神经元”之间的连接）。每个连接线对应一个不同的****权重</strong>（其值称为<strong>权值</strong>），这是需要训练得到的。</li></ol><p><strong>除了从左到右的形式表达的结构图，还有一种常见的表达形式是从下到上来表示一个神经网络。这时候，输入层在图的最下方。输出层则在图的最上方，如下图：</strong></p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/b65bc032792c3cc4e8949dc2b066ac93.png" alt="img"></p><p><strong>神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。</strong></p><p>**　　下图是一个典型的神经元模型：包含有 3 个输入，1 个输出，以及 2 个计算功能。**</p><p>**　　注意中间的箭头线。这些线称为“连接”。每个上有一个“权值”。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/75b9760fdd6dc27daf143454b9749fd1.png" alt="img"></p><p>**图 6 神经元模型 **</p><p>**　　连接是神经元中最重要的东西。每一个连接上都有一个权重。**</p><p>**　　一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。**</p><p>**　　我们使用 a 来表示输入，用 w 来表示权值。一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是 a，端中间有加权参数 w，经过这个加权后的信号会变成 a***<strong>w，因此在连接的末端，信号的大小就变成了 a*w。</strong></p><p><strong>如果我们将神经元图中的所有变量用符号表示，并且写出输出的计算公式的话，就是下图。</strong></p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/5edde0590ebecbb366852259ce371054.png" alt="img"></p><p><strong>可见 z 是在输入和权值的线性加权和叠加了一个****函数 g</strong> 的值。在 MP 模型里，函数 g 是 sgn 函数，也就是取符号函数。这个函数当输入大于 0 时，输出 1，否则输出 0。</p><p><strong>下面对神经元模型的图进行一些扩展。首先将 sum 函数与 sgn 函数合并到一个圆圈里，代表神经元的内部计算。其次，把输入 a 与输出 z 写到连接线的左上方，便于后面画复杂的网络。最后说明，一个神经元可以引出多个代表输出的有向箭头，但值都是一样的。</strong></p><p>**　　神经元可以看作一个计算与存储单元。计算是神经元对其的输入进行计算功能。存储是神经元会暂存计算结果，并传递到下一层。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/1159ca7927d03a090e353bf2377deb02.png" alt="img"></p><p>**图 9 神经元扩展 **</p><p><strong>神经元模型的使用可以这样理解：</strong></p><p>**　　我们有一个数据，称之为样本。样本有四个属性，其中三个属性已知，一个属性未知。我们需要做的就是通过三个已知属性**<strong>预测</strong>未知属性。</p><p>**　　具体办法就是使用神经元的公式进行计算。三个已知属性的值是 a1，a2，a3，未知属性的值是 z。z 可以通过公式计算出来。**</p><p>**　　这里，已知的属性称之为<strong><strong>特征</strong>，未知的属性称之为**目标</strong>。假设特征与目标之间确实是线性关系，并且我们已经得到表示这个关系的权值 w1，w2，w3。那么，我们就可以通过神经元模型预测新样本的目标。</p><p><strong>这里虽然简单，但已经建立了神经网络大厦的地基。但是，MP 模型中，权重的值都是预先设置的，因此不能学习。</strong></p><p><strong>单层神经网络（感知机）</strong></p><p>**　在原来 MP 模型的“输入”位置添加神经元节点，标志其为“输入单元”。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/938b7c669240a4250c46f46cde645aab.png" alt="img"></p><p><strong>在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。</strong></p><p><strong>我们把需要计算的层次称之为“计算层”，并把拥有一个计算层的网络称之为“单层神经网络”。我们根据计算层的数量来命名。</strong></p><p><strong>因此感知机是单层神经网络。</strong></p><p><strong>假如我们要预测的目标不再是一个值，而是一个向量，例如[2,3]。那么可以在输出层再增加一个“输出单元”。</strong></p><p>**　　下图显示了带有两个输出单元的单层神经网络，其中输出单元 z1 的计算公式如下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/53c8c4855619cd0dc1515864c7eb00fe.png" alt="img"></p><p><strong>图 13 单层神经网络(Z1)</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814110911355.png" alt="image-20250814110911355"></p><p><strong>可以看到，z2 的计算中除了三个新的权值：w4，w5，w6 以外，其他与 z1 是一样的。</strong></p><p>**　　整个网络的输出如下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/24e9956cc367ed4e8d21d8d39394ec2a.png" alt="img"></p><p><strong>图 15 单层神经网络(Z1 和 Z2)</strong></p><p>**　　目前的表达公式有一点不让人满意的就是：w4，w5，w6 是后来加的，很难表现出跟原先的 w1，w2，w3 的关系。**</p><p><strong>目前的表达公式有一点不让人满意的就是：w4，w5，w6 是后来加的，很难表现出跟原先的 w1，w2，w3 的关系。</strong></p><p>**　　因此我们改用二维的下标，用 wx,y 来表达一个权值。下标中的 x 代表后一层神经元的序号，而 y 代表前一层神经元的序号（序号的顺序从上到下）。**</p><p>**　　例如，w1,2 代表后一层的第 1 个神经元与前一层的第 2 个神经元的连接的权值（这种标记方式参照了 Andrew Ng 的课件）。根据以上方法标记，我们有了下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/8d37f29e30331a1367b9c4156f9ba1a9.png" alt="img"></p><p><strong>图 16 单层神经网络(扩展)</strong></p><p>** 如果我们仔细看输出的计算公式，会发现这两个公式就是线性代数方程组。因此可以用矩阵乘法来表达这两个公式。**</p><p>**　　例如，输入的变量是[a1，a2，a3]T（代表由 a1，a2，a3 组成的列向量），用向量**<strong>a</strong> 来表示。方程的左边是[z1，z2]T，用向量 <strong>z</strong> 来表示。</p><p>**　　系数则是矩阵**<strong>W</strong>（2 行 3 列的矩阵，排列形式与公式中的一样）。</p><p>**　　于是，输出公式可以改写成：**</p><p>****g(<strong>W</strong> * <strong>a</strong>) &#x3D; <strong>z</strong>;</p><p>**　　这个公式就是神经网络中从前一层计算后一层的**<strong>矩阵运算。</strong></p><p><strong>3.效果</strong></p><p>**　　与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个**<strong>逻辑回归</strong>模型，可以做线性分类任务。</p><p>**　　我们可以用**<strong>决策分界</strong>来形象的表达分类的效果。决策分界就是在二维的数据平面中划出一条直线，当数据的维度是 3 维的时候，就是划出一个平面，当数据的维度是 n 维时，就是划出一个 n-1 维的超平面。</p><p>**　　下图显示了在二维平面中划出决策分界的效果，也就是感知器的分类效果。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/d8ac48846e6e18911b3a9869d7be5301.png" alt="img"></p><p><strong>图 17 单层神经网络（决策分界）</strong></p><p><strong>权值 w 并不是事先人为设定好的，而是模型****根据数据自动学出来的参数</strong>，就像学生通过做题不断修正自己的解题方法。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814111819961.png" alt="image-20250814111819961"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814111834727.png" alt="image-20250814111834727"></p><p><strong>偏置就是一个额外的权重，对应输入恒为 1，用来调整神经元的输出基准，让模型的决策边界更灵活。</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814112554503.png" alt="image-20250814112554503"></p><p><strong>感知器能做的事情：</strong></p><ul><li><strong>它可以把空间分成两部分。</strong></li><li><strong>所以它只能处理****线性可分</strong>问题（比如 AND、OR）。</li></ul><p><strong>XOR 不满足线性可分条件，因此单层感知器无法找到一组权重 w 和偏置 b 使得输出完全正确。</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814113057424.png" alt="image-20250814113057424"></p><p><strong>四. 两层神经网络（多层感知器）</strong></p><p>**　　**<strong>1.引子</strong></p><p>**　　两层神经网络是本文的重点，因为正是在这时候，神经网络开始了大范围的推广与使用。**</p><p>**　　Minsky 说过单层神经网络无法解决异或问题。但是当增加一个计算层以后，两层神经网络不仅可以解决异或问题，而且具有非常好的非线性分类效果。不过两层神经网络的计算是一个问题，没有一个较好的解法。**</p><p>**　　1986 年，Rumelhar 和 Hinton 等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。目前，大量的教授神经网络的教材，都是重点介绍两层（带一个隐藏层）神经网络的内容。 **</p><p>**　　这时候的 Hinton 还很年轻，30 年以后，正是他重新定义了神经网络，带来了神经网络复苏的又一春。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/bd5d018f58f101c7b8341a0bc996cc1c.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814113925679.png" alt="image-20250814113925679"></p><p>**　计算最终输出 z 的方式是利用了中间层的 a1(2)，a2(2)和第二个权值矩阵计算得到的，如下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/ff6b58c6dc41f9f439a8ceaa9393757c.png" alt="img"></p><p><strong>图 21 两层神经网络（输出层计算）</strong></p><p>**　　假设我们的预测目标是一个向量，那么与前面类似，只需要在“输出层”再增加节点即可。**</p><p>**　　我们使用向量和矩阵来表示层次中的变量。**<strong>a</strong>(1)，<strong>a</strong>(2)，<strong>z</strong> 是网络中传输的向量数据。<strong>W</strong>(1)和 <strong>W</strong>(2)是网络的矩阵参数。如下图。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/7b83ef7d2f2eeb3be332a0f60bc1509c.png" alt="img"></p><p><strong>图 22 两层神经网络（向量形式）</strong></p><p>**　　使用矩阵运算来表达整个计算公式的话如下：**</p><p>** g(**<strong>W</strong>(1) * <strong>a</strong>(1)) &#x3D; <strong>a</strong>(2);</p><p>**g(**<strong>W</strong>(2) * <strong>a</strong>(2)) &#x3D; <strong>z</strong>;</p><p>** 需要说明的是，至今为止，我们对神经网络的结构图的讨论中都没有提到偏置节点（bias unit）。事实上，这些节点是默认存在的。它本质上是一个只含有存储功能，且存储值永远为 1 的单元。在神经网络的每个层次中，除了输出层以外，都会含有这样一个偏置单元。正如线性回归模型与逻辑回归模型中的一样。**</p><p>**　　偏置单元与后一层的所有节点都有连接，我们设这些参数值为向量**<strong>b</strong>，称之为偏置。如下图。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/c2c8420cff26253a2a0ff71ed9b9ab2c.png" alt="img"></p><p><strong>图 23 两层神经网络（考虑偏置节点）</strong></p><hr><p>**　　可以看出，偏置节点很好认，因为其没有输入（前一层中没有箭头指向它）。有些神经网络的结构图中会把偏置节点明显画出来，有些不会。一般情况下，我们都不会明确画出偏置节点。 **</p><p>**　　在考虑了偏置以后的一个神经网络的矩阵运算如下：**</p><p>** g(**<strong>W</strong>(1) * <strong>a</strong>(1) + <strong>b</strong>(1)) &#x3D; <strong>a</strong>(2);</p><p>**g(**<strong>W</strong>(2) * <strong>a</strong>(2) + <strong>b</strong>(2)) &#x3D; <strong>z</strong>;</p><hr><p>**　　需要说明的是，在两层神经网络中，我们不再使用 sgn 函数作为函数 g，而是使用平滑函数 sigmoid 作为函数 g。我们把函数 g 也称作激活函数（active function）。**</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814131412701.png" alt="image-20250814131412701"></p><p><strong>3.效果</strong></p><p>**　　与单层神经网络不同。理论证明，两层神经网络可以无限逼近任意连续函数。**</p><p>**　　这是什么意思呢？也就是说，面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。**</p><p>**　　下面就是一个例子（此两图来自 colah 的**<a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">博客</a>），红色的线与蓝色的线代表数据。而红色区域和蓝色区域代表由神经网络划开的区域，两者的分界线就是决策分界。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/05fc87cd4485eb8a9291a26812596766.png" alt="img"></p><p><strong>图 24 两层神经网络（决策分界）</strong></p><p>**　　**</p><p>**　　可以看到，这个两层神经网络的决策分界是非常平滑的曲线，而且分类的很好。有趣的是，前面已经学到过，单层网络只能做线性分类任务。而两层神经网络中的后一层也是线性分类层，应该只能做线性分类任务。为什么两个线性分类任务结合就可以做非线性分类任务？**</p><p>**　　我们可以把输出层的决策分界单独拿出来看一下。就是下图。**</p><h3 id="第二步：隐藏层的“魔术”——-空间变换-Spatial-Transformation"><a href="#第二步：隐藏层的“魔术”——-空间变换-Spatial-Transformation" class="headerlink" title="第二步：隐藏层的“魔术”—— 空间变换 (Spatial Transformation)"></a>第二步：隐藏层的“魔术”—— 空间变换 (Spatial Transformation)</h3><p><strong>现在，我们在输入层和输出层之间加入一个“隐藏层”，就构成了两层神经网络。这个隐藏层究竟做了什么？</strong></p><p><strong>它对原始数据的坐标空间进行了一次非线性变换。</strong></p><p><strong>这个变换可以想象成将原始的坐标纸（特征空间）进行“拉伸”、“弯曲”、“折叠”，使得原本挤在一起、无法用直线分开的数据点，在一个新的坐标系下，变得可以用直线轻易分开了。</strong></p><p><strong>这个变换具体是通过两个操作完成的：</strong></p><ol><li><strong>线性计算</strong>：输入数据与隐藏层的权重矩阵 (W) 进行矩阵乘法，再加上偏置 (b)。这本质上是对坐标空间进行旋转、缩放、平移等线性变换。</li><li><strong>非线性激活</strong>：对上一步的线性计算结果，施加一个<strong>非线性激活函数</strong>（如 Sigmoid, ReLU, Tanh 等）。<strong>这是实现非线性变换的关键！</strong> 如果没有这个非线性激活函数，那么无论多少个隐藏层叠加，最终都等价于一个单层的线性模型，无法学习到非线性的关系。</li></ol><p><img src="https://i-blog.csdnimg.cn/blog_migrate/c2a4059fd628588ad7f2a5d4aa60758b.png" alt="img"></p><p><strong>图中的灰色网格线，实际上就是原始空间中标准的直线网格（比如 x&#x3D;0.1, 0.2… 和 y&#x3D;0.1, 0.2…）经过隐藏层****变换后</strong>的样子。您可以看到，原本笔直的网格线被“掰弯”了。这直观地展示了空间本身被扭曲了。</p><p><strong>可以看到，输出层的决策分界仍然是直线。关键就是，从输入层到隐藏层时，数据发生了空间变换。也就是说，两层神经网络中，隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;由于实习等一系列事情，leetcode 更新暂时延缓，只保留每日刷一道题，知识点学习暂且搁置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面是 llm 前置知识，在这部分结束后，我将更新经典论文阅读。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>芯片验证（一）</title>
    <link href="https://zjncs.github.io/2025/08/14/%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://zjncs.github.io/2025/08/14/%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2025-08-14T02:10:06.000Z</published>
    <updated>2025-08-14T02:10:38.777Z</updated>
    
    <content type="html"><![CDATA[<p><strong>芯片验证是确保芯片设计正确性的关键环节。随着芯片复杂度的不断提升，验证工作在整个设计流程中所占比重越来越大，已成为芯片成功与否的决定性因素。这一讲我们将从基础概念入手，系统介绍验证的重要性、基本流程与方法、验证层次和评估指标，探讨实际项目流程中可能遇到的挑战与敏捷验证的应对思路，分析当前验证领域面临的困境以及使用高级语言进行验证的价值，并展望芯片验证众包这一未来解决方案。</strong></p><p><strong>接下来，你将了解：</strong></p><ul><li><strong>芯片验证的基本概念</strong>：什么是芯片验证，为什么它对芯片设计至关重要，以及验证不足可能导致的严重后果。</li><li><strong>验证流程与敏捷方法</strong>：完整的验证流程是如何开展的，敏捷验证的原则与实践，以及从计划到报告的完整验证步骤。</li><li><strong>验证层次体系</strong>：从单元测试到系统测试的不同验证层次及其特点。</li><li><strong>验证质量评估</strong>：如何通过功能正确性、代码&#x2F;功能覆盖率、缺陷密度等关键指标来评估验证质量。</li><li><strong>当前验证挑战与高级语言价值</strong>：验证面临的工作量、成本、人才等挑战，以及使用高级语言（如 Python）的优势及其对验证的推动作用。</li><li><strong>芯片验证众包前景</strong>：作为应对挑战的创新方案，众包验证的可行性、技术路线，以及 Picker 等工具在其中的作用。</li></ul><h2 id="芯片验证的定义"><a href="#芯片验证的定义" class="headerlink" title="芯片验证的定义"></a>芯片验证的定义</h2><p><strong>芯片验证是芯片开发流程中的关键环节，它的目标是确保设计的芯片在功能、性能和功耗等方面都满足预定的规范要求。</strong></p><p><strong>在本课程中，我们主要关注的是****功能验证</strong>，也就是验证设计的电路逻辑是否满足既定需求，回答的核心问题是：<strong>“这个设计真的能按照预期工作吗？”</strong></p><p><strong>芯片验证并不等同于芯片测试。验证发生在设计阶段，通过各种方法（如仿真）在芯片制造前发现问题；而测试则是在芯片制造后，通过物理手段检查实际芯片是否工作正常。</strong></p><p><strong>想象一下，如果你的手机突然无法计算，或者自动驾驶汽车的导航系统出现了错误，这将是多么可怕的事情！芯片验证正是为了防止这些问题发生。</strong></p><p><strong>一旦芯片被制造出来，修改错误的成本将会非常高昂。以下是几个验证不足导致灾难性后果的经典案例：</strong></p><ul><li><strong>Intel Pentium FDIV Bug （1994）</strong>: 浮点单元的一个计算错误导致 Intel 不得不召回大量处理器，造成约 4.75 亿美元的损失。</li><li><strong>AMD Barcelona Bug （2007）</strong>: TLB 错误导致系统不稳定，AMD 不得不降低处理器频率并推迟产品发布。</li><li><strong>Intel Sandy Bridge 芯片组缺陷（2011）</strong>：缺陷源于芯片组电路设计中的问题，SATA 端口可能在某些情况下退化，影响设备性能。根据<a href="https://www.cnet.com/science/intels-sandy-bridge-chipset-flaw-the-fallout/"> CNET - Intel’s Sandy Bridge chipset flaw: The fallout</a>，Intel 预计 2011 年第一季度损失约 3 亿美元的销售收入，并支付 7 亿美元的维修和更换费用，总计约 10 亿美元的损失。</li></ul><h1 id="3-验证流程与敏捷方法"><a href="#3-验证流程与敏捷方法" class="headerlink" title="3. 验证流程与敏捷方法"></a>3. 验证流程与敏捷方法</h1><h2 id="验证与设计的关系"><a href="#验证与设计的关系" class="headerlink" title="验证与设计的关系"></a>验证与设计的关系</h2><p><strong>芯片验证并不是设计完成后的一个简单检查步骤，而是与设计过程并行进行的关键活动。</strong></p><p><strong>设计团队和验证团队通常从同一份规范出发，但有着不同的实现方式和关注点：</strong></p><ul><li><strong>设计团队</strong>：开发 DUT，关注功能实现、代码的可综合性和电路效率。<br><strong>DUT（Design Under Test）是****待测设备</strong> ，通常是一个模块或子系统。</li><li><strong>验证团队</strong>：开发验证平台，专注于验证功能的正确实现。</li></ul><p><strong>这种设计与验证的分离确保了两个团队能够独立理解规范，从而提高发现潜在错误的概率。</strong></p><p><img src="https://open-verify.cc/beginner/course/1-basis/assets/flow.png" alt="img"></p><h2 id="完整的验证流程"><a href="#完整的验证流程" class="headerlink" title="完整的验证流程"></a>完整的验证流程</h2><p><strong>芯片验证是一个系统工程，确保设计按预期工作。其主要流程概括如下：</strong></p><ol><li><strong>制定验证计划：此阶段是验证工作的起点，旨在明确“验证什么”和“如何验证”。主要任务是定义验证的总体范围、目标、采用的验证方法、所需资源、整理功能点等。</strong></li><li><strong>搭建验证平台：根据验证计划，此阶段专注于构建用于执行测试的验证环境，包含测试输入产生、信号收集和结果检查等组件。平台搭建的初步成功通常以通过基本的“冒烟测试”为标志，证明环境主要功能通路工作正常。</strong></li><li><strong>编写测试用例：在验证平台基础上，此阶段的核心是依据验证计划，编写实现具体的测试用例，用以全面覆盖预定的功能点、边界条件及异常场景。</strong></li><li><strong>收集 Bug 和覆盖率：此阶段将运行已开发的测试用例，识别并记录设计中出现的缺陷，同时收集代码覆盖率和功能覆盖率数据以评估验证的完备程度。这是一个包含调试和分析的迭代过程。</strong></li><li><strong>进行回归测试：在设计代码发生变更（如缺陷修复或功能更新）后，重新运行相关测试用例，确保修改的正确性且未引入新问题。</strong></li><li><strong>撰写验证报告：在验证达到特定节点或结束时，总结整个验证过程、测试结果、缺陷状态、覆盖率达成情况及存在的风险，为项目决策提供依据。</strong></li></ol><p><strong>功能点</strong>是指芯片设计中需要验证的具体功能或特性，通常从设计规范和要求文档中提取。</p><p><strong>测试点</strong>是从功能点派生出的具体测试用例或场景，用于确保功能点的每个方面都被彻底测试。</p><p><strong>功能点（Functional Point）是验证的“目标”，而测试点（Test Point）是为达成这个目标而采取的“具体行动和步骤”</strong></p><p><strong>假设我们正在设计一个芯片，其中包含一个 DMA（Direct Memory Access，直接内存访问）模块。</strong></p><h4 id="第-1-步：从设计规范中提取“功能点”"><a href="#第-1-步：从设计规范中提取“功能点”" class="headerlink" title="第 1 步：从设计规范中提取“功能点”"></a><strong>第 1 步：从设计规范中提取“功能点”</strong></h4><p><strong>翻开设计规范文档，关于 DMA 的部分有这样一条要求：</strong></p><ul><li><strong>功能点 1</strong>：DMA 模块必须支持**突发传输（Burst Transfer）**模式。</li></ul><p><strong>这是一个很明确的功能点。项目经理和验证负责人在看进度时，会关注“突发传输”这个功能点是否已经验证。</strong></p><h4 id="第-2-步：将“功能点”分解为具体的“测试点”"><a href="#第-2-步：将“功能点”分解为具体的“测试点”" class="headerlink" title="第 2 步：将“功能点”分解为具体的“测试点”"></a><strong>第 2 步：将“功能点”分解为具体的“测试点”</strong></h4><p><strong>现在，验证工程师拿到这个功能点，他需要思考：“为了证明 DMA 的突发传输功能是完全正确的，我需要测试哪些场景？” 他会从不同维度进行分解：</strong></p><ul><li><strong>正常工作场景 (Happy Path)</strong>：<ul><li><strong>测试点 1.1</strong>：测试突发长度为 4（Burst Length&#x3D;4）的传输。</li><li><strong>测试点 1.2</strong>：测试突发长度为 8（Burst Length&#x3D;8）的传输。</li><li><strong>测试点 1.3</strong>：测试不同的数据位宽（32 位，64 位）下的突发传输。</li></ul></li><li><strong>边界条件场景 (Boundary Conditions)</strong>：<ul><li><strong>测试点 1.4</strong>：测试<strong>最小</strong>突发长度（例如 1）的传输。</li><li><strong>测试点 1.5</strong>：测试<strong>最大</strong>突发长度（例如 16）的传输。</li><li><strong>测试点 1.6</strong>：测试传输的数据总量恰好等于一个突发包的大小。</li><li><strong>测试点 1.7</strong>：测试源地址或目标地址未对齐（Unaligned）的情况。</li></ul></li><li><strong>异常和错误场景 (Exception&#x2F;Error Scenarios)</strong>：<ul><li><strong>测试点 1.8</strong>：在突发传输过程中，外部总线（Bus）返回一个错误信号，看 DMA 是否能正确中止并上报错误。</li><li><strong>测试点 1.9</strong>：配置一个不支持的突发长度，看 DMA 是否能报错或不工作。</li><li><strong>测试点 1.10</strong>：在传输过程中，尝试通过软件中止（abort）任务。</li></ul></li><li><strong>组合和压力场景 (Corner Cases)</strong>：<ul><li><strong>测试点 1.11</strong>：一个突发传输刚结束，立即启动下一个突发传输（背靠背，Back-to-Back）。</li><li><strong>测试点 1.12</strong>：同时启动多个 DMA 通道进行突发传输，测试仲裁和带宽压力。</li></ul></li></ul><p><strong>现在，您可以看到，为了验证“支持突发传输”这一个功能点，我们派生出了十几个具体的、可操作的测试点。只有当所有这些测试点都成功通过后，我们才能有信心地说，这个功能点已经得到了充分和彻底的验证。</strong></p><p><strong>第一阶段：需求理解与规划</strong></p><ol><li><p><strong>深入研究规范文档</strong></p><ol><li><strong>反复、仔细地阅读功能规范、架构规范。</strong></li><li><strong>在需要时参考详细设计规范，以挖掘和覆盖边界情况。</strong></li><li><strong>目标是全面理解设计意图、功能、接口、性能指标和操作模式。</strong></li></ol></li><li><p><strong>跨部门协作与澄清</strong></p><ol><li><p><strong>与架构师、设计师以及其他验证工程师紧密合作。</strong></p></li><li><p><strong>采用多种沟通方式确保理解一致：</strong></p><ul><li><strong>串讲：</strong> 由需求提出者（如架构师）向验证&#x2F;设计团队讲解需求。</li><li><strong>反串讲：</strong> 由验证&#x2F;设计团队向需求提出者复述他们的理解，以确认无误。</li><li><strong>评审：</strong> 组织正式的会议，共同审查需求的准确性、完整性和可测试性。</li></ul></li><li><p><strong>此阶段的目标是消除歧义，就需求达成共识。</strong></p></li></ol></li><li><p><strong>确定组织方法</strong><br><strong>当我们完成上一阶段之后，需要开始制定验证计划。在制定验证计划时，我们需要组织需求和功能点，主要有两种方法：</strong></p><ul><li><strong>自下而上</strong><ol><li><strong>核心</strong>：设计的具体模块或接口出发，强调设计视角。</li><li><strong>优点</strong>：易提取具体需求，便于链接到代码覆盖点，适合模块级验证。</li><li><strong>缺点</strong>：能产生大量低层需求，不易把握系统全局。</li><li><strong>适用</strong>：模块验证、控制逻辑复杂的单元、有详细实现文档时。</li></ol></li><li><strong>自上而下</strong><ol><li><strong>核心</strong>：系统级的使用场景或数据流出发，强调客户&#x2F;验证视角。</li><li><strong>优点</strong>：能更好地把握系统级功能和性能，可在早期进行。</li><li><strong>缺点</strong>：需要清晰的高层规划，用例可能非常多，覆盖点可能偏宏观。</li><li><strong>适用</strong>：SoC（片上系统）验证、数据流为主的设计、有清晰架构或用例定义时。</li></ol></li><li><strong>实践中，</strong> 常常将两者结合，先用“自上而下”定义整体框架和主要场景，再用“自下而上”细化关键模块或接口的需求 。选择哪种方式取决于项目特点和可用信息。</li></ul></li></ol><p><strong>第二阶段：功能点识别与测试点细化</strong></p><ol><li><strong>识别功能点</strong><ol><li><strong>明确需求之后，我们需要识别设计规范和文档中需要验证的内容，例如关键功能、配置组合方式、操作模式、数据流、时序关系、协议规则等。它们构成了需要验证的功能点。</strong></li><li><strong>对功能点进行优先级排序，重点关注高风险、新设计、关键性能或客户要求的部分。</strong></li></ol></li><li><strong>分解与细化测试点</strong>：<ol><li><p><strong>将每个功能点进一步分解为具体的、可测量的****测试点</strong>或<strong>覆盖项</strong>。这是定义如何衡量功能点是否被覆盖的关键步骤。</p></li><li><p><strong>我们可以从不同维拆分测试点，例如：</strong></p><ul><li><strong>场景</strong>：不同的特权状态，如 RISC-V 中某条指令在 M、S、U 特权模式下的行为，应该是什么样的。</li><li><strong>功能</strong>：设计的核心操作，如算法计算、数据转换、控制逻辑。</li><li><strong>白盒</strong>：关注内部实现细节，如状态机状态和跳转、内部计数器边界值、流水线状态等。</li><li><strong>接口</strong>：模块或芯片与外部的交互，如总线协议时序、握手信号、中断处理。</li><li><strong>异常</strong>：错误处理、故障注入、超时、边界条件下的行为、非法配置或输入。</li><li><strong>复位与初始化</strong>：注复位后所有相关逻辑都恢复到预期默认值。</li></ul></li><li><p><strong>链接测试点与需求</strong>：在验证计划中，把每个需求明确地链接到一个或多个具体的测试点其实现类型。</p></li></ol></li></ol><p><strong>第三阶段：覆盖实现与迭代</strong></p><p>**此阶段，我们通过“**<strong>覆盖率</strong>”这一量化指标来评定验证的完备性。</p><p><strong>在仿真过程中，我们需要了解各个****测试点</strong>是否被测试激励有效“命中”。为准确获取并体现这一覆盖情况，我们会针对这些测试点编写专门的覆盖代码，用以在仿真时监测和记录它们的激活状态，最终得到覆盖率信息。</p><p>**关于覆盖率的具体技术细节，后续课程将详细介绍，此处不作展开。但我们需要知道的是，**<strong>验证是一个持续迭代的过程</strong>。这意味着需要分析覆盖率报告，找出“覆盖盲区”（即未被充分测试的部分），并据此指导后续的测试用例开发，如此循环，直至各项覆盖率达到预设的验收目标。</p><h2 id="敏捷验证"><a href="#敏捷验证" class="headerlink" title="敏捷验证"></a>敏捷验证</h2><p><strong>然而，在实践中</strong>，尤其是在追求快速迭代和市场响应的 <strong>创业公司或新兴业务</strong> 中，情况往往更加复杂。有时，为了快速验证想法或抢占市场先机，<strong>芯片开发本身也越来越多地借鉴和实践“敏捷开发”的原则</strong>：设计实现可能在规范细节尚未完全冻结时就已经开始，甚至出现“设计先行，规范后补”或者设计与规范频繁迭代的情况。</p><p>**在这种快速变化、规范可能不完全成熟的环境下，传统的、依赖稳定规范的验证方法会面临巨大挑战。如果严格等待规范最终确定再开始验证，可能会错失市场窗口；而如果基于不稳定的规范进行验证，则可能需要大量的重复工作。 因此，**<strong>敏捷验证</strong>的概念应运而生。</p><p><strong>敏捷验证强调：</strong></p><ul><li><strong>早期介入与持续集成</strong>：验证工作尽早开始，与设计紧密迭代，持续集成和测试新功能。</li><li><strong>适应性与灵活性</strong>：能够快速响应需求和设计的变更，调整验证计划和策略。</li><li><strong>风险驱动</strong>：优先验证最高风险或最不确定的部分。</li><li><strong>紧密协作</strong>：设计与验证团队之间需要更频繁、更紧密的沟通与协作。</li></ul><p><strong>虽然敏捷验证带来了灵活性，但也对验证团队的技术能力、工具链的自动化程度以及团队协作模式提出了更高的要求。如何在快速迭代和保证质量之间找到平衡点，是许多现代芯片开发团队需要面对的课题。</strong></p><h1 id="4-芯片验证的层次"><a href="#4-芯片验证的层次" class="headerlink" title="4. 芯片验证的层次"></a>4. 芯片验证的层次</h1><p><strong>芯片验证可以按照验证对象的规模分为四个主要层次，从小到大依次为：</strong></p><ol><li><strong>单元测试（Unit Testing，UT）</strong>：单元测试关注的是最小的功能单元，即单个模块或组件。</li><li><strong>块测试（Block Testing，BT）</strong>：当多个模块之间存在紧密耦合关系时，单独测试每个模块可能效率不高。块测试将这些相互关联的模块组合在一起进行测试。</li><li><strong>集成测试（Integration Testing，IT）</strong>：集成测试将多个功能块组合在一起，验证它们能否正确协同工作，通常用于验证子系统级别的功能。</li><li><strong>系统测试（System Testing，ST）</strong>：系统测试也称为 Top 验证，是将所有子系统组合起来，验证整个芯片系统的功能是否符合预期。</li></ol><blockquote><p><strong>🧩 在实际项目中，验证层次的选择应根据项目规模、团队经验和时间预算灵活调整。对于小型项目，可能只需要 UT 和 ST 两个层次；而对于复杂的 SoC 设计，通常需要所有四个层次的验证。</strong></p></blockquote><hr><h1 id="5-芯片验证指标"><a href="#5-芯片验证指标" class="headerlink" title="5. 芯片验证指标"></a>5. 芯片验证指标</h1><p><strong>如何知道我们的验证工作做得是否足够充分？这就需要一系列指标来评估验证质量，下面是芯片验证中的一些关键指标：</strong></p><h2 id="功能正确性"><a href="#功能正确性" class="headerlink" title="功能正确性"></a>功能正确性</h2><p><strong>功能正确性</strong>是最基本也是最重要的指标，即芯片是否能正确执行设计规范中定义的所有功能。功能正确性是一个定性指标（无法直接用数值来衡量），通常通过以下方式验证：</p><ul><li><strong>正常工作条件下的功能测试。</strong></li><li><strong>极端条件下的边界测试。</strong></li><li><strong>异常情况下的健壮性测试。</strong></li></ul><h2 id="测试覆盖率"><a href="#测试覆盖率" class="headerlink" title="测试覆盖率"></a>测试覆盖率</h2><p><strong>测试覆盖率是评估验证进展和验证完整性****最重要的量化指标</strong>，主要包括代码覆盖率和功能覆盖率。</p><h3 id="代码覆盖率"><a href="#代码覆盖率" class="headerlink" title="代码覆盖率"></a>代码覆盖率</h3><p><strong>代码覆盖率是一种****隐式覆盖率指标</strong>，用于衡量在仿真过程中设计源代码的执行情况。它通过分析代码结构（如行、语句、分支等）来识别哪些部分在测试中被激活，哪些未被执行。</p><p><strong>代码覆盖率包括以下几种常见类型：</strong></p><ul><li><strong>翻转覆盖率</strong>：跟踪寄存器或连线中每一位从 0 到 1 和从 1 到 0 的翻转情况，用于检查基本连接性。</li><li><strong>行覆盖率</strong>：记录哪些代码行在模拟中被执行。</li><li><strong>语句覆盖率</strong>：比行覆盖率更细粒度，跟踪每个语句的执行情况。</li><li><strong>分支覆盖率</strong>：确保控制结构（如 if、case）的布尔表达式在测试中评估为真和假。</li><li><strong>表达式覆盖率</strong>：验证表达式中的每个条件独立地评估为真和假。</li><li><strong>有限状态机覆盖率</strong>：测量状态机的状态访问和状态间转换情况。</li></ul><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h5><ul><li><strong>自动化生成</strong>：代码覆盖率可以由工具自动提取并分析，无需手动定义，易于集成到现有验证流程。</li><li><strong>识别未执行代码</strong>：帮助发现测试中未覆盖的代码区域，提示需要调整输入激励。</li></ul><h5 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a><strong>局限性</strong></h5><ul><li><strong>不保证功能正确性</strong>：即使达到 100% 的代码覆盖率，也无法确保设计没有错误或功能符合规范，因为它不涉及功能需求的验证。</li><li><strong>缺乏规范关联</strong>：无法判断是否测试了规范中定义的所有功能，仅关注代码的结构执行。</li></ul><h3 id="功能覆盖率"><a href="#功能覆盖率" class="headerlink" title="功能覆盖率"></a>功能覆盖率</h3><p><strong>功能覆盖率是一种****显式覆盖率指标</strong>，用于衡量在验证仿真的过程中，设计规范中定义的功能需求是否被测试到。与代码覆盖率不同，功能覆盖率需要手动创建，通常基于设计规范或设计的实现细节完成功能点、测试点的划分后，再编写测试点的触发条件在仿真时采样，然后收集结果得到功能覆盖率。</p><p><strong>功能覆盖率主要分为以下两种模型：</strong></p><ul><li><strong>覆盖组模型</strong>：在特定时间点采样状态值，例如使用 Toffee 的 <code>CovGroup</code> 收集功能点和测试点。</li><li><strong>覆盖属性模型</strong>：观察事件序列的时间关系，例如使用断言验证总线协议的握手序列或状态机的状态转换。</li></ul><h5 id="功能覆盖率的优点"><a href="#功能覆盖率的优点" class="headerlink" title="功能覆盖率的优点"></a><strong>功能覆盖率的优点</strong></h5><ul><li><strong>与规范直接关联</strong>：能够追踪功能需求的测试进度。</li><li><strong>识别未测试功能</strong>：帮助发现规范中定义但未被测试的功能。</li></ul><h5 id="功能覆盖率的局限性"><a href="#功能覆盖率的局限性" class="headerlink" title="功能覆盖率的局限性"></a><strong>功能覆盖率的局限性</strong></h5><ul><li><strong>手动创建</strong>：需要工程师根据规范定义覆盖模型，过程复杂且耗时。</li><li><strong>可能遗漏功能</strong>：如果覆盖模型设计不全面，可能无法覆盖所有功能需求。</li></ul><blockquote><p><strong>🔍 思考：如果功能覆盖率很高，但是代码覆盖率不是很高，说明什么？</strong></p></blockquote><h3 id="两者的关系"><a href="#两者的关系" class="headerlink" title="两者的关系"></a>两者的关系</h3><p><strong>代码覆盖率和功能覆盖率****相辅相成</strong>，共同提供更全面的验证视图：</p><ul><li><strong>代码覆盖率</strong>从底层视角检查代码执行的完整性，但无法验证功能是否符合设计意图。例如，100% 的代码覆盖率可能仍遗漏关键功能测试。</li><li><strong>功能覆盖率</strong>从顶层视角确保规范中的需求被测试，但可能无法发现未实现的代码或冗余代码。</li><li><strong>结合使用</strong>：通过结合两者，验证团队可以同时识别未执行的代码（通过代码覆盖率）和未测试的功能（通过功能覆盖率），从而更准确地评估验证质量和进度。</li></ul><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>代码覆盖率</strong>是一种自动化的指标，关注设计实现的执行情况，帮助发现测试中的盲点，但不涉及功能正确性。</p><p><strong>功能覆盖率</strong>是一种手动的指标，关注设计规范的测试情况，确保功能需求的实现和验证，但依赖于覆盖模型的完备性。</p><p><strong>在实际验证中，这两者应协同使用，以实现从代码结构到功能需求的全面覆盖，确保设计的可靠性和规范符合性。通常认为代码覆盖率达到 90% 以上，功能覆盖率达到 100% 时，验证工作才算充分。</strong></p><blockquote><p>**⚖️ ****覆盖率 100% 是否意味着设计没有错误？**答案是否定的。</p><p><strong>高覆盖率是必要条件，但不是充分条件。我们无法测试所有可能的输入组合和状态，因此即使达到 100% 的覆盖率，设计中仍可能存在未被发现的错误。这也是为什么验证工作需要综合运用多种方法和技术。</strong></p></blockquote><h2 id="缺陷密度"><a href="#缺陷密度" class="headerlink" title="缺陷密度"></a>缺陷密度</h2><p><strong>缺陷密度是指在单位代码量中发现的缺陷数量。随着验证的深入，新发现的缺陷应该逐渐减少，缺陷密度曲线应趋于平稳。如果在项目后期仍然有大量新缺陷被发现，这通常意味着验证工作不够充分。</strong></p><h2 id="验证效率与成本"><a href="#验证效率与成本" class="headerlink" title="验证效率与成本"></a>验证效率与成本</h2><p><strong>验证效率是指在有限的时间和资源下完成的验证工作量。验证成本则包括人力、设备、时间等各类资源消耗。</strong></p><p><strong>提高验证效率、降低验证成本是芯片设计企业的重要目标。</strong></p><h1 id="7-高级语言在芯片验证中的价值"><a href="#7-高级语言在芯片验证中的价值" class="headerlink" title="7. 高级语言在芯片验证中的价值"></a>7. 高级语言在芯片验证中的价值</h1><p>**面对验证复杂性、成本和人才方面的挑战，业界也在不断探索新的方法和工具。其中，****在验证中使用高级编程语言（如 Python、Java、C++ 等）**显示出越来越大的价值，原因在于：</p><ol><li><strong>更广泛的人才基础和生态系统</strong>：相比传统的硬件描述&#x2F;验证语言，高级语言拥有更庞大的开发者社区、更丰富的学习资源和成熟的软件库（生态系统），这有助于降低学习门槛，吸引更多不同背景的人才进入验证领域。学术界也认识到，<a href="https://aha.stanford.edu/life-post-moores-law-new-cad-frontier">吸引软件工程师参与硬件领域</a>对于应对后摩尔定律时代挑战的重要性。</li><li>**与软件测试实践的共通性：**虽然领域不同，但芯片功能验证与软件测试在目标（发现缺陷）、流程（测试规划、用例编写、Bug 管理）、度量（覆盖率）以及环境（大多基于软件仿真）等方面存在诸多共通之处。高级语言及其测试框架（如 pytest）可以更容易地引入软件工程中的最佳实践（如单元测试、持续集成、自动化测试等），提升验证的效率和规范性。</li><li>**提升抽象层次和开发效率：**高级语言通常提供更强的抽象能力和更简洁的语法，使得验证工程师可以更专注于验证逻辑本身，而不是底层的信号交互细节（尽管这需要如 Picker 这样的工具进行桥接），从而可能提高验证环境的开发效率和可维护性。</li></ol><p><strong>正是这些优势，使得基于高级语言的验证方法成为降低验证门槛、提高效率、促进验证众包模式发展的关键推动力之一。</strong></p><blockquote><p><strong>💡</strong><a href="https://github.com/XS-MLVP/picker">Picker</a> 正是实现这一目标的关键工具之一，它能够将 RTL 设计代码转换为多种高级语言（如 Python、C++、Java 等）的接口，让开发者可以使用自己熟悉的语言来驱动和验证硬件设计。</p></blockquote><h2 id="芯片验证众包的技术路线"><a href="#芯片验证众包的技术路线" class="headerlink" title="芯片验证众包的技术路线"></a>芯片验证众包的技术路线</h2><p><strong>为了推动芯片验证众包的发展，我们提出以下技术路线：</strong></p><ol><li><strong>多语言验证工具</strong>：开发如 <strong>Picker</strong> 等工具，允许验证人员使用自己熟悉的编程语言（如 Python、Java、C++ 或 Go）参与验证，降低入门门槛。</li><li><strong>开放学习资源</strong>：提供全面、系统的在线学习材料，让任何人都能自学芯片验证知识。</li><li><strong>真实验证案例</strong>：基于开源处理器（如”香山昆明湖”RISC-V 处理器）提供实际验证案例，让学习者能够实践所学。</li><li><strong>众包验证平台</strong>：建立专门的众包验证平台，连接芯片设计公司和验证人才，组织验证任务的分发和管理。</li></ol><p><img src="https://open-verify.cc/beginner/course/1-basis/assets/opensource-chip-steps.png" alt="img"></p><blockquote><p>**🚀 **<strong>未来展望</strong>：我们的愿景是”打开传统验证模式的黑盒，让所有感兴趣的人可以随时随地的，用自己擅长的编程语言参与芯片验证”。这将极大地扩展验证人才池，降低芯片验证成本，加速芯片创新周期。</p></blockquote><h1 id="9-小结"><a href="#9-小结" class="headerlink" title="9. 小结"></a>9. 小结</h1><p><strong>在本节课中，我们学习了芯片验证的基础知识，包括：</strong></p><ul><li><strong>芯片验证的定义及其在芯片设计中的关键作用。</strong></li><li><strong>完整的芯片验证流程，从验证计划到验证报告。</strong></li><li><strong>芯片验证的不同层次，从单元测试到系统测试。</strong></li><li><strong>评估验证质量的关键指标，特别是覆盖率指标。</strong></li><li><strong>当前芯片验证面临的挑战。</strong></li><li><strong>芯片验证众包作为未来解决方案的潜力。</strong></li></ul><p><strong>芯片验证是确保芯片质量的关键环节，也是芯片设计中最耗时和耗资的部分。掌握验证知识不仅能够帮助你成为一名优秀的验证工程师，还能为推动芯片验证方法的创新做出贡献。</strong></p><p><strong>通过参与芯片验证众包，你不仅可以学以致用，还能为半导体产业的发展贡献自己的力量。无论你是大学生、软件开发者还是对硬件感兴趣的爱好者，都可以参与到这一激动人心的领域中来。</strong></p><p><strong>下一节课，我们将讲解 Picker 的使用，并尝试用它尝试验证环境的搭建和简单测试用例的编写。</strong></p><h1 id="10-课程后续需要的预备知识"><a href="#10-课程后续需要的预备知识" class="headerlink" title="10. 课程后续需要的预备知识"></a>10. 课程后续需要的预备知识</h1><p><strong>为了后续的学习，您还需要确保学习过以下知识：</strong></p><h2 id="Linux-基础"><a href="#Linux-基础" class="headerlink" title="Linux 基础"></a>Linux 基础</h2><ol><li><strong>Linux 的基本命令和环境配置</strong></li><li><strong>Git 的使用</strong></li><li><strong>gcc 和常用的二进制工具：重点是如何源码编译安装</strong></li></ol><blockquote><p><strong>可以看</strong><a href="https://missing-semester-cn.github.io/">计算机教育中缺失的一课</a></p></blockquote><h2 id="Python-基础"><a href="#Python-基础" class="headerlink" title="Python 基础"></a>Python 基础</h2><ol><li><strong>Python 的安装、环境配置和</strong><code>pip</code> 的使用</li><li><strong>Python 基础</strong></li><li><strong>基础的 Python 面向对象编程</strong></li><li><strong>Python 协程相关的内容（</strong><code>asyncio</code>）</li></ol><blockquote><p><strong>可以看</strong><a href="https://liaoxuefeng.com/books/python/introduction/index.html">廖雪峰的 Python 教程</a>：</p><ul><li><strong>4</strong></li><li><strong>5</strong></li><li><strong>6</strong></li><li><strong>7.1~7.4</strong></li><li><strong>8.2~8.4</strong></li><li><strong>9</strong></li><li><strong>10</strong></li><li><strong>23.1~23.2</strong></li></ul></blockquote><p><strong>上述内容是本教程的验证开发环境和使用的编程语言。</strong></p><h2 id="数字电路基础"><a href="#数字电路基础" class="headerlink" title="数字电路基础"></a>数字电路基础</h2><p><strong>学习数字电路是芯片验证的核心基础。它能帮工程师透彻理解芯片设计原理、精准对接规范要求，同时解决时序冲突和信号完整性问题，高效排查逻辑漏洞，并设计出覆盖全场景的测试用例。可以说，数字电路知识贯穿验证全流程，是确保芯片功能可靠的关键底层能力。</strong></p><p><strong>这就要求我们掌握：</strong></p><ol><li><strong>Verilog 基础</strong><ul><li><strong>推荐视频：</strong><a href="https://www.bilibili.com/video/BV1PS4y1s7XW">从电路设计的角度入门 VerilogHDL</a></li></ul></li><li><strong>Chisel 基础</strong></li></ol><p><strong>Chisel 可以等到后续的果壳 Cache 实战再开始学习，但下一讲的例子我们会用到使用 Verilog 描述的模块。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;芯片验证是确保芯片设计正确性的关键环节。随着芯片复杂度的不断提升，验证工作在整个设计流程中所占比重越来越大，已成为芯片成功与否的决定性因素。这一讲我们将从基础概念入手，系统介绍验证的重要性、基本流程与方法、验证层次和评估指标，探讨实际项目流程中可能遇到的挑战</summary>
      
    
    
    
    <category term="开源项目" scheme="https://zjncs.github.io/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
    <category term="GLCC" scheme="https://zjncs.github.io/tags/GLCC/"/>
    
  </entry>
  
  <entry>
    <title>eoh环境配置</title>
    <link href="https://zjncs.github.io/2025/08/13/eoh%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>https://zjncs.github.io/2025/08/13/eoh%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</id>
    <published>2025-08-13T13:20:18.000Z</published>
    <updated>2025-08-18T07:22:30.403Z</updated>
    
    <content type="html"><![CDATA[<p>by zjn</p><p>1.克隆一下源码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/FeiLiu36/EOH/</span><br></pre></td></tr></table></figure><p>2.进入源码目录，创建虚拟环境</p><p>我家里的电脑没有装conda，所以我用的是Python自带的<code>venv</code>，如果你有conda，可以用conda创建虚拟环境。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv eoh_env</span><br></pre></td></tr></table></figure><p>然后激活虚拟环境:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> eoh_env/Scripts/activate</span><br></pre></td></tr></table></figure><p>记得虚拟环境的Python版本要&gt;3.10</p><p>可以确定一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><p>3.安装依赖</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#基础依赖</span></span><br><span class="line">pip install numpy numba joblib</span><br></pre></td></tr></table></figure><p><img src="C:\Users\22692\AppData\Roaming\Typora\typora-user-images\image-20250812234415782.png" alt="image-20250812234415782"></p><p>在这个目录下，直接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>也可以</p><p>4.配置llm参数</p><p><img src="C:\Users\22692\AppData\Roaming\Typora\typora-user-images\image-20250812234524030.png" alt="image-20250812234524030"></p><p>按照官网的指示，我选择了</p><h6 id="示例1：旅行商问题的构造算法"><a href="#示例1：旅行商问题的构造算法" class="headerlink" title="示例1：旅行商问题的构造算法"></a>示例1：旅行商问题的构造算法</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd examples/tsp_construct</span><br><span class="line"></span><br><span class="line">python runEoH.py</span><br></pre></td></tr></table></figure><p>但是需要先去买api</p><p><a href="https://platform.deepseek.com/usage">DeepSeek 开放平台</a></p><p><img src="C:\Users\22692\AppData\Roaming\Typora\typora-user-images\image-20250813000015718.png" alt="image-20250813000015718"></p><p>在runEoH里面改一下参数</p><p>理论上就可以跑</p><p>但是，可能会遇到timeout</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\zny\Desktop\eoh\EoH-main\eoh&gt; &amp; C:\Users\zny\Desktop\eoh\eoh_env\Scripts\python.exe c:/Users/zny/Desktop/eoh/EoH-main/examples/tsp_construct/runEoH.py</span><br><span class="line">----------------------------------------- </span><br><span class="line">---              Start EoH            ---</span><br><span class="line">-----------------------------------------</span><br><span class="line">- output folder created -</span><br><span class="line">-  parameters loaded -</span><br><span class="line">- Prob tsp_construct loaded </span><br><span class="line">- EoH parameters loaded -</span><br><span class="line">- Evolution Start -</span><br><span class="line">- check LLM API</span><br><span class="line">remote llm api is used ...</span><br><span class="line">creating initial population:</span><br><span class="line">Parallel <span class="keyword">time</span> out .</span><br><span class="line">Parallel <span class="keyword">time</span> out .</span><br><span class="line">Pop initial: </span><br><span class="line"></span><br><span class="line">initial population has been created!</span><br><span class="line"> OP: e1, [1 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line"> OP: e2, [2 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line"> OP: m1, [3 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line"> OP: m2, [4 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;c:\Users\zny\Desktop\eoh\EoH-main\examples\tsp_construct\runEoH.py&quot;</span>, line 22, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    evolution.run()</span><br><span class="line">  File <span class="string">&quot;C:\Users\zny\Desktop\eoh\EoH-main\eoh\src\eoh\eoh.py&quot;</span>, line 42, <span class="keyword">in</span> run</span><br><span class="line">    method.run()</span><br><span class="line">  File <span class="string">&quot;C:\Users\zny\Desktop\eoh\EoH-main\eoh\src\eoh\methods\eoh\eoh.py&quot;</span>, line 177, <span class="keyword">in</span> run</span><br><span class="line">    json.dump(population[0], f, indent=5)</span><br><span class="line">              ~~~~~~~~~~^^^</span><br><span class="line">IndexError: list index out of range</span><br></pre></td></tr></table></figure><p><img src="C:\Users\22692\AppData\Roaming\Typora\typora-user-images\image-20250813000210705.png" alt="image-20250813000210705"></p><p>找到utils getParas</p><p><img src="C:\Users\22692\AppData\Roaming\Typora\typora-user-images\image-20250813000238820.png" alt="image-20250813000238820"></p><p>timeout设的高一点，但没有完全解决问题，推测可能是r1模型不是很聪明，因为花了大几万token只找到一个解</p><p>或许也可以降低tsp问题的复杂度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">(eoh_env) PS C:\Users\zny\Desktop\eoh\EoH-main\eoh&gt; &amp; C:\Users\zny\Desktop\eoh\eoh_env\Scripts\python.exe c:/Users/zny/Desktop/eoh/EoH-main/examples/tsp_construct/runEoH.py</span><br><span class="line">-----------------------------------------</span><br><span class="line">---              Start EoH            ---</span><br><span class="line">-----------------------------------------</span><br><span class="line">- output folder created -</span><br><span class="line">-  parameters loaded -</span><br><span class="line">- Prob tsp_construct loaded</span><br><span class="line">- EoH parameters loaded -</span><br><span class="line">- Evolution Start -</span><br><span class="line">- check LLM API</span><br><span class="line">remote llm api <span class="keyword">is</span> used ...</span><br><span class="line">creating initial population:</span><br><span class="line">Pop initial: </span><br><span class="line"> Obj:  <span class="number">7.03416</span>| Obj:  <span class="number">7.50039</span>| Obj:  <span class="number">11.58909</span>|</span><br><span class="line">initial population has been created!</span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="number">7.65304</span>| Obj:  <span class="number">7.59725</span>| Obj:  <span class="number">9.37639</span>| Obj:  <span class="number">7.45505</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="number">7.6436</span>| Obj:  <span class="number">8.47352</span>| Obj:  <span class="number">8.59245</span>| Obj:  <span class="number">8.47352</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">1</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">30.6</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.59725</span></span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">2</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">36.9</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.59725</span></span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="number">7.45505</span>| Obj:  <span class="number">10.23619</span>| Obj:  <span class="number">7.57794</span>| Obj:  <span class="number">8.05993</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">3</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">50.8</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.57794</span></span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">4</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">57.1</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.57794</span></span><br><span class="line">&gt; End of Evolution!</span><br><span class="line">-----------------------------------------</span><br><span class="line">---     EoH successfully finished !   ---</span><br></pre></td></tr></table></figure><p>虽然成功finish</p><p>但是m1和m2的obj都是None</p><p>说明修改策略都超时了，因为e1和e2都简单一些所以成功了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;by zjn&lt;/p&gt;
&lt;p&gt;1.克隆一下源码&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;t</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    <category term="杂类" scheme="https://zjncs.github.io/categories/llm/%E6%9D%82%E7%B1%BB/"/>
    
    
    <category term="环境配置" scheme="https://zjncs.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>EoH文章阅读</title>
    <link href="https://zjncs.github.io/2025/08/13/EoH%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/"/>
    <id>https://zjncs.github.io/2025/08/13/EoH%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/</id>
    <published>2025-08-13T02:07:21.000Z</published>
    <updated>2025-08-13T02:08:24.536Z</updated>
    
    <content type="html"><![CDATA[<p>源码及文章：<a href="https://github.com/FeiLiu36/EoH/blob/main/README_CN.md">EoH&#x2F;README_CN.md at main · FeiLiu36&#x2F;EoH</a></p><p><strong>Evolution of Heuristic 启发式进化：</strong></p><p><strong>Evolutionary Computation 进化计算：</strong></p><p><strong>Automatic Heuristic Design 自动启发式设计</strong></p><p><strong>EoH 将自然语言中的启发式思维转化为可执行代码，通过优化搜索框架对思维与代码的持续演化，显著提升了高性能启发式算法的生成效率。</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250811094659600.png" alt="image-20250811094659600"></p><p><strong>创新点</strong>：</p><p><strong>双重演进</strong>：EoH 利用 LLM 不仅演进代码，更重要的是它还演进“思想”。LLM 首先根据现有的优秀启发式（包含思想和代码），生成一个改进的或全新的“思想” 。</p><p><strong>思想指导代码</strong>：随后，LLM 再将这个新生成的“思想”作为指导，翻译成具体的“代码” 。</p><p><strong>提示策略 (Prompt Strategies)</strong>：整个演进过程并非盲目进行，而是由一系列精心设计的提示策略来引导，分为两大类：探索（Exploration: E1, E2）和修改（Modification: M1, M2, M3），以确保生成更多样化和更有效的启发式算法 。</p><p><strong>通过构建 thought 来表征启发式算法的核心逻辑。随后借助语言模型生成代码实现。随后协同进化逐步优化思想域代码</strong></p><p><strong>三大贡献：</strong></p><p><strong>框架上提出 EoH</strong></p><p><strong>设计了高效的 prompt</strong></p><p><strong>通过组合优化问题对 EoH 进行了全面评估</strong></p><p><strong>与本研究最相关的是 FunSearch 框架：</strong></p><p>**FunSearch 是由 Google DeepMind 开发的一种创新的方法，其名称是 “在函数空间中搜索”（Searching in the **<strong>Fun</strong>ction Space）的缩写。它旨在利用大型语言模型（LLM）来解决数学和计算机科学领域的难题，甚至做出全新的科学发现。</p><p><strong>FunSearch 的核心思想是将一个预训练的大型语言模型（LLM）的创造力与一个自动评估系统结合起来。它并不直接让 LLM 给出问题的最终答案，而是让 LLM 生成解决问题的“程序”或“函数”。这种方法的巧妙之处在于：</strong></p><ul><li><strong>规避“幻觉”</strong>：LLM 常常会“一本正经地胡说八道”（产生幻觉）。但 FunSearch 生成的是代码，这些代码可以通过一个自动评估器（Evaluator）来运行和打分，从而有效过滤掉所有不正确或无效的想法。</li><li><strong>输出可解释的知识</strong>：FunSearch 最终产出的是一个能够解决问题的程序。人类科学家可以阅读和理解这个程序，从而洞察问题是如何被解决的，而不仅仅是知道答案是什么。这有助于激发新的研究思路。</li></ul><p><strong>FunSearch 的工作方式可以看作是一种由 LLM 驱动的“演化算法”或“遗传编程”。其基本流程如下：</strong></p><ol><li><strong>定义问题</strong>：用户首先需要用代码来描述一个问题。这通常包括一个用于评估解决方案好坏的 <code>evaluate</code> 函数，以及一个非常简单的初始程序作为“种子”。</li><li><strong>演化循环</strong>：<ul><li><strong>选择与提示</strong>：系统从一个“程序数据库”（Program Database）中挑选出一些当前最高效的程序。</li><li><strong>LLM 生成新代码</strong>：将这些高效程序作为“范例”输入给 LLM（一个专门训练用于编码的 LLM，如 Codey），并提示它在此基础上进行创新，生成新的、可能更好的函数代码。</li><li><strong>评估与筛选</strong>：新生成的代码会被自动评估器运行和打分。</li><li><strong>更新数据库</strong>：如果新程序的表现优于现有的程序，它就会被添加到程序数据库中，用于下一轮的演化。</li></ul></li><li><strong>持续迭代</strong>：这个“生成-评估-筛选”的循环会不断重复，推动程序从一个简单的“种子”逐步“演化”成一个非常高效的解决方案。</li></ol><p><strong>FunSearch 已经在一些长期存在的数学开放性问题上取得了突破性的成果：</strong></p><ul><li><strong>上限集问题（Cap Set Problem）</strong>：这是一个困扰了数学家几十年的组合数学难题。FunSearch 发现了比人类已知方法更大的上限集构造方案，这是首次由 LLM 在这类具有挑战性的科学问题上做出新发现。</li><li><strong>在线装箱问题（Bin Packing Problem）</strong>：这是一个经典的组合优化问题，旨在找到最有效的方式将不同大小的物品装入有限数量的箱子。FunSearch 发现了一种比人类常用启发式算法更优的策略。</li></ul><p><strong>EoH 旨在通过进化思想和代码，模拟人类专家进行启发式开发的过程，从而实现高效的自动启发式设计。</strong></p><p><strong>1.每次实验，系统允许大语言模型以自然语言形式生成启发式算法与对应的代码实现。</strong></p><p><strong>2.采用五种提示策略来指导 LLM 对现有思想和代码进行推理</strong></p><p><strong>3.进化出一组候选启发式算法，它利用大语言模型在遗传算子（如交叉变异）种生成新的启发式算法，并通过选择机制引导搜索过程并评估</strong></p><p><strong>与大多数进化算法中个体是优化问题的候选解不同，我们认为“思想”的进化应该是一个重要的研究方向</strong></p><p><strong>进化框架：</strong></p><p><strong>第 0 步：初始化 (Initialization)</strong></p><ul><li><strong>通过特定的“初始化提示”（Initialization prompt）来请求大型语言模型（LLM），生成一个包含 N 个初始启发式算法的种群 P。</strong></li><li><strong>每个生成的启发式算法都会被评估其性能，并被赋予一个适应度值（fitness value）。</strong></li></ul><p><strong>第 1 步：生成新的启发式算法 (Generation of Heuristics)</strong></p><ul><li><strong>只要未达到停止条件（例如，预设的代数），系统就会同时使用五种不同的“演化提示策略”（Evolution prompt strategies）来生成总共 5N 个新的启发式算法。</strong></li><li><strong>对于这五种策略中的每一种，都会重复执行 N 次以下子流程：</strong><ul><li><strong>第 1.1 步：选择父辈</strong>：从当前种群中选择一个或多个父辈启发式算法来构建提示。父辈的选择是基于其适应度排名，排名越高的个体被选中的概率越低（公式为 pi∝1&#x2F;(ri+N)，其中 ri 是排名），这鼓励了对种群中更多样化个体的探索。</li><li><strong>第 1.2 步：生成新个体</strong>：请求 LLM 根据提示生成一个新的启发式算法，包括其“思想”（自然语言描述）和对应的“代码”实现。</li><li><strong>第 1.3 步：评估</strong>：在指定的评估实例集上运行新生成的启发式算法，以确定其适应度值。</li><li><strong>第 1.4 步：加入种群</strong>：如果新生成的启发式算法及其代码是可行的（例如，没有语法错误），就将其添加到当前种群中。</li></ul></li></ul><p><strong>第 2 步：种群管理 (Population Management)</strong></p><ul><li><strong>在生成了多达 5N 个新个体后，将它们与原有的 N 个个体合并。</strong></li><li><strong>从这个扩大的种群中，选择出适应度值最高的 N 个启发式算法，形成下一代的种群。</strong></li><li><strong>之后，返回第 1 步，开始新一轮的演化。</strong></li></ul><h4 id="步骤-0-初始化-Initialization"><a href="#步骤-0-初始化-Initialization" class="headerlink" title="步骤 0: 初始化 (Initialization)"></a><strong>步骤 0: 初始化 (Initialization)</strong></h4><ul><li><strong>目标</strong>：创建初始种群。</li><li><strong>过程</strong>：框架首先会创建一个包含 <code>N</code> 个启发式算法的初始种群 <code>P</code> 。这些初始算法并非由人类专家提供，而是通过向 LLM 发送“初始化提示”（Initialization prompt）自动生成的，从而减少了对专家知识的依赖 。这个过程会重复<br><code>N</code> 次，以获得 <code>N</code> 个初始启发式算法 。</li></ul><h4 id="步骤-1-新启发式算法的生成-Generation-of-Heuristics"><a href="#步骤-1-新启发式算法的生成-Generation-of-Heuristics" class="headerlink" title="步骤 1: 新启发式算法的生成 (Generation of Heuristics)"></a><strong>步骤 1: 新启发式算法的生成 (Generation of Heuristics)</strong></h4><ul><li><strong>目标</strong>：通过进化操作产生新的、可能更优的启发式算法。</li><li><strong>过程</strong>：只要未达到停止条件（例如，预设的代数），框架就会利用五种不同的“进化提示策略”（Evolution prompt strategies）来生成新的启发式算法 。这些策略分为两大类 ：<ul><li><strong>探索 (Exploration)</strong>：如 E1 和 E2 策略，旨在通过类似交叉的操作探索启发式算法空间，产生与父代差异较大的新想法 。</li><li><strong>修改 (Modification)</strong>：如 M1, M2, M3 策略，旨在通过微调、修改参数或简化冗余部分来优化某个父代启发式算法 。</li></ul></li><li>**在每一代中，这五种策略会同时被使用，每个策略均被调用 **<br><code>N</code> 次，从而生成最多 <code>5N</code> 个新的启发式算法 。</li><li><strong>生成每一个新算法的具体流程如下：</strong><ol><li><strong>选择父代 (Parent Selection)</strong>：从当前种群中选择一个或多个父代启发式算法 。选择过程可以基于适应度排名，适应度高的个体有更高的被选中概率 。</li><li><strong>生成新个体 (Generation)</strong>：将选定的父代（包括其“思想”和“代码”）和相应的策略指令构建成一个提示，请求 LLM 生成一个新的启发式算法（包括新的“思想”和“代码”） 。</li><li><strong>评估 (Evaluation)</strong>：在新生成代码可行的情况下，将其在一组评估实例上运行，以计算出其适应度值 。</li><li><strong>加入种群 (Addition)</strong>：将这个经过评估且可行的新启发式算法添加到当前种群中 。</li></ol></li></ul><h4 id="步骤-2-种群管理-Population-Management"><a href="#步骤-2-种群管理-Population-Management" class="headerlink" title="步骤 2: 种群管理 (Population Management)"></a><strong>步骤 2: 种群管理 (Population Management)</strong></h4><ul><li><strong>目标</strong>：为下一代选择优胜者。</li><li><strong>过程</strong>：在 <code>5N</code> 个新个体生成并加入后，种群规模会临时扩大。此时，框架会从扩大的种群中选择适应度最高的 <code>N</code> 个启发式算法，形成下一代的种群 。</li><li><strong>之后，算法返回****步骤 1</strong>，开始新一代的进化 。<br><strong>Heuristic Representation：</strong></li></ul><ol><li><strong>自然语言描述 (Natural Language Description)</strong><ul><li><strong>这部分由几句自然语言组成，被称作“思想”（thought） 。</strong></li><li><strong>它由大型语言模型（LLM）创建，用于呈现启发式算法的高级思想和核心逻辑 。</strong></li></ul></li><li><strong>代码块 (Code Block)</strong><ul><li><strong>这是对上述“思想”的具体编程实现 。</strong></li><li><strong>代码必须遵循预定义的格式，以便 EoH 框架能够自动识别和无缝集成 。在实验中，这通常实现为一个 Python 函数 。</strong></li><li><strong>为了格式化代码块，需要明确指定三个基本组成部分：函数名称、输入变量和输出变量 。</strong></li></ul></li><li><strong>适应度值 (Fitness Value)</strong><ul><li><strong>每个启发式算法都会被赋予一个适应度值 。</strong></li><li><strong>这个值是通过在指定问题的一组实例上运行该启发式算法，并评估其性能而获得的 。</strong></li></ul></li></ol><h1 id="提示词"><a href="#提示词" class="headerlink" title="提示词"></a>提示词</h1><p><strong>初始化提示在我们的实验中，我们使用语言模型 （LLMs）生成所有初始启发式算法，无需依赖专家知识。</strong></p><h3 id="探索策略-Exploration-Strategies"><a href="#探索策略-Exploration-Strategies" class="headerlink" title="探索策略 (Exploration Strategies)"></a>探索策略 (Exploration Strategies)</h3><p><strong>探索策略专注于通过对父代启发式算法进行类似交叉的操作来探索更广阔的算法空间 。</strong></p><ul><li><strong>E1: 差异化探索</strong><br><strong>目标</strong>: 生成与父代尽可能不同的新启发式算法 。<br><strong>过程</strong>: 首先，从当前种群中选择 <code>p</code> 个父代启发式算法 。然后，提示大型语言模型（LLM）设计一个在思想上与这些父代尽可能不同的新算法，以探索全新的思路 。</li><li><strong>E2: 共同思想探索</strong><br><strong>目标</strong>: 探索与父代共享相同核心思想但实现方式不同的新启发式算法 。<br><strong>过程</strong>: 首先，从当前种群中选择 <code>p</code> 个父代 。然后，指令 LLM 识别这些算法背后的共同思想 。接着，要求 LLM 在这些共同思想的基础上，通过引入新元素来设计一个尽可能与父代不同的新算法 。</li></ul><h3 id="修改策略-Modification-Strategies"><a href="#修改策略-Modification-Strategies" class="headerlink" title="修改策略 (Modification Strategies)"></a>修改策略 (Modification Strategies)</h3><p><strong>修改策略专注于通过调整、修改参数或简化来优化单个父代启发式算法 。</strong></p><ul><li><strong>M1: 性能改进</strong><br><strong>目标</strong>: 修改一个启发式算法以获得更好的性能 。<br><strong>过程</strong>: 从种群中选择一个启发式算法 。然后，提示 LLM 对其进行修改，以产生一个新的版本 。</li><li><strong>M2: 参数调整</strong><br><strong>目标</strong>: 修改一个已选启发式算法的参数 。<br><strong>过程</strong>: 从种群中选择一个启发式算法 。然后，提示 LLM 尝试在该算法中调整参数，而不是设计一个全新的算法 。</li><li><strong>M3: 简化与去冗余</strong><br><strong>目标</strong>: 通过移除冗余组件来简化启发式算法 。<br><strong>过程</strong>: 从种群中选择一个启发式算法 。然后，提示 LLM 分析并识别其主要组成部分，并判断是否存在冗余 。最后，要求 LLM 根据其分析结果来简化该算法的代码实现 。</li></ul><p><strong>选择机制：</strong></p><h3 id="排序与排名"><a href="#排序与排名" class="headerlink" title="排序与排名"></a>排序与排名</h3><ul><li><strong>把种群中的所有启发式算法按****适应度</strong>从好到坏排序。</li><li><strong>排名 <strong>r_i</strong> 是启发式算法 i 的位置（最好的是 1，最差是 N）。</strong></li></ul><p><strong>选择的概率公式：<strong>p_i</strong>∝1&#x2F;(<strong>r_i</strong>+N)</strong></p><p><strong>概率与排名与 N 的和成反比</strong></p><p><strong>也就是排名越好，概率越大</strong></p><p><strong>排名越差，值越小，但永远不会是零（所以最差的启发式也有机会被选中）。</strong></p><p><strong>加上 N 可以让概率差距变小，保证****探索性</strong>，防止过早陷入局部最优。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p><strong>在线装箱问题：</strong></p><p>**这个问题的目标是将一系列不同大小的物品，放入尽可能少的、具有固定容量 **</p><p><code>C</code> 的箱子中 。实验重点关注的是“在线场景”，即物品是依次到达的，每当一个物品到达时，必须立即决定将其放入哪个箱子，而不能等待后续物品的信息 。</p><p><strong>评估实例</strong>: 在启发式算法的进化过程中，其性能是在五个大小为 5k（即 5000 个物品）、容量为 100 的 Weibull 实例上进行评估的 。</p><p><strong>Weibull 实例是指物品大小遵循 Weibull 分布的装箱问题实例，这种分布常用于模拟实际应用中的物品大小。</strong></p><p><strong>适应度计算</strong>: 一个启发式算法的适应度值被设定为在这五个实例上 lb&#x2F;n 的平均值 。</p><ul><li><strong>其中，</strong> lb ** 代表理论上最优解（即最少箱子数）的下限 。比如直接总容量除以单个容量**</li><li><strong>n 是被评估的启发式算法完成所有物品装箱后，实际使用的箱子总数 。</strong><br><strong>这个比率越高，说明算法使用的箱子数越接近理论最优值，性能也就越好。</strong></li></ul><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813091735990.png" alt="image-20250813091735990"></p><p><strong>比较方法即 人工 +funsearch</strong></p><p><strong>tsp</strong></p><h3 id="目标-Objective"><a href="#目标-Objective" class="headerlink" title="目标 (Objective)"></a>目标 (Objective)</h3><p><strong>旅行商问题（TSP）的目标是找到一条最短的路线，这条路线需要访问所有给定的地点各一次，并最终返回到出发点 。它是一个被广泛研究的组合优化问题，也是一个常用的启发式算法测试平台 。</strong></p><h3 id="评估设置-Evaluation-Setup"><a href="#评估设置-Evaluation-Setup" class="headerlink" title="评估设置 (Evaluation Setup)"></a>评估设置 (Evaluation Setup)</h3><p><strong>评估实例</strong>: 启发式算法的进化（训练）过程是在一组 64 个 TSP100（即 100 个地点）的实例上进行的 。这些实例中的地点位置是从一个 [0, 1]² 的二维空间中随机抽样生成的 。</p><p><strong>也就是六十四个场景。边长为 1 的正方形区域，100 个地点的位置（即 X, Y 坐标）都是在这个 1x1 的正方形地图上****随机生成</strong>的</p><p><strong>适应度计算</strong>: 一个启发式算法的适应度值，是根据其解法与最优解之间的“平均差距”（average gap）来确定的 。这个用于计算差距的最优解是由一个名为“Concorde”的精确求解器生成的 。</p><p><strong>最优解 (Optimal Solution)</strong>: 对于每一个 TSP 问题，理论上都存在一个唯一的最短路径。研究人员使用一个叫做 <strong>Concorde</strong> 的顶尖求解器，它非常强大，可以计算出这 100 个地点问题的精确最优解</p><p><strong>差距 (Gap)</strong>: 当一个待评估的启发式算法对某个问题给出一个解（一条路径）后，研究人员会计算这个解的长度与“标准答案”的长度之间的百分比差异。这个差异就是“差距（Gap）”。例如，如果标准答案是 100 公里，算法算出来是 102 公里，那么差距就是 2%。</p><p><strong>平均差距 (Average Gap)</strong>: 算法会在全部 64 个实例上运行，得到 64 个“差距”值。最后，计算这 64 个值的<strong>平均数</strong>。</p><p><strong>适应度值 (Fitness Value)</strong>: 这个最终的<strong>平均差距</strong>就被用作该算法的适应度值。这个值越小，说明算法的解越接近最优解，性能就越好。</p><p><strong>比较方法是最近插入法和最远插入法，加上 ORtools</strong></p><p><strong>AI 方面</strong><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813092505786.png" alt="image-20250813092505786"></p><p><strong>实验细节</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813092653598.png" alt="image-20250813092653598"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813093043080.png" alt="image-20250813093043080"></p><p><strong>感觉就是人类定了大方向与框架，然后 llm 负责实现与迭代</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813090211212.png" alt="image-20250813090211212"></p><p><strong>结果：</strong></p><p><strong>X 轴</strong> 代表“进化代数”（Number of generations），从第 1 代到第 20 代。</p><p><strong>Y 轴</strong> 代表“性能”（Performance），这个值越高，说明算法的效果越好。</p><p><strong>红色的折线</strong> 显示了在每一代中发现的最佳启发式算法的性能。您可以看到，性能从最初的 0.9620，经过 20 代的持续优化，最终达到了 0.9932。</p><p><strong>折线上的每个红点都代表一个性能上的“飞跃”，即发现了一个更好的启发式算法。</strong></p><p>**旁边的标注（如 **<strong>E1, E2, M1</strong>）指明了这是由哪一种“提示策略”实现的突破。</p><p>**标注的文字（如 **<code>E2, utilization of cubic root</code>）则是对这个新算法核心思想的简要描述，也就是“思想”（Thought）。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094028517.png" alt="image-20250813094028517"></p><p><strong>人类想到的，算出一个物品大小和容量，然后做差，差最大的说明放完东西后，箱子剩下的空间最小</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094351634.png" alt="image-20250813094351634"></p><p><strong>AI 想到的，</strong><code>comb1</code> 项通过 <code>(bins - max_bin)**2</code> 惩罚那些容量较大（较空）的箱子，鼓励利用已部分填充的箱子。</p><p><code>comb2</code> 和 <code>comb3</code> 项则包含了物品大小和箱子容量的二次方和三次方关系。</p><p><strong>但是物理意义不直观</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094544302.png" alt="image-20250813094544302"></p><p><strong>EoH，显式地融合了多种启发式思想：</strong></p><ol><li><strong>利用率 (<code>ulti</code>)</strong>: 衡量放入物品后箱子有多满。</li><li><strong>动态调整 (<code>adjust</code>)</strong>: 使用 <code>where</code> 条件语句，根据剩余空间和物品大小的关系，采取不同的策略，实现了“惩罚大箱子”的逻辑。</li><li><strong>混合分数 (<code>hybrid_exp</code>, <code>adjust</code>)</strong>: 将多个不同来源的启发式思想（如指数衰减、利用率、条件惩罚）组合成最终的得分。</li></ol><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094817807.png" alt="image-20250813094817807"></p><p><strong>消融研究指的是，为了理解一个复杂模型或系统的各个组成部分的重要性，而系统性地“移除”或“简化”其中一个或多个组件，然后观察整个系统性能变化的一种实验方法。</strong></p><p><strong>根据论文 4.3 节的描述，作者进行消融研究的目的是“为了更好地理解 EoH 中主要组成部分的贡献” 。</strong></p><p><strong>具体做法是，他们创建了几个“被削弱”的 EoH 版本，并与完整的 EoH 模型进行性能比较：</strong></p><p><strong>移除了“思想”部分</strong>: 他们创建了一个名为 <code>EoC</code> (Evolution of Codes) 的版本。这个版本只进化代码，完全没有自然语言的“思想”部分，以此来验证“思想”这个组件的价值 。</p><p><strong>移除了部分“提示策略”</strong>: 他们还创建了 <code>EoH-e1</code> 和 <code>EoH-e2</code> 版本。这些版本虽然保留了“思想”，但只使用了五种提示策略中的一种或两种 。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813095229016.png" alt="image-20250813095229016"></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813095444591.png" alt="image-20250813095444591"></p><h1 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h1><p><strong>为了证明 EoH 中“思想”（自然语言描述）和“代码”共同进化是其核心优势，研究者进行了对比实验 。</strong></p><p><strong>实验设置</strong>: 他们将完整的 EoH 与几个变体进行了比较 ：</p><p><code>C2C</code>: 只进化代码，没有“思想”部分 。</p><p><code>T2T2C</code>: 只在进化中使用“思想”表示，需要时再由 LLM 生成代码用于评估 。</p><p><code>T&amp;C2T2C</code>: 进化时同时使用“思想”和“代码”作为输入，但只让 LLM 输出新的“思想”</p><p><strong>结论</strong>: 实验结果（表 6）明确表明，只进化代码（C2C）或只进化思想（T2T2C）的效果远不如完整的 EoH 。这有力地证明了**“思想”和“代码”的共同进化对 EoH 的成功做出了重大贡献** 。</p><h4 id="不同大型语言模型的影响-Different-LLMs"><a href="#不同大型语言模型的影响-Different-LLMs" class="headerlink" title="不同大型语言模型的影响 (Different LLMs)"></a><strong>不同大型语言模型的影响 (Different LLMs)</strong></h4><p><strong>研究者测试了 EoH 在使用不同 LLM 时的性能，包括 GPT-3.5、Gemini Pro、CodeLlama 和 Deepseek 。</strong></p><ul><li><strong>结论</strong>:<ul><li><strong>EoH 在使用这些不同的 LLM 时，都能够生成性能良好的启发式算法 。</strong></li><li><strong>即使只进行 2000 次查询，其性能也优于随机查询 GPT-3.5 一万次的结果 。</strong></li><li><strong>尽管如此，实验结果也显示，使用更强大的 LLM（如 GPT-3.5 和 Gemini Pro）能带来更好的性能 。</strong></li></ul></li></ul><h4 id="利用专家启发式算法-Use-of-Expert-Heuristic"><a href="#利用专家启发式算法-Use-of-Expert-Heuristic" class="headerlink" title="利用专家启发式算法 (Use of Expert Heuristic)"></a><strong>利用专家启发式算法 (Use of Expert Heuristic)</strong></h4><p><strong>研究者探究了将一个已知的、由人类专家或其它 AI 系统设计的优秀算法（专家启发式算法）放入 EoH 的初始种群中会产生什么影响 。</strong></p><p><strong>实验设置</strong>: 他们将 FunSearch 论文中提供的优秀启发式算法放入 EoH 的初始种群，并将这个版本称为 <code>EoH expert</code> 。</p><p><strong>结论</strong>: 结果显示，<code>EoH expert</code> 的性能明显超过了原始的 EoH 和 FunSearch 。这表明，<strong>EoH 框架可以有效地继承和进化已有的专家知识，从而产生更优秀的下一代算法</strong> 。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;源码及文章：&lt;a href=&quot;https://github.com/FeiLiu36/EoH/blob/main/README_CN.md&quot;&gt;EoH&amp;#x2F;README_CN.md at main · FeiLiu36&amp;#x2F;EoH&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;stro</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="论文" scheme="https://zjncs.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>链表双指针0808</title>
    <link href="https://zjncs.github.io/2025/08/08/%E9%93%BE%E8%A1%A8%E5%8F%8C%E6%8C%87%E9%92%880808/"/>
    <id>https://zjncs.github.io/2025/08/08/%E9%93%BE%E8%A1%A8%E5%8F%8C%E6%8C%87%E9%92%880808/</id>
    <published>2025-08-08T07:17:53.000Z</published>
    <updated>2025-08-08T07:18:00.984Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3-0019-删除链表的倒数第-N-个结点"><a href="#3-0019-删除链表的倒数第-N-个结点" class="headerlink" title="3.0019. 删除链表的倒数第 N 个结点"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.09-Exercises?id=_3-0019-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%AC-n-%E4%B8%AA%E7%BB%93%E7%82%B9">3.</a><a href="https://leetcode.cn/problems/remove-nth-node-from-end-of-list/">0019. 删除链表的倒数第 N 个结点</a></h2><h3 id="3-1-题目大意"><a href="#3-1-题目大意" class="headerlink" title="3.1 题目大意"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.09-Exercises?id=_31-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">3.1 题目大意</a></h3><p><strong>描述</strong>：给定一个链表的头节点 <code>head</code>。</p><p><strong>要求</strong>：删除链表的倒数第 <code>n</code> 个节点，并且返回链表的头节点。</p><p><strong>说明</strong>：</p><ul><li><strong>要求使用一次遍历实现。</strong></li><li>**链表中结点的数目为 **<code>sz</code>。</li></ul><p><strong>示例</strong>：</p><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024001901.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2,3,4,5], n = 2</span><br><span class="line"> 输出：[1,2,3,5]</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> 输入：head = [1], n = 1</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">     def removeNthFromEnd(self, head: Optional[ListNode], n: int) -&gt; Optional[ListNode]:</span><br><span class="line">         slow, fast = head, head</span><br><span class="line">         </span><br><span class="line">         # fast 先走 n 步</span><br><span class="line">         for _ in range(n):</span><br><span class="line">             fast = fast.next</span><br><span class="line">         </span><br><span class="line">         # 如果 fast 走到 None，说明删除的是头节点</span><br><span class="line">         if not fast:</span><br><span class="line">             return head.next</span><br><span class="line">         </span><br><span class="line">         # 同步移动，直到 fast 到最后一个节点</span><br><span class="line">         while fast.next:</span><br><span class="line">             slow = slow.next</span><br><span class="line">             fast = fast.next</span><br><span class="line">         </span><br><span class="line">         # 删除 slow.next 节点</span><br><span class="line">         slow.next = slow.next.next</span><br><span class="line">         return head</span><br><span class="line"> </span><br></pre></td></tr></table></figure><ul><li><a href="https://leetcode.cn/problems/middle-of-the-linked-list/">876. 链表的中间结点 - 力扣（LeetCode）</a></li></ul><h4 id="3-4-2-题目大意"><a href="#3-4-2-题目大意" class="headerlink" title="3.4.2 题目大意"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.08-Linked-List-Two-Pointers?id=_342-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">3.4.2 题目大意</a></h4><p><strong>描述</strong>：给定一个单链表的头节点 <code>head</code>。</p><p><strong>要求</strong>：返回链表的中间节点。如果有两个中间节点，则返回第二个中间节点。</p><p><strong>说明</strong>：</p><ul><li>**给定链表的结点数介于 **<code>1</code> 和 <code>100</code> 之间。</li></ul><p><strong>示例</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> 输入：[1,2,3,4,5]</span><br><span class="line"> 输出：此列表中的结点 3 (序列化形式：[3,4,5])</span><br><span class="line"> 解释：返回的结点值为 3 。</span><br><span class="line"> 注意，我们返回了一个 ListNode 类型的对象 ans，这样：</span><br><span class="line"> ans.val = 3, ans.next.val = 4, ans.next.next.val = 5, 以及 ans.next.next.next = NULL.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> 输入：[1,2,3,4,5,6]</span><br><span class="line"> 输出：此列表中的结点 4 (序列化形式：[4,5,6])</span><br><span class="line"> 解释：由于该列表有两个中间结点，值分别为 3 和 4，我们返回第二个结点。</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">     def middleNode(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         slow, fast = head, head</span><br><span class="line">         while fast and fast.next:</span><br><span class="line">             slow = slow.next</span><br><span class="line">             fast = fast.next.next</span><br><span class="line">         return slow</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;3-0019-删除链表的倒数第-N-个结点&quot;&gt;&lt;a href=&quot;#3-0019-删除链表的倒数第-N-个结点&quot; class=&quot;headerlink&quot; title=&quot;3.0019. 删除链表的倒数第 N 个结点&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://dataw</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>链表排序0807</title>
    <link href="https://zjncs.github.io/2025/08/07/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0807/"/>
    <id>https://zjncs.github.io/2025/08/07/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0807/</id>
    <published>2025-08-07T08:32:08.000Z</published>
    <updated>2025-08-07T09:05:02.307Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2-0021-合并两个有序链表"><a href="#2-0021-合并两个有序链表" class="headerlink" title="2.0021. 合并两个有序链表"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_2-0021-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8">2.</a><a href="https://leetcode.cn/problems/merge-two-sorted-lists/">0021. 合并两个有序链表</a></h2><h3 id="2-1-题目大意"><a href="#2-1-题目大意" class="headerlink" title="2.1 题目大意"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_21-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">2.1 题目大意</a></h3><p><strong>描述</strong>：给定两个升序链表的头节点 <code>list1</code> 和 <code>list2</code>。</p><p><strong>要求</strong>：将其合并为一个升序链表。</p><p><strong>说明</strong>：</p><ul><li><strong>两个链表的节点数目范围是 。</strong></li><li><code>list1</code> 和 <code>list2</code> 均按 <strong>非递减顺序</strong> 排列</li></ul><p><strong>示例</strong>：</p><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024002101.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 输入：list1 = [1,2,4], list2 = [1,3,4]</span><br><span class="line"> 输出：[1,1,2,3,4,4]</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> 输入：list1 = [], list2 = []</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> class ListNode:</span><br><span class="line">     def __init__(self, val=0, next=None):</span><br><span class="line">         self.val = val</span><br><span class="line">         self.next = next</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> class Solution:</span><br><span class="line">     def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         # 创建一个哑节点 dummy，它的 next 最后会指向合并后的链表头</span><br><span class="line">         dummy = ListNode(-1)</span><br><span class="line">         current = dummy</span><br><span class="line"> </span><br><span class="line">         # 遍历两个链表，哪个值小就接到 current 后面</span><br><span class="line">         while list1 and list2:</span><br><span class="line">             if list1.val &lt;= list2.val:</span><br><span class="line">                 current.next = list1</span><br><span class="line">                 list1 = list1.next</span><br><span class="line">             else:</span><br><span class="line">                 current.next = list2</span><br><span class="line">                 list2 = list2.next</span><br><span class="line">             current = current.next  # 移动 current 指针</span><br><span class="line"> </span><br><span class="line">         # 把剩余的链表接上（最多只有一个不为 None）</span><br><span class="line">         current.next = list1 if list1 else list2</span><br><span class="line"> </span><br><span class="line">         # 返回合并后的链表头</span><br><span class="line">         return dummy.next</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p>**在新建链表的时候，我们可以选择用哑节点加指针的方式来简化代码逻辑。哑节点是一个不存储实际数据的节点，它的 **<code>next</code> 最终会指向合并后的链表头。</p><h2 id="3-0148-排序链表"><a href="#3-0148-排序链表" class="headerlink" title="3.0148. 排序链表"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_3-0148-%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8">3.</a><a href="https://leetcode.cn/problems/sort-list/">0148. 排序链表</a></h2><h3 id="3-1-题目大意"><a href="#3-1-题目大意" class="headerlink" title="3.1 题目大意"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_31-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">3.1 题目大意</a></h3><p><strong>描述</strong>：给定链表的头节点 <code>head</code>。</p><p><strong>要求</strong>：按照升序排列并返回排序后的链表。</p><p><strong>说明</strong>：</p><ul><li><strong>链表中节点的数目在范围 内。</strong></li></ul><p><strong>示例</strong>：</p><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024014801.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [4,2,1,3]</span><br><span class="line"> 输出：[1,2,3,4]Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024014802.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [-1,5,3,4,0]</span><br><span class="line"> 输出：[-1,0,3,4,5]</span><br></pre></td></tr></table></figure><p><strong>解法：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">     def sortList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         # Base case</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return head</span><br><span class="line"> </span><br><span class="line">         # Step 1: Split the list into two halves</span><br><span class="line">         slow, fast = head, head.next</span><br><span class="line">         while fast and fast.next:</span><br><span class="line">             slow = slow.next</span><br><span class="line">             fast = fast.next.next</span><br><span class="line"> </span><br><span class="line">         mid = slow.next</span><br><span class="line">         slow.next = None  # Cut the list</span><br><span class="line"> </span><br><span class="line">         # Step 2: Sort each half recursively</span><br><span class="line">         left = self.sortList(head)</span><br><span class="line">         right = self.sortList(mid)</span><br><span class="line"> </span><br><span class="line">         # Step 3: Merge the sorted halves</span><br><span class="line">         return self.merge(left, right)</span><br><span class="line"> </span><br><span class="line">     def merge(self, list1: ListNode, list2: ListNode) -&gt; ListNode:</span><br><span class="line">         dummy = ListNode(0)</span><br><span class="line">         tail = dummy</span><br><span class="line"> </span><br><span class="line">         while list1 and list2:</span><br><span class="line">             if list1.val &lt;= list2.val:</span><br><span class="line">                 tail.next = list1</span><br><span class="line">                 list1 = list1.next</span><br><span class="line">             else:</span><br><span class="line">                 tail.next = list2</span><br><span class="line">                 list2 = list2.next</span><br><span class="line">             tail = tail.next</span><br><span class="line"> </span><br><span class="line">         # Connect remaining nodes</span><br><span class="line">         tail.next = list1 if list1 else list2</span><br><span class="line">         return dummy.next</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p><strong>这里其实用到了上一题的函数，也就是合并链表并排序。我们先将链表分成两半，然后递归地对每一半进行排序，最后再合并两个已排序的链表。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;2-0021-合并两个有序链表&quot;&gt;&lt;a href=&quot;#2-0021-合并两个有序链表&quot; class=&quot;headerlink&quot; title=&quot;2.0021. 合并两个有序链表&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://datawhalechina.github.i</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>链表排序0806</title>
    <link href="https://zjncs.github.io/2025/08/06/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0806/"/>
    <id>https://zjncs.github.io/2025/08/06/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0806/</id>
    <published>2025-08-06T01:49:32.000Z</published>
    <updated>2025-08-06T01:51:12.079Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-链表排序简介"><a href="#1-链表排序简介" class="headerlink" title="1. 链表排序简介"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.05-Linked-List-Sort?id=_1-%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F%E7%AE%80%E4%BB%8B">1. 链表排序简介</a></h2><p><strong>在数组排序中，常见的排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序、计数排序、桶排序、基数排序等。</strong></p><p>**而对于链表排序而言，因为链表不支持随机访问，访问链表后面的节点只能依靠 **<code>next</code> 指针从头部顺序遍历，所以相对于数组排序问题来说，链表排序问题会更加复杂一点。</p><p><strong>下面先来总结一下适合链表排序与不适合链表排序的算法：</strong></p><ul><li>**适合链表的排序算法：**<strong>冒泡排序</strong>、<strong>选择排序</strong>、<strong>插入排序</strong>、<strong>归并排序</strong>、<strong>快速排序</strong>、<strong>计数排序</strong>、<strong>桶排序</strong>、<strong>基数排序</strong>。</li><li>**不适合链表的排序算法：**<strong>希尔排序</strong>。</li><li>**可以用于链表排序但不建议使用的排序算法：**<strong>堆排序</strong>。</li></ul><blockquote><p><strong>希尔排序为什么不适合链表排序？</strong></p></blockquote><p><strong>希尔排序</strong>：希尔排序中经常涉及到对序列中第 <code>i + gap</code> 的元素进行操作，其中 <code>gap</code> 是希尔排序中当前的步长。而链表不支持随机访问的特性，导致这种操作不适合链表，因而希尔排序算法不适合进行链表排序。</p><blockquote><p><strong>为什么不建议使用堆排序？</strong></p></blockquote><p><strong>堆排序</strong>：堆排序所使用的最大堆 &#x2F; 最小堆结构本质上是一棵完全二叉树。而完全二叉树适合采用顺序存储结构（数组）。因为数组存储的完全二叉树可以很方便的通过下标序号来确定父亲节点和孩子节点，并且可以极大限度的节省存储空间。</p><p><strong>而链表用在存储完全二叉树的时候，因为不支持随机访问的特性，导致其寻找子节点和父亲节点会比较耗时，如果增加指向父亲节点的变量，又会浪费大量存储空间。所以堆排序算法不适合进行链表排序。</strong></p><p><strong>如果一定要对链表进行堆排序，则可以使用额外的数组空间表示堆结构。然后将链表中各个节点的值依次添加入堆结构中，对数组进行堆排序。排序后，再按照堆中元素顺序，依次建立链表节点，构建新的链表并返回新链表头节点。</strong></p><h2 id="1-0147-对链表进行插入排序"><a href="#1-0147-对链表进行插入排序" class="headerlink" title="1.0147. 对链表进行插入排序"></a><a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_1-0147-%E5%AF%B9%E9%93%BE%E8%A1%A8%E8%BF%9B%E8%A1%8C%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F">1.</a><a href="https://leetcode.cn/problems/insertion-sort-list/">0147. 对链表进行插入排序</a></h2><p>**给定单个链表的头 **<code>head</code> ，使用 <strong>插入排序</strong> 对链表进行排序，并返回 <em>排序后链表的头</em> 。</p><p><strong>插入排序</strong> 算法的步骤:</p><ol><li><strong>插入排序是迭代的，每次只移动一个元素，直到所有元素可以形成一个有序的输出列表。</strong></li><li><strong>每次迭代中，插入排序只从输入数据中移除一个待排序的元素，找到它在序列中适当的位置，并将其插入。</strong></li><li><strong>重复直到所有输入数据插入完为止。</strong></li></ol><p><strong>下面是插入排序算法的一个图形示例。部分排序的列表(黑色)最初只包含列表中的第一个元素。每次迭代时，从输入数据中删除一个元素(红色)，并就地插入已排序的列表中。</strong></p><p><strong>对链表进行插入排序。</strong></p><p><img src="https://pic.leetcode.cn/1724130387-qxfMwx-Insertion-sort-example-300px.gif" alt="img"></p><hr><p><strong>示例 1：</strong></p><p><img src="https://pic.leetcode.cn/1724130414-QbPAjl-image.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [4,2,1,3]</span><br><span class="line"> 输出: [1,2,3,4]</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><p><img src="https://pic.leetcode.cn/1724130432-zoOvdI-image.png" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [-1,5,3,4,0]</span><br><span class="line"> 输出: [-1,0,3,4,5]</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> </span><br><span class="line"> class Solution:</span><br><span class="line">     def insertionSortList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return head</span><br><span class="line">         </span><br><span class="line">         # 创建一个哨兵节点（虚拟头节点）</span><br><span class="line">         dummy = ListNode(0)</span><br><span class="line">         dummy.next = head</span><br><span class="line">         </span><br><span class="line">         # 已排序部分的最后一个节点</span><br><span class="line">         last_sorted = head</span><br><span class="line">         # 当前要插入的节点</span><br><span class="line">         current = head.next</span><br><span class="line">         </span><br><span class="line">         while current:</span><br><span class="line">             if current.val &gt;= last_sorted.val:</span><br><span class="line">                 # 当前节点已经在正确位置，无需移动</span><br><span class="line">                 last_sorted = last_sorted.next</span><br><span class="line">             else:</span><br><span class="line">                 # 从头开始找插入位置</span><br><span class="line">                 prev = dummy</span><br><span class="line">                 while prev.next and prev.next.val &lt; current.val:</span><br><span class="line">                     prev = prev.next</span><br><span class="line">                 </span><br><span class="line">                 # 插入 current 节点到 prev 和 prev.next 之间</span><br><span class="line">                 last_sorted.next = current.next  # 断开 current</span><br><span class="line">                 current.next = prev.next</span><br><span class="line">                 prev.next = current</span><br><span class="line"> </span><br><span class="line">             # 移动 current 指针</span><br><span class="line">             current = last_sorted.next</span><br><span class="line">         </span><br><span class="line">         return dummy.next</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-链表排序简介&quot;&gt;&lt;a href=&quot;#1-链表排序简介&quot; class=&quot;headerlink&quot; title=&quot;1. 链表排序简介&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://datawhalechina.github.io/leetcode-notes/#/ch</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>链表0805</title>
    <link href="https://zjncs.github.io/2025/08/05/%E9%93%BE%E8%A1%A80805/"/>
    <id>https://zjncs.github.io/2025/08/05/%E9%93%BE%E8%A1%A80805/</id>
    <published>2025-08-05T08:42:50.000Z</published>
    <updated>2025-08-06T01:50:50.083Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0203-移除链表元素"><a href="#0203-移除链表元素" class="headerlink" title="0203. 移除链表元素"></a><a href="https://leetcode.cn/problems/remove-linked-list-elements/">0203. 移除链表元素</a></h2><p>**给你一个链表的头节点 **<code>head</code> 和一个整数 <code>val</code> ，请你删除链表中所有满足 <code>Node.val == val</code> 的节点，并返回 <strong>新的头节点</strong> 。</p><p><strong>示例 1：</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/06/removelinked-list.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2,6,3,4,5,6], val = 6</span><br><span class="line"> 输出：[1,2,3,4,5]</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [], val = 1</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p><strong>示例 3：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [7,7,7,7], val = 7</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p>** **<strong>提示：</strong></p><ul><li>**列表中的节点数目在范围 **<code>[0, 104]</code> 内</li><li><code>1 &lt;= Node.val &lt;= 50</code></li><li><code>0 &lt;= val &lt;= 50</code></li></ul><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> class Solution:</span><br><span class="line">     def removeElements(self, head: Optional[ListNode], val: int) -&gt; Optional[ListNode]:</span><br><span class="line">         dummy = ListNode(0)</span><br><span class="line">         dummy.next = head</span><br><span class="line">         current = dummy</span><br><span class="line">         #创建了虚拟头结点</span><br><span class="line">         while current and current.next:</span><br><span class="line">             if current.next.val==val:</span><br><span class="line">                 current.next=current.next.next</span><br><span class="line">             else : current=current.next</span><br><span class="line">         return dummy.next</span><br><span class="line">         </span><br></pre></td></tr></table></figure><p><strong>这里创建了虚拟头结点，目的就是为了方便删除头结点的情况，便于统一管理所有结点</strong></p><h2 id="0328-奇偶链表"><a href="#0328-奇偶链表" class="headerlink" title="0328. 奇偶链表"></a><a href="https://leetcode.cn/problems/odd-even-linked-list/">0328. 奇偶链表</a></h2><p>**给定单链表的头节点 **<code>head</code> ，将所有索引为奇数的节点和索引为偶数的节点分别分组，保持它们原有的相对顺序，然后把偶数索引节点分组连接到奇数索引节点分组之后，返回重新排序的链表。</p><p><strong>第一个</strong>节点的索引被认为是 <strong>奇数</strong> ， <strong>第二个</strong>节点的索引为 <strong>偶数</strong> ，以此类推。</p><p><strong>请注意，偶数组和奇数组内部的相对顺序应该与输入时保持一致。</strong></p><p>**你必须在 **<code>O(1)</code> 的额外空间复杂度和 <code>O(n)</code> 的时间复杂度下解决这个问题。</p><hr><p><strong>示例 1:</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/10/oddeven-linked-list.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [1,2,3,4,5]</span><br><span class="line"> 输出: [1,3,5,2,4]</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/10/oddeven2-linked-list.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [2,1,3,5,6,4,7]</span><br><span class="line"> 输出: [2,3,6,7,1,5,4]</span><br></pre></td></tr></table></figure><hr><p><strong>提示:</strong></p><ul><li><code>n == </code> 链表中的节点数</li><li><code>0 &lt;= n &lt;= 104</code></li><li><code>-106 &lt;= Node.val &lt;= 106</code></li></ul><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> class Solution:</span><br><span class="line">     def oddEvenList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return head</span><br><span class="line">         odd = head</span><br><span class="line">         even = head.next</span><br><span class="line">         even_head = even  # 保存偶数链的起点</span><br><span class="line">         while even and even.next:</span><br><span class="line">             odd.next = even.next</span><br><span class="line">             odd = odd.next</span><br><span class="line"> </span><br><span class="line">             even.next = odd.next</span><br><span class="line">             even = even.next</span><br><span class="line"> </span><br><span class="line">         # 连接奇数链尾部到偶数链头</span><br><span class="line">         odd.next = even_head</span><br><span class="line">         return head</span><br></pre></td></tr></table></figure><p><strong>很容易想到快慢指针，但是要先保存偶数链起点的引用，不然就容易丢失</strong></p><h2 id="0234-回文链表"><a href="#0234-回文链表" class="headerlink" title="0234. 回文链表"></a><a href="https://leetcode.cn/problems/palindrome-linked-list/">0234. 回文链表</a></h2><p>**给你一个单链表的头节点 **<code>head</code> ，请你判断该链表是否为回文链表。如果是，返回 <code>true</code> ；否则，返回 <code>false</code> 。</p><p><strong>示例 1：</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/03/pal1linked-list.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2,2,1]</span><br><span class="line"> 输出：true</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/03/pal2linked-list.jpg" alt="img"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2]</span><br><span class="line"> 输出：false</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> class Solution:</span><br><span class="line">     def isPalindrome(self, head: Optional[ListNode]) -&gt; bool:</span><br><span class="line">         # 特殊情况：空链表或只有一个节点，必然是回文</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return True</span><br><span class="line">         dummy=ListNode(0)</span><br><span class="line">         dummy.next=head</span><br><span class="line">         left,right=dummy,dummy</span><br><span class="line">         while right and right.next:</span><br><span class="line">             right=right.next.next</span><br><span class="line">             left=left.next</span><br><span class="line">         current=head</span><br><span class="line">         second_half_list = []</span><br><span class="line">         while left.next:</span><br><span class="line">             </span><br><span class="line">             second_half_list.append(left.next.val)</span><br><span class="line">             left = left.next</span><br><span class="line">         while second_half_list:</span><br><span class="line">             if current.val != second_half_list.pop():</span><br><span class="line">                 return False</span><br><span class="line">             current = current.next</span><br><span class="line"> </span><br><span class="line">         return True</span><br><span class="line">                      </span><br><span class="line"> </span><br></pre></td></tr></table></figure><p><strong>其实可以直接将整个链表转换成列表，然后用双指针判断是否为回文。</strong></p><p><strong>也可以构造辅助函数，实现原地翻转，这样的空间复杂度是 O(1)。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> # 反转链表的辅助函数</span><br><span class="line">     def reverse(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         prev = None</span><br><span class="line">         curr = head</span><br><span class="line">         while curr:</span><br><span class="line">             next_temp = curr.next</span><br><span class="line">             curr.next = prev</span><br><span class="line">             prev = curr</span><br><span class="line">             curr = next_temp</span><br><span class="line">         return prev</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;0203-移除链表元素&quot;&gt;&lt;a href=&quot;#0203-移除链表元素&quot; class=&quot;headerlink&quot; title=&quot;0203. 移除链表元素&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://leetcode.cn/problems/remove-linked-</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>Blog搭建指南</title>
    <link href="https://zjncs.github.io/2025/08/05/Blog%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/"/>
    <id>https://zjncs.github.io/2025/08/05/Blog%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/</id>
    <published>2025-08-05T03:28:22.000Z</published>
    <updated>2025-08-05T05:03:01.395Z</updated>
    
    <content type="html"><![CDATA[<p><strong>这篇文章将手把手记录我如何搭建自己的技术博客，涵盖 Hexo 博客初始化、主题美化、内容管理到自动部署的完整流程，希望对也想打造自己博客的你有所帮助。</strong></p><hr><h2 id="一、Hexo-初始化与基础配置"><a href="#一、Hexo-初始化与基础配置" class="headerlink" title="一、Hexo 初始化与基础配置"></a>一、Hexo 初始化与基础配置</h2><p><strong>Hexo 是一款基于 Node.js 的静态博客框架，轻量、快速，非常适合开发者记录技术文章。</strong></p><h3 id="初始化项目结构"><a href="#初始化项目结构" class="headerlink" title="初始化项目结构"></a>初始化项目结构</h3><p><strong>确保本地安装了 Node.js 和 Git，然后全局安装 Hexo：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> npm install -g hexo-cli</span><br><span class="line"> hexo init my-blog</span><br><span class="line"> cd my-blog</span><br><span class="line"> npm install</span><br></pre></td></tr></table></figure><p><strong>项目初始化完成后，会看到几个关键目录和文件，比如：</strong></p><ul><li><code>source/</code>：文章目录</li><li><code>themes/</code>：主题目录</li><li><code>_config.yml</code>：博客全局配置文件</li></ul><h3 id="基本信息配置"><a href="#基本信息配置" class="headerlink" title="基本信息配置"></a>基本信息配置</h3><p>**打开根目录下的 **<code>_config.yml</code>，修改以下内容来设置站点信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> title: Johnny-Zhao&#x27;s TechBlog</span><br><span class="line"> subtitle: KEEP FIGHTING</span><br><span class="line"> author: Johnny-Zhao</span><br><span class="line"> language: zh-CN</span><br><span class="line"> url: https://zjncs.github.io</span><br></pre></td></tr></table></figure><p><strong>接着，安装依赖（推荐使用 yarn）：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> yarn install</span><br></pre></td></tr></table></figure><p><strong>这样 Hexo 的核心环境就搭好了。</strong></p><hr><h2 id="二、美化博客：Butterfly-主题配置"><a href="#二、美化博客：Butterfly-主题配置" class="headerlink" title="二、美化博客：Butterfly 主题配置"></a>二、美化博客：Butterfly 主题配置</h2><p><strong>一个好看的博客主题，不光提升观感，还能激发写作动力。我选择的是 Butterfly —— 颜值高、功能全、社区活跃。</strong></p><h3 id="启用主题"><a href="#启用主题" class="headerlink" title="启用主题"></a>启用主题</h3><p>**从 **<a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 仓库</a> 克隆到 <code>themes</code> 目录，并在 <code>_config.yml</code> 中指定：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> theme: butterfly</span><br></pre></td></tr></table></figure><h3 id="个性化配置"><a href="#个性化配置" class="headerlink" title="个性化配置"></a>个性化配置</h3><p>**主题的详细配置写在 **<code>_config.butterfly.yml</code> 中，这里记录几个关键改动：</p><ul><li><strong>夜间模式</strong>：支持自动&#x2F;手动切换</li><li><strong>首页背景图 + 动态头像</strong>：加点动画效果，看着更灵动</li><li><strong>副标题打字机效果</strong>：配上「愿你历尽千帆，归来仍是少年」等短句</li><li><strong>侧边栏组件</strong>：作者简介、公告栏、分类、标签、归档一应俱全</li><li><strong>评论系统</strong>：集成 Giscus，评论数据保存在 GitHub 仓库中</li><li><strong>代码块美化</strong>：mac 风格 + 一键复制 + 语言标识</li><li><strong>数学公式支持</strong>：开启 KaTeX，写公式不再痛苦</li></ul><h3 id="Hexo-Pro：桌面端可视化管理利器"><a href="#Hexo-Pro：桌面端可视化管理利器" class="headerlink" title="Hexo Pro：桌面端可视化管理利器"></a>Hexo Pro：桌面端可视化管理利器</h3><p>**除了传统命令行操作，我还使用了 **<a href="https://github.com/jiangtj/hexo-pro">Hexo Pro</a> —— 一款基于 Electron 的桌面客户端。它支持：</p><ul><li><strong>图形化管理文章、分类、标签；</strong></li><li><strong>一键新建、编辑、发布文章；</strong></li><li><strong>直接预览博客样式；</strong></li><li><strong>支持 Hexo 插件管理与主题切换；</strong></li><li><strong>提供 Windows&#x2F;macOS 版本，开箱即用。</strong></li></ul><p><strong>这对不熟悉命令行或希望更高效率地管理博客内容的用户非常友好，特别适合日常频繁写作的技术人。</strong></p><hr><h3 id="Qexo：极致轻量的后端服务推荐"><a href="#Qexo：极致轻量的后端服务推荐" class="headerlink" title="Qexo：极致轻量的后端服务推荐"></a>Qexo：极致轻量的后端服务推荐</h3><p>**如果你想更进一步，让博客拥有完整的后台管理系统，不妨试试 **<a href="https://github.com/anyesu/qexo">Qexo</a>。</p><p><strong>Qexo 是一个为 Hexo 博客设计的轻量级后台，它的特点包括：</strong></p><ul><li><strong>支持在线创建&#x2F;修改文章；</strong></li><li><strong>自带图床功能，方便插入图片；</strong></li><li><strong>可搭配 Cloudflare Pages、Vercel、GitHub Pages 等平台部署；</strong></li><li><strong>极简风格 UI，操作直观、性能出色；</strong></li><li><strong>支持 GitHub&#x2F;Gitee 登录；</strong></li><li><strong>与 Hexo 博客仓库无缝连接，自动提交 PR 实现文章管理。</strong></li></ul><p><strong>这对于想在手机或浏览器上随时写作的朋友来说，非常实用。</strong></p><hr><blockquote><p>**💡 **<strong>个人建议</strong>：Hexo Pro 更适合桌面端写作和内容管理，Qexo 则提供了一个轻量在线 CMS 管理界面，两者可以结合使用，让你的博客写作体验更上一层楼。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;这篇文章将手把手记录我如何搭建自己的技术博客，涵盖 Hexo 博客初始化、主题美化、内容管理到自动部署的完整流程，希望对也想打造自己博客的你有所帮助。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;一、Hexo-初始化与基础配置&quot;&gt;&lt;a href=&quot;#</summary>
      
    
    
    
    <category term="杂类" scheme="https://zjncs.github.io/categories/%E6%9D%82%E7%B1%BB/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
    <category term="环境配置" scheme="https://zjncs.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
</feed>
