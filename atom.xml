<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Johnny-Zhao&#39;s TechBlog</title>
  
  <subtitle>KEEP FIGHTING</subtitle>
  <link href="https://zjncs.github.io/atom.xml" rel="self"/>
  
  <link href="https://zjncs.github.io/"/>
  <updated>2025-11-24T16:51:49.310Z</updated>
  <id>https://zjncs.github.io/</id>
  
  <author>
    <name>Johnny-Zhao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>信息经济学考试押题</title>
    <link href="https://zjncs.github.io/2025/11/25/%E4%BF%A1%E6%81%AF%E7%BB%8F%E6%B5%8E%E5%AD%A6%E8%80%83%E8%AF%95%E6%8A%BC%E9%A2%98/"/>
    <id>https://zjncs.github.io/2025/11/25/%E4%BF%A1%E6%81%AF%E7%BB%8F%E6%B5%8E%E5%AD%A6%E8%80%83%E8%AF%95%E6%8A%BC%E9%A2%98/</id>
    <published>2025-11-24T16:46:57.000Z</published>
    <updated>2025-11-24T16:51:49.310Z</updated>
    
    <content type="html"><![CDATA[<h4 id="第一题-信息经济学的作用"><a class="markdownIt-Anchor" href="#第一题-信息经济学的作用"></a> 第一题 信息经济学的作用</h4><ol><li><strong>信息经济学有利于揭示市场经济中低效率的原因</strong>。有益于揭示<strong>信息分布的非对称性</strong>对<strong>激励机制、商业谈判、制度安排</strong>等的影响，对<strong>市场运</strong>行的不利影响及其弥补措施。</li><li>信息经济学可以帮助人们建立对市场经济中<strong>信息市场运行的认识框架</strong>。包括委托代理与激励、逆向选择与道德风险、信号发送与信息甄别，以及搜寻与信息系统选择等，从而可以更好地认识信息和信息系统的特性。</li><li>信息经济学揭示了<strong>信息作为经济中重要投入要素的作用，其作用具有边际效益递增</strong>的趋势。</li><li>信息经济学促使人们理解<strong>信息</strong>的可靠性、完整程度和披露方式对市场和政府有效运作的重要影响，<strong>信息不灵</strong>会导致市场配置和政府调控的失效 。</li><li>信息经济学推动人们认识到，越是<strong>复杂的经济活动</strong>越需要依赖信息，信息对这类活动的作用日益增大，缺乏信息和必要的信息处理能力，会极大影响这类活动的效率，甚至导致失败。</li></ol><h4 id="第二题-分离均衡与混同均衡的定义"><a class="markdownIt-Anchor" href="#第二题-分离均衡与混同均衡的定义"></a> 第二题 分离均衡与混同均衡的定义</h4><ol><li><strong>混同均衡是指在不同的类型的参与者都采取相同的策略时</strong>，市场参与者<strong>无法区分</strong>不同类型的参与者。在这种情况下，信息不对称导致市场参与者<strong>无法</strong>根据其他参与者的类型来<strong>做出决策</strong>。导致市场<strong>低效率</strong></li><li><strong>分离均衡是指不同类型的参与者采取不同的策略</strong>，使得市场参与者<strong>可以</strong>根据其他参与者的行为来<strong>区分</strong>不同类型的参与者。在这种情况下，<strong>信息不对称被部分消除</strong>，市场参与者可以根据其他参与者的行为来做出更准确的决策。实现了<strong>市场效率</strong></li><li><strong>自然分离均衡：指高能力者无须刻意增加信号强度</strong>，仅选择其在<strong>完全信息下</strong>的最优水平，就足以让低能力者因成本过高而自动放弃模仿</li><li><strong>扭曲分离均衡：指为了防止低能力者的模仿，高能力者被迫选择高于其最优水平的信号强度，通过这种过度的信号投资拉大成本差距，以此来阻挡模仿者</strong></li></ol><h4 id="第三题-委托代理与机制设计"><a class="markdownIt-Anchor" href="#第三题-委托代理与机制设计"></a> 第三题 委托代理与机制设计</h4><h5 id="1-什么是委托代理理论"><a class="markdownIt-Anchor" href="#1-什么是委托代理理论"></a> 1. 什么是委托代理理论？</h5><ol><li><strong>核心问题</strong>：所有有组织或者需要组织的活动都需要契约去协调人与人之间的关系，而委托代理问题就是解决如何设计契约、如何让契约有效、以及市场参与者如何改进和限制这些契约的问题</li><li><strong>研究内容</strong>：主要研究委托人如何通过机制设计，在既满足参与约束与激励相容约束的前提下，解决信息不对称带来的逆向选择与道德风险问题</li><li><strong>基本特点</strong>：<ol><li><strong>经济关系：交易过程中双方存在信息不对称，处于信息优势的一方叫做代理人，处于信息劣势的一方叫委托人，这种关系就叫委托代理关系</strong></li><li><strong>风险与不确定性：市场上存在者风险与不确定性</strong></li><li><strong>信息不对称：委托人无法完全监督代理人的行为，代理人无法保证行为的最终结果</strong></li><li><strong>独立个体与合同建立：市场上双方是独立个体，理性经济人，在满足约束条件下追求效用最大化，通过合同建立关系</strong></li><li><strong>不利影响：由于双方的目标函数往往是不一致的，代理人的行为往往会对委托人的利益产生不利影响</strong></li></ol></li><li><strong>基本形式</strong>：一对一，医患。一对多，中央政府与国企。多对一，用户与移动。多对多，保险公司与投保人。互为委托代理，经力与员工</li><li><strong>拓展</strong>：信息经济学是委托代理理论的拓展与深化<ol><li><strong>引入了信号博弈</strong></li><li><strong>从静态博弈到动态博弈，比如重复博弈、棘轮效应、声誉机制</strong></li><li><strong>从单任务、单个委托人、代理人到多任务、多个委托人、代理人</strong></li></ol></li><li><strong>总结：<strong>委托代理的</strong>均衡合同</strong>是在信息不对称的情况下委托人与代理人展开对策的结果</li></ol><h5 id="2-什么是参与约束什么是激励相容"><a class="markdownIt-Anchor" href="#2-什么是参与约束什么是激励相容"></a> 2. 什么是参与约束？什么是激励相容？</h5><ol><li><strong>参与约束：代理人在委托人处获得的预期效用，不能低于其在其他委托人获得效益的平均值</strong></li><li><strong>激励相容：委托人通过设计合同，使得代理人在满足自身预期效用最大化的前提下，也保证委托人的效用最大化、</strong></li></ol><h5 id="3-激励相容的作用"><a class="markdownIt-Anchor" href="#3-激励相容的作用"></a> 3. 激励相容的作用？</h5><ol><li><strong>激励相容的目标</strong>：一方面使得代理人愿意说真话，暴露真实信息；另一方面使得代理人能够努力工作，诱导其不偷懒</li><li><strong>是达成均衡的必要条件</strong>，<strong>诱导代理人的最优行为</strong>，使其在道德风险中努力工作，在逆向选择中说真话</li><li><strong>解决了利益冲突</strong>，将代理人的私利与委托人的利益绑定在一起，在实现代理人预期效用最大化的时候，客观上实现了委托人的利益最大化</li><li><strong>常见的激励机制包括，组金，劳动工资，分成</strong></li></ol><h5 id="4-机制设计"><a class="markdownIt-Anchor" href="#4-机制设计"></a> 4. 机制设计</h5><ol><li><p><strong>核心定义</strong>：机制设计是指在信息不对称下，委托人如何通过设计一套机制，在满足特定约束条件的前提下，使得代理人从其自身效用最大化出发，选择与委托人目标相一致的行动 ，解决了逆向选择与道德风险问题。</p></li><li><p><strong>目标：<strong>机制设计的核心就是回答一个问题——</strong>“我怎样使某人愿意为我做某事”</strong> 。有两个目标：</p><ul><li><strong>针对隐蔽信息</strong>（逆向选择）：目标是让代理人“说真话”</li><li><strong>针对隐蔽行动</strong>（道德风险）：目标是让代理人“不偷懒”</li></ul></li><li><p><strong>两大约束</strong></p><ul><li><strong>参与约束</strong></li><li><strong>激励相容约束</strong></li></ul></li><li><p><strong>主要应用</strong>（对应目标写）：通过信号传递与信息甄别解决逆向选择问题，通过激励机制解决道德风险问题</p></li></ol><h4 id="第四题-逆向选择与道德风险"><a class="markdownIt-Anchor" href="#第四题-逆向选择与道德风险"></a> 第四题 逆向选择与道德风险</h4><h5 id="1-什么是逆向选择核心机制与效果"><a class="markdownIt-Anchor" href="#1-什么是逆向选择核心机制与效果"></a> 1. 什么是逆向选择？核心机制与效果？</h5><ol><li><strong>逆向选择是指在签订合同前，交易双方存在着市场的信息不对称，处在信息劣势的一方面临着不利的选择环境</strong></li><li><strong>核心机制：</strong><ol><li><strong>买方无法分辨市场上的产品质量，导致只能给出平均价格购买产品</strong></li><li><strong>具有高质量产品的卖方不愿意接受低价，于是退出市场</strong></li><li><strong>市场上只剩下质量差的产品，最终导致劣币驱逐良币的现象</strong></li></ol></li><li><strong>效果：市场交易量萎缩，市场失灵，资源配置无效率</strong></li></ol><h5 id="2-逆向选择的案例"><a class="markdownIt-Anchor" href="#2-逆向选择的案例"></a> 2. 逆向选择的案例</h5><ol><li><strong>二手车市场：由于买方无法判断二手车的质量，只愿意出平均价格，导致优质的二手车商退出市场，市场上只剩下劣质的二手车</strong></li><li><strong>信贷市场：由于银行提高利率，导致稳健的企业不想支付高利率的利息，退出市场，但是追求高风险的企业愿意，导致银行高风险</strong></li><li><strong>保险市场：由于保险公司提供的是平均的保险价格，身体质量好的人因为价格贵不会去参保，而身体质量差的人会选择参保，导致保验公司赔付率过高亏损</strong></li><li><strong>P2P 网贷：由于出借人无法区分借贷人的信用，导致信用较差的借贷人提供高利率，信用好的借贷人无法提供高利率而退出市场，导致平台高风险</strong></li><li><strong>电商平台：由于质量差的电商平台选择刷单、刷好评，消费者无法区分质量好坏，而导致质量好的产品被埋没，电商平台充斥着质量差的产品</strong></li></ol><h5 id="3-逆向选择的解决方案"><a class="markdownIt-Anchor" href="#3-逆向选择的解决方案"></a> 3. 逆向选择的解决方案</h5><ol><li><strong>逆向选择的解决方案本质上是通过机制设计使得私人信息暴露出来</strong></li><li><strong>信号发送：在信息不对称的市场中，代理人为了展示自己的真实能力和产品质量，主动采取有成本的行动传递信息</strong></li><li><strong>信息甄别：在信息不对称的市场中，委托人设计一套合同，使代理人通过主动选择，释放自己的真实类型</strong></li><li><strong>信号发送的例子：</strong><ol><li><strong>保修书/承诺：只有高质量厂商才愿意承诺保修，因为低质量厂商保修质量太高了</strong></li><li><strong>品牌效应：只有正品才会去建立品牌，卖假货会杂牌子</strong></li><li><strong>广告：只有高品质厂商才会去投入大量资金去建立广告</strong></li><li><strong>教育：高能力者会通过考取文凭来证明自己的能力</strong></li></ol></li><li><strong>信息甄别的例子：</strong><ol><li><strong>保险合同菜单：也就是说保险公司会设计一系列菜单，供不同人群选择</strong><ol><li><strong>向身体健康差的人推出高保费 + 全保</strong></li><li><strong>向身体健康好的人推出低保费 + 部分保</strong></li><li><strong>不同风险的人人会选择自己的合同，达到了分离均衡</strong></li></ol></li><li><strong>薪酬：</strong><ol><li><strong>追求稳定的推出高底薪 + 低提成方案</strong></li><li><strong>能力强的推出低底薪 + 高提成方案</strong></li></ol></li></ol></li></ol><h5 id="4-道德风险定义与核心特征"><a class="markdownIt-Anchor" href="#4-道德风险定义与核心特征"></a> 4. 道德风险定义与核心特征</h5><ol><li><strong>道德风险是指发生在签订合同之后，代理人利用委托人无法完全监督自己行为的信息不对称，采取了隐蔽行为谋取效用最大化，损害委托人或者其他代理人利益的行为</strong></li><li><strong>核心特征：</strong><ol><li><strong>并非败徳行为，而是基于理性决策</strong></li><li><strong>发生签订合同之后</strong></li><li><strong>隐蔽行为，委托人无法完全观测</strong></li></ol></li></ol><h5 id="5-道德风险与逆向选择的区别"><a class="markdownIt-Anchor" href="#5-道德风险与逆向选择的区别"></a> 5. 道德风险与逆向选择的区别</h5><ol><li><strong>发生时间：逆向选择发生在签订合同之前，而道德风险发生在签订合同之后</strong></li><li><strong>隐蔽信息：逆向选择隐蔽的是私人的信息，而道德风险隐蔽的是私人行动</strong></li><li><strong>解决思路：逆向选择的解决思路是信号发送与信息甄别；道德风险的解决思路除了这两个外，还有激励机制设计，信任机制，长期合同机制，部分保险和抵押</strong></li><li><strong>典型逻辑：劣币驱逐良币；搭便车、偷懒、过度冒险</strong></li></ol><h5 id="6-道德风险的案例"><a class="markdownIt-Anchor" href="#6-道德风险的案例"></a> 6. 道德风险的案例</h5><ol><li><strong>保险市场：厂商在买了失火的保险之后，就会疏于管理，导致失火的概率增大，最终导致保险公司利益受损</strong></li><li><strong>公司管理：由于职业经理人管的不是自己的钱，而是股东的钱，导致他不会精打细算，而是公款吃喝、盲目投资，损害公司利益</strong></li><li><strong>P2P 网贷：借款人在借的贷款后，追求高风险的投机性为，导致出借人利益受损</strong></li><li><strong>雇员与雇主：雇员拿的是固定工资，而且雇主无法做到时刻监督，所以会出现偷懒的现象，导致生产效率低下</strong></li></ol><h5 id="7-道德风险的解决方案"><a class="markdownIt-Anchor" href="#7-道德风险的解决方案"></a> 7. 道德风险的解决方案</h5><ol><li><strong>道德风险的解决方案主要包括信号发送、信息甄别、激励机制设计</strong></li><li><strong>信任机制是长期经济来往中双方建立起来的一套互相掌握信息、互相制约、自我约束的一套机制，通过声誉惩罚与长期合同损失来约束代理人，如果代理人偷懒作弊，会导致声誉损失与失去合作关系，因此他会选择诚实努力</strong></li><li><strong>部分保险与抵押：通过让代理人承担一部分风险，从而减少代理人在合同执行过程中的投机行为，有如下方式：</strong><ol><li><strong>抵押：让代理人抵押，一旦发现代理人违约，扣除抵押</strong></li><li><strong>风险承担：让代理人承担一部分后果，从而减少代理人道德风险</strong></li></ol></li><li><strong>长期合同机制：长期合同有利于建立更强的约束。</strong><ol><li><strong>代理人更关注于未来收益，而非简单的眼前利益</strong></li><li><strong>代理人需要建立和维护声誉，一旦违约，会损失大量的机会成本</strong></li><li><strong>对于委托人来说，长期合同可以减少监督成本</strong></li></ol></li></ol><h4 id="第五题-信号发送与信息甄别的区别"><a class="markdownIt-Anchor" href="#第五题-信号发送与信息甄别的区别"></a> 第五题 信号发送与信息甄别的区别</h4><p><strong>1. 行为主体与主动性不同：</strong></p><p><strong>信号传递：</strong></p><p><strong>主动方：代理人（拥有私人信息、处于信息优势的一方）。</strong></p><p>逻辑：代理人为了避免被误认为低质量类型，主动向委托人展示某种凭证。</p><p><strong>信息甄别 ：</strong></p><p><strong>主动方：委托人。</strong></p><p><strong>逻辑：委托人为了区分代理人的类型，主动设计一套方案让代理人来选。</strong></p><p><strong>2. 核心运作机制与条件不同：</strong></p><p><strong>信号传递：</strong></p><p><strong>机制：依赖信号成本的差异性。</strong></p><p><strong>条件：要想信号有效，高质量代理人的信号成本必须显著低于低质量代理人。只有这样，低质量代理人才因为“模仿成本太高”而放弃伪装，从而使信号可信。</strong></p><p><strong>信息甄别：</strong></p><p><strong>机制：依赖自我选择与激励相容。</strong></p><p><strong>条件：委托人设计的合同菜单必须满足激励相容约束。即必须让高类型代理人觉得选属于高类型的合同最划算，低类型代理人觉得选属于低类型的合同最划算，任何一方都不会去选对方的合同。</strong></p><p><strong>3. 信息揭示的方式不同：</strong></p><p><strong>信号传递：是通过观察代理人的信号发送行为来推断其类型。</strong></p><p><strong>信息甄别：是通过观察代理人对合同的选择行为来直接确认其类型。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;第一题-信息经济学的作用&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#第一题-信息经济学的作用&quot;&gt;&lt;/a&gt; 第一题 信息经济学的作用&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;信息经济学有利于揭示市场经济中低效率的原因&lt;/stron</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>11.24 信息经济学（一）</title>
    <link href="https://zjncs.github.io/2025/11/24/11.24%20%E4%BF%A1%E6%81%AF%E7%BB%8F%E6%B5%8E%E5%AD%A6%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://zjncs.github.io/2025/11/24/11.24%20%E4%BF%A1%E6%81%AF%E7%BB%8F%E6%B5%8E%E5%AD%A6%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2025-11-23T16:14:41.000Z</published>
    <updated>2025-11-23T16:23:47.750Z</updated>
    
    <content type="html"><![CDATA[<h4 id="第一题-什么是逆向选择核心机制与效果"><a class="markdownIt-Anchor" href="#第一题-什么是逆向选择核心机制与效果"></a> 第一题 什么是逆向选择？核心机制与效果？</h4><ol><li><strong>逆向选择是指在签订合同前，交易双方存在着市场的信息不对称，处在信息劣势的一方面临着不利的选择环境</strong></li><li><strong>核心机制：</strong><ol><li><strong>买方无法分辨市场上的产品质量，导致只能给出平均价格购买产品</strong></li><li><strong>具有高质量产品的卖方不愿意接受低价，于是退出市场</strong></li><li><strong>市场上只剩下质量差的产品，最终导致劣币驱逐良币的现象</strong></li></ol></li><li><strong>效果：市场交易量萎缩，市场失灵，资源配置无效率</strong></li></ol><h4 id="第二题-逆向选择的案例"><a class="markdownIt-Anchor" href="#第二题-逆向选择的案例"></a> 第二题 逆向选择的案例</h4><ol><li><strong>二手车市场：由于买方无法判断二手车的质量，只愿意出平均价格，导致优质的二手车商退出市场，市场上只剩下劣质的二手车</strong></li><li><strong>信贷市场：由于银行提高利率，导致稳健的企业不想支付高利率的利息，退出市场，但是追求高风险的企业愿意，导致银行高风险</strong></li><li><strong>保险市场：由于保险公司提供的是平均的保险价格，身体质量好的人因为价格贵不会去参保，而身体质量差的人会选择参保，导致保验公司赔付率过高亏损</strong></li><li><strong>P2P 网贷：由于出借人无法区分借贷人的信用，导致信用较差的借贷人提供高利率，信用好的借贷人无法提供高利率而退出市场，导致平台高风险</strong></li><li><strong>电商平台：由于质量差的电商平台选择刷单、刷好评，消费者无法区分质量好坏，而导致质量好的产品被埋没，电商平台充斥着质量差的产品</strong></li></ol><h4 id="第三题-逆向选择的解决方案"><a class="markdownIt-Anchor" href="#第三题-逆向选择的解决方案"></a> 第三题 逆向选择的解决方案</h4><ol><li><strong>逆向选择的解决方案本质上是通过机制设计使得私人信息暴露出来</strong></li><li><strong>信号发送：在信息不对称的市场中，代理人为了展示自己的真实能力和产品质量，主动采取有成本的行动传递信息</strong></li><li><strong>信息甄别：在信息不对称的市场中，委托人设计一套合同，使代理人通过主动选择，释放自己的真实类型</strong></li><li><strong>信号发送的例子：</strong><ol><li><strong>保修书/承诺：只有高质量厂商才愿意承诺保修，因为低质量厂商保修质量太高了</strong></li><li><strong>品牌效应：只有正品才会去建立品牌，卖假货会杂牌子</strong></li><li><strong>广告：只有高品质厂商才会去投入大量资金去建立广告</strong></li><li><strong>教育：高能力者会通过考取文凭来证明自己的能力</strong></li></ol></li><li><strong>信息甄别的例子：</strong><ol><li><strong>保险合同菜单：也就是说保险公司会设计一系列菜单，供不同人群选择</strong><ol><li><strong>向身体健康差的人推出高保费 + 全保</strong></li><li><strong>向身体健康好的人推出低保费 + 部分保</strong></li><li><strong>不同风险的人人会选择自己的合同，达到了分离均衡</strong></li></ol></li><li><strong>薪酬：</strong><ol><li><strong>追求稳定的推出高底薪 + 低提成方案</strong></li><li><strong>能力强的推出低底薪 + 高提成方案</strong></li></ol></li></ol></li></ol><h4 id="第四题-道德风险"><a class="markdownIt-Anchor" href="#第四题-道德风险"></a> 第四题 道德风险</h4><ol><li><strong>道德风险是指发生在签订合同之后，代理人利用委托人无法完全监督自己行为的信息不对称，采取了隐蔽行为谋取效用最大化，损害委托人或者其他代理人利益的行为</strong></li><li><strong>核心特征：</strong><ol><li><strong>并非败徳行为，而是基于理性决策</strong></li><li><strong>发生签订合同之后</strong></li><li><strong>隐蔽行为，委托人无法完全观测</strong></li></ol></li></ol><h4 id="第五题-道德风险与逆向选择的区别"><a class="markdownIt-Anchor" href="#第五题-道德风险与逆向选择的区别"></a> 第五题 道德风险与逆向选择的区别</h4><ol><li><strong>发生时间：逆向选择发生在签订合同之前，而道德风险发生在签订合同之后</strong></li><li><strong>隐蔽信息：逆向选择隐蔽的是私人的信息，而道德风险隐蔽的是私人行动</strong></li><li><strong>解决思路：逆向选择的解决思路是信号发送与信息甄别；道德风险的解决思路除了这两个外，还有激励机制设计，信任机制，长期合同机制，部分保险和抵押</strong></li></ol><h4 id="第六题-道德风险的案例"><a class="markdownIt-Anchor" href="#第六题-道德风险的案例"></a> 第六题 道德风险的案例</h4><ol><li><strong>保险市场：厂商在买了失火的保险之后，就会疏于管理，导致失火的概率增大，最终导致保险公司利益受损</strong></li><li><strong>公司管理：由于职业经理人管的不是自己的钱，而是股东的钱，导致他不会精打细算，而是公款吃喝、盲目投资，损害公司利益</strong></li><li><strong>P2P 网贷：借款人在借的贷款后，追求高风险的投机性为，导致出借人利益受损</strong></li><li><strong>雇员与雇主：雇员拿的是固定工资，而且雇主无法做到时刻监督，所以会出现偷懒的现象，导致生产效率低下</strong></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;第一题-什么是逆向选择核心机制与效果&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#第一题-什么是逆向选择核心机制与效果&quot;&gt;&lt;/a&gt; 第一题 什么是逆向选择？核心机制与效果？&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;逆向选择是指在签</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>复习</title>
    <link href="https://zjncs.github.io/2025/11/24/%E5%A4%8D%E4%B9%A0/"/>
    <id>https://zjncs.github.io/2025/11/24/%E5%A4%8D%E4%B9%A0/</id>
    <published>2025-11-23T16:14:41.000Z</published>
    <updated>2025-11-23T16:23:45.520Z</updated>
    
    <content type="html"><![CDATA[<h4 id="第一题-什么是逆向选择核心机制与效果"><a class="markdownIt-Anchor" href="#第一题-什么是逆向选择核心机制与效果"></a> 第一题 什么是逆向选择？核心机制与效果？</h4><ol><li><strong>逆向选择是指在签订合同前，交易双方存在着市场的信息不对称，处在信息劣势的一方面临着不利的选择环境</strong></li><li><strong>核心机制：</strong><ol><li><strong>买方无法分辨市场上的产品质量，导致只能给出平均价格购买产品</strong></li><li><strong>具有高质量产品的卖方不愿意接受低价，于是退出市场</strong></li><li><strong>市场上只剩下质量差的产品，最终导致劣币驱逐良币的现象</strong></li></ol></li><li><strong>效果：市场交易量萎缩，市场失灵，资源配置无效率</strong></li></ol><h4 id="第二题-逆向选择的案例"><a class="markdownIt-Anchor" href="#第二题-逆向选择的案例"></a> 第二题 逆向选择的案例</h4><ol><li><strong>二手车市场：由于买方无法判断二手车的质量，只愿意出平均价格，导致优质的二手车商退出市场，市场上只剩下劣质的二手车</strong></li><li><strong>信贷市场：由于银行提高利率，导致稳健的企业不想支付高利率的利息，退出市场，但是追求高风险的企业愿意，导致银行高风险</strong></li><li><strong>保险市场：由于保险公司提供的是平均的保险价格，身体质量好的人因为价格贵不会去参保，而身体质量差的人会选择参保，导致保验公司赔付率过高亏损</strong></li><li><strong>P2P 网贷：由于出借人无法区分借贷人的信用，导致信用较差的借贷人提供高利率，信用好的借贷人无法提供高利率而退出市场，导致平台高风险</strong></li><li><strong>电商平台：由于质量差的电商平台选择刷单、刷好评，消费者无法区分质量好坏，而导致质量好的产品被埋没，电商平台充斥着质量差的产品</strong></li></ol><h4 id="第三题-逆向选择的解决方案"><a class="markdownIt-Anchor" href="#第三题-逆向选择的解决方案"></a> 第三题 逆向选择的解决方案</h4><ol><li><strong>逆向选择的解决方案本质上是通过机制设计使得私人信息暴露出来</strong></li><li><strong>信号发送：在信息不对称的市场中，代理人为了展示自己的真实能力和产品质量，主动采取有成本的行动传递信息</strong></li><li><strong>信息甄别：在信息不对称的市场中，委托人设计一套合同，使代理人通过主动选择，释放自己的真实类型</strong></li><li><strong>信号发送的例子：</strong><ol><li><strong>保修书/承诺：只有高质量厂商才愿意承诺保修，因为低质量厂商保修质量太高了</strong></li><li><strong>品牌效应：只有正品才会去建立品牌，卖假货会杂牌子</strong></li><li><strong>广告：只有高品质厂商才会去投入大量资金去建立广告</strong></li><li><strong>教育：高能力者会通过考取文凭来证明自己的能力</strong></li></ol></li><li><strong>信息甄别的例子：</strong><ol><li><strong>保险合同菜单：也就是说保险公司会设计一系列菜单，供不同人群选择</strong><ol><li><strong>向身体健康差的人推出高保费 + 全保</strong></li><li><strong>向身体健康好的人推出低保费 + 部分保</strong></li><li><strong>不同风险的人人会选择自己的合同，达到了分离均衡</strong></li></ol></li><li><strong>薪酬：</strong><ol><li><strong>追求稳定的推出高底薪 + 低提成方案</strong></li><li><strong>能力强的推出低底薪 + 高提成方案</strong></li></ol></li></ol></li></ol><h4 id="第四题-道德风险"><a class="markdownIt-Anchor" href="#第四题-道德风险"></a> 第四题 道德风险</h4><ol><li><strong>道德风险是指发生在签订合同之后，代理人利用委托人无法完全监督自己行为的信息不对称，采取了隐蔽行为谋取效用最大化，损害委托人或者其他代理人利益的行为</strong></li><li><strong>核心特征：</strong><ol><li><strong>并非败徳行为，而是基于理性决策</strong></li><li><strong>发生签订合同之后</strong></li><li><strong>隐蔽行为，委托人无法完全观测</strong></li></ol></li></ol><h4 id="第五题-道德风险与逆向选择的区别"><a class="markdownIt-Anchor" href="#第五题-道德风险与逆向选择的区别"></a> 第五题 道德风险与逆向选择的区别</h4><ol><li><strong>发生时间：逆向选择发生在签订合同之前，而道德风险发生在签订合同之后</strong></li><li><strong>隐蔽信息：逆向选择隐蔽的是私人的信息，而道德风险隐蔽的是私人行动</strong></li><li><strong>解决思路：逆向选择的解决思路是信号发送与信息甄别；道德风险的解决思路除了这两个外，还有激励机制设计，信任机制，长期合同机制，部分保险和抵押</strong></li></ol><h4 id="第六题-道德风险的案例"><a class="markdownIt-Anchor" href="#第六题-道德风险的案例"></a> 第六题 道德风险的案例</h4><ol><li><strong>保险市场：厂商在买了失火的保险之后，就会疏于管理，导致失火的概率增大，最终导致保险公司利益受损</strong></li><li><strong>公司管理：由于职业经理人管的不是自己的钱，而是股东的钱，导致他不会精打细算，而是公款吃喝、盲目投资，损害公司利益</strong></li><li><strong>P2P 网贷：借款人在借的贷款后，追求高风险的投机性为，导致出借人利益受损</strong></li><li><strong>雇员与雇主：雇员拿的是固定工资，而且雇主无法做到时刻监督，所以会出现偷懒的现象，导致生产效率低下</strong></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;第一题-什么是逆向选择核心机制与效果&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#第一题-什么是逆向选择核心机制与效果&quot;&gt;&lt;/a&gt; 第一题 什么是逆向选择？核心机制与效果？&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;逆向选择是指在签</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>git学习</title>
    <link href="https://zjncs.github.io/2025/09/16/git%E5%AD%A6%E4%B9%A0/"/>
    <id>https://zjncs.github.io/2025/09/16/git%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-09-16T13:00:40.000Z</published>
    <updated>2025-09-16T13:00:40.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>git 学习，笔记参考 Peter Cottle 的：</strong><a href="https://learngitbranching.js.org/?locale=zh_CN&amp;NODEMO=">https://learngitbranching.js.org/?locale=zh_CN&amp;NODEMO=</a></p><h2 id="git-branch"><a class="markdownIt-Anchor" href="#git-branch"></a> Git branch</h2><p><strong>git 的分支非常轻量，只是指向某一个提交记录。</strong></p><p><strong>也就是相当于一个指针，指向一个 commit，git checkout 是切换分支。</strong></p><p><strong>再次进行 git commit 的时候，main 会更新，但是分支不会更新。</strong></p><h2 id="git-merge"><a class="markdownIt-Anchor" href="#git-merge"></a> Git merge</h2><p><strong>将两个分支合并到一起。在 Git 中合并两个分支时会产生一个特殊的提交记录，它有两个 parent 节点。</strong></p><ul><li>**创建新分支 **<code>bugFix</code></li><li>**用 **<code>git checkout bugFix</code> 命令切换到该分支</li><li><strong>提交一次</strong></li><li>**用 **<code>git checkout main</code> 切换回 <code>main</code></li><li><strong>再提交一次</strong></li><li>**用 **<code>git merge</code> 把 <code>bugFix</code> 合并到 <code>main</code></li></ul><p><strong>必须先创建分支，再切换分支，才能提交</strong></p><p><strong>注意的是 git merge 的时候需要 checkout 到被合并的分支（也就是主分支）上。</strong></p><h2 id="git-rebase"><a class="markdownIt-Anchor" href="#git-rebase"></a> Git rebase</h2><p>**第二种合并分支的方法是 **<code>git rebase</code>。Rebase 实际上就是取出一系列的提交记录，“复制”它们，然后在另外一个地方逐个的放下去。</p><p><strong>bugFix 分支里的工作直接移到 main 分支上。移动以后会使得两个分支的功能看起来像是按顺序开发，但实际上它们是并行开发的。提交记录 C3 依然存在（树上那个半透明的节点），而 C3’ 是我们 Rebase 到 main 分支上的 C3 的副本。</strong></p><p><strong>其实就是复制了一个副本 commit，然后这个副本将会合并到主分支上。与 merge 不同的是，rebase 是站在 bugFix 分支上的。</strong></p><h2 id="head"><a class="markdownIt-Anchor" href="#head"></a> Head</h2><p><strong>HEAD 总是指向当前分支上最近一次提交记录。大多数修改提交树的 Git 命令都是从改变 HEAD 的指向开始的。</strong></p><p><strong>HEAD 通常情况下是指向分支名的（如 bugFix）。在你提交时，改变了 bugFix 的状态，这一变化通过 HEAD 变得可见。</strong></p><p>**如果想看 HEAD 指向，可以通过 **<code>cat .git/HEAD</code> 查看， 如果 HEAD 指向的是一个引用，还可以用 <code>git symbolic-ref HEAD</code> 查看它的指向。</p><ul><li><strong>当你使用 <code>git checkout &lt;commit&gt;</code> 或者在 <code>detached HEAD</code> 状态下时，<code>HEAD</code> 会直接指向某个特定的提交，而不是分支。</strong></li><li><strong>当你执行 <code>git checkout &lt;branch&gt;</code> 时，Git 会更新 <code>HEAD</code>，使其指向新的分支。在这个过程中，<code>HEAD</code> 会变成该分支的最新提交。</strong></li></ul><h2 id="相对引用"><a class="markdownIt-Anchor" href="#相对引用"></a> 相对引用</h2><p>**通过指定提交记录哈希值的方式在 Git 中移动不太方便。在实际应用时，并没有像本程序中这么漂亮的可视化提交树供你参考，所以你就不得不用 **<code>git log</code> 来查查看提交记录的哈希值。</p><p><strong>比较令人欣慰的是，Git 对哈希的处理很智能。你只需要提供能够唯一标识提交记录的前几个字符即可。因此我可以仅输入</strong><code>fed2</code> 而不是上面的一长串字符。</p><p>**使用相对引用的话，你就可以从一个易于记忆的地方（比如 **<code>bugFix</code> 分支或 <code>HEAD</code>）开始计算。</p><p><strong>相对引用非常给力，这里我介绍两个简单的用法：</strong></p><ul><li><p>**使用 **<code>^</code> 向上移动 1 个提交记录</p></li><li><p>**使用 **<code>~&lt;num&gt;</code> 向上移动多个提交记录，如 <code>~3</code></p></li><li><p>**操作符 **<code>~</code> 后面可以跟一个数字（可选，不跟数字时与 <code>^</code> 相同，向上移动一次），指定向上移动多少次。</p></li><li><p>**我使用相对引用最多的就是移动分支。可以直接使用 **<code>-f</code> 选项让分支指向另一个提交。例如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">   git branch -f main HEAD~3</span><br></pre></td></tr></table></figure><p><strong>上面的命令会将 main 分支强制指向 HEAD 的第 3 级 parent 提交。</strong></p></li></ul><p><strong>个人心得，branch 本质上是分支管理，而 checkout 是切换</strong></p><h2 id="撤销变更"><a class="markdownIt-Anchor" href="#撤销变更"></a> 撤销变更</h2><p><code>git reset</code> 通过把分支记录回退几个提交记录来实现撤销改动。你可以将这想象成“改写历史”。<code>git reset</code> 向上移动分支，原来指向的提交记录就跟从来没有提交过一样。</p><p><strong>虽然在你的本地分支中使用 <strong><code>git reset</code> 很方便，但是这种“改写历史”的方法对大家一起使用的远程分支是无效的，所以要用 <code>git revert</code> 本质上是创建新的提交，新提交记录 <code>C2'</code> 引入了</strong>更改</strong> —— 这些更改刚好是用来撤销 <code>C2</code> 这个提交的。也就是说 <code>C2'</code> 的状态与 <code>C1</code> 是相同的。revert 之后就可以把你的更改推送到远程仓库与别人分享。</p><h2 id="整理提交记录"><a class="markdownIt-Anchor" href="#整理提交记录"></a> 整理提交记录</h2><p>**本系列的第一个命令是 **<code>git cherry-pick</code>, 命令形式为:</p><ul><li><code>git cherry-pick &lt;提交号&gt;...</code></li></ul><p><strong>如果你想将一些提交复制到当前所在的位置（</strong><code>HEAD</code>）下面的话， Cherry-pick 是最直接的方式了。</p><p>**但是如果你不清楚你想要的提交记录的哈希值呢? 幸好 Git 帮你想到了这一点, 我们可以利用交互式的 rebase —— 如果你想从一系列的提交记录中找到想要的记录, 这就是最好的方法了,交互式 rebase 指的是使用带参数 **<code>--interactive</code> 的 rebase 命令, 简写为 <code>-i</code></p><p><strong>如果你在命令后增加了这个选项, Git 会打开一个 UI 界面并列出将要被复制到目标分支的备选提交记录，它还会显示每个提交记录的哈希值和提交说明，提交说明有助于你理解这个提交进行了哪些更改。</strong></p><p><strong>来看一个在开发中经常会遇到的情况：我正在解决某个特别棘手的 Bug，为了便于调试而在代码中添加了一些调试命令并向控制台打印了一些信息。这些调试和打印语句都在它们各自的提交记录里。最后我终于找到了造成这个 Bug 的根本原因，解决掉以后觉得沾沾自喜！最后就差把 bugFix 分支里的工作合并回 main 分支了。你可以选择通过 fast-forward 快速合并到 main 分支上，但这样的话 main 分支就会包含我这些调试语句了。</strong></p><p><strong>但是可以通过 cherry-pick 和 rebase 去进行更改，从而把调试和 print 的记录删掉。</strong></p><h2 id="git-tag-与-git-describe"><a class="markdownIt-Anchor" href="#git-tag-与-git-describe"></a> Git tag 与 git describe</h2><p><strong>git tag 就是给 commit 一个标签。</strong></p><p><strong>由于标签在代码库中起着“锚点”的作用，Git 还为此专门设计了一个命令用来****描述</strong>离你最近的锚点（也就是标签），它就是 <code>git describe</code>！</p><p>**Git Describe 能帮助在提交历史中移动了多次以后找到方向；当用 **<code>git bisect</code>（一个查找产生 Bug 的提交记录的指令）找到某个提交记录时，可能会用到这个命令。</p><p><code>git describe</code> 的语法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> git describe &lt;ref&gt;</span><br></pre></td></tr></table></figure><p><code>&lt;ref&gt;</code> 可以是任何能被 Git 识别成提交记录的引用，如果你没有指定的话，Git 会使用你目前所在的位置（<code>HEAD</code>）。</p><p><strong>它输出的结果是这样的：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> &lt;tag&gt;_&lt;numCommits&gt;_g&lt;hash&gt;</span><br></pre></td></tr></table></figure><p><code>tag</code> 表示的是离 <code>ref</code> 最近的标签， <code>numCommits</code> 是表示这个 <code>ref</code> 与 <code>tag</code> 相差有多少个提交记录， <code>hash</code> 表示的是你所给定的 <code>ref</code> 所表示的提交记录哈希值的前几位。</p><p>**当 **<code>ref</code> 提交记录上有某个标签时，则只输出标签名称</p><h2 id="远程分支"><a class="markdownIt-Anchor" href="#远程分支"></a> 远程分支</h2><p>**既然你已经看过 **<code>git clone</code> 命令了，咱们深入地看一下发生了什么。</p><p><strong>你可能注意到的第一个事就是在我们的本地仓库多了一个名为 <strong><code>o/main</code> 的分支, 这种类型的分支就叫</strong>远程</strong>分支。由于远程分支的特性导致其拥有一些特殊属性。</p><p><strong>远程分支反映了远程仓库(在你上次和它通信时)的****状态</strong>。这会有助于你理解本地的工作与公共工作的差别 —— 这是你与别人分享工作成果前至关重要的一步.</p><p><strong>远程分支有一个特别的属性，在你切换到远程分支时，自动进入分离 HEAD 状态。Git 这么做是出于不能直接在这些分支上进行操作的原因, 你必须在别的地方完成你的工作, （更新了远程分支之后）再用远程分享你的工作成果。</strong></p><p>**你可能想问这些远程分支的前面的 **<code>o/</code> 是什么意思呢？好吧, 远程分支有一个命名规范 —— 它们的格式是:</p><ul><li><code>&lt;remote name&gt;/&lt;branch name&gt;</code></li></ul><p>**因此，如果你看到一个名为 **<code>o/main</code> 的分支，那么这个分支就叫 <code>main</code>，远程仓库的名称就是 <code>o</code>。</p><p>**大多数的开发人员会将它们主要的远程仓库命名为 **<code>origin</code>，并不是 <code>o</code>。这是因为当你用 <code>git clone</code> 某个仓库时，Git 已经帮你把远程仓库的名称设置为 <code>origin</code> 了</p><p>**不过 **<code>origin</code> 对于我们的 UI 来说太长了，因此不得不使用简写 <code>o</code> 😃 但是要记住, 当你使用真正的 Git 时, 你的远程仓库默认为 <code>origin</code>!</p><p>**如何从远程仓库获取数据 —— 命令如其名，它就是 **<code>git fetch</code>。当我们从远程仓库获取数据时, 远程分支也会更新以反映最新的远程仓库。</p><p><code>git fetch</code> 完成了仅有的但是很重要的两步:</p><ul><li><strong>从远程仓库下载本地仓库中缺失的提交记录</strong></li><li>**更新远程分支指针(如 **<code>o/main</code>)</li></ul><p><code>git fetch</code> 实际上将本地仓库中的远程分支更新成了远程仓库相应分支最新的状态。</p><p><code>git fetch</code> 并不会改变你本地仓库的状态。它不会更新你的 <code>main</code> 分支，也不会修改你磁盘上的文件。</p><p><strong>理解这一点很重要，因为许多开发人员误以为执行了 <strong><code>git fetch</code> 以后，他们本地仓库就与远程仓库同步了。它可能已经将进行这一操作所需的所有数据都下载了下来，但是</strong>并没有</strong>修改你本地的文件。</p><p><strong>git pull 实际上就是 fetch+merge</strong></p><p><strong>如果你是在一个大的合作团队中工作, 很可能是 main 被锁定了, 需要一些 Pull Request 流程来合并修改。如果你直接提交(commit)到本地 main, 然后试图推送(push)修改, 你将会收到这样类似的信息:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> ! [远程服务器拒绝] main -&gt; main (TF402455: 不允许推送(push)这个分支; 你必须使用pull request来更新这个分支.)</span><br></pre></td></tr></table></figure><p><strong>远程服务器拒绝直接推送(push)提交到 main, 因为策略配置要求 pull requests 来提交更新.</strong></p><p><strong>你应该按照流程,新建一个分支, 推送(push)这个分支并申请 pull request,但是你忘记并直接提交给了 main.现在你卡住并且无法推送你的更新.</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;git 学习，笔记参考 Peter Cottle 的：&lt;/strong&gt;&lt;a href=&quot;https://learngitbranching.js.org/?locale=zh_CN&amp;amp;NODEMO=&quot;&gt;https://learngitbranchin</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>量子计算学习</title>
    <link href="https://zjncs.github.io/2025/08/28/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0/"/>
    <id>https://zjncs.github.io/2025/08/28/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-08-28T10:06:07.000Z</published>
    <updated>2025-08-28T10:06:25.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1.1 量子计算原理</strong> <strong>量子比特概念介绍</strong> <strong>量子计算是一种基于量子力学基本原理的信息处理范式，它利用量子叠加、量子纠缠和量子干涉等现象，解决经典计算机无法高效处理的问题。</strong></p><p><strong>在经典计算机中，信息的基本单元是比特（bit），只以 0 和 1 两种可能的形式存储信息。而在量子计算中，基本单元是量子比特（Qubit），它可以存储 0 和 1 的任何叠加状态（比如 64% 可能是 1，36% 可能是 0），使得量子计算在处理信息时拥有巨大的并行计算能力。</strong></p><p><strong>经典比特</strong> <strong>（1）表示为二进制状态（0 或 1），如开关的“开/关”；</strong></p><p><strong>（2）物理载体通常有晶体管的高低电压，磁盘的南北极磁化方向等；</strong></p><p><strong>（3）N 个经典比特只能存储 1 个 N 位状态。</strong></p><p><strong>量子比特</strong></p><p><strong>（1）可以表示为叠加态（α|0⟩ + β|1⟩），其中 α 和 β 是复数概率幅，满足 |α|^2 + |β|^2 = 1；</strong></p><p><strong>量子态特性</strong> <strong>（1）量子叠加</strong></p><p><strong>量子态可以是两个或多个不相容的经典态的叠加，比如 0 和 1 的叠加，这使得量子计算机可以指数级的并行处理加速。</strong></p><p><strong>数学描述</strong></p><p><strong>|ψ⟩ = α|0⟩ + β|1⟩</strong></p><p><strong>n 个量子比特：可同时表示 2^n 个状态</strong></p><h2 id="1-经典世界一条路一条路走"><a class="markdownIt-Anchor" href="#1-经典世界一条路一条路走"></a> 1. 经典世界：一条路一条路走</h2><p><strong>想象你在一个迷宫里找出口。</strong></p><ul><li><strong>经典计算机</strong>：只能一个人走一条路，看是不是出口。</li><li><strong>要把 <strong>2^n</strong> 条路都走一遍，就得派 <strong>2^n</strong> 个人，或者自己一条条慢慢试。</strong></li></ul><hr /><h2 id="2-量子世界所有路同时展开"><a class="markdownIt-Anchor" href="#2-量子世界所有路同时展开"></a> 2. 量子世界：所有路同时展开</h2><p><strong>量子比特有“叠加”特性。</strong></p><ul><li>**当你用 Hadamard 门准备一个量子态时，**<strong>它不是选一条路，而是进入所有路的叠加态</strong>。</li><li><strong>就好像“同一个人”能****分身成 <strong>2^n</strong> 个影子</strong>，每个影子走一条路。</li></ul><p><strong>数学上就是：</strong></p><p><strong>|0\rangle \xrightarrow{H} \frac{1}{\sqrt{2}}(|0\rangle + |1\rangle)</strong></p><p><strong>|00\rangle \xrightarrow{H\otimes H} \frac{1}{2}(|00\rangle+|01\rangle+|10\rangle+|11\rangle)</strong></p><hr /><h2 id="3-那么问题来了既然有分身为什么最后测量只看到一条路"><a class="markdownIt-Anchor" href="#3-那么问题来了既然有分身为什么最后测量只看到一条路"></a> 3. 那么问题来了：既然有分身，为什么最后测量只看到一条路？</h2><p><strong>因为量子分身之间****不是各自独立的影子</strong>，而是<strong>一首乐曲的不同音符</strong>。</p><ul><li><strong>当你对量子态施加运算，就像给每个音符同时加效果器。</strong></li><li><strong>最后乐曲会“干涉”，有些音符声音增强（正确答案），有些被抵消（错误答案）。</strong></li><li><strong>你测量时听到的“主旋律”就是概率最高的那部分。</strong></li></ul><p><strong>👉 所以量子计算的关键不是“同时算完所有答案”，而是****用干涉机制，把正确答案放大到能被测量出来</strong>。</p><hr /><h2 id="4-一个直观比喻"><a class="markdownIt-Anchor" href="#4-一个直观比喻"></a> 4. 一个直观比喻 🎨</h2><ul><li><strong>经典计算机：像手电筒，一次只能照亮一条路。</strong></li><li><strong>量子计算机：像激光干涉实验，所有路径的光都会叠加在一起。</strong><ul><li><strong>错误的路径 → 光波互相抵消。</strong></li><li><strong>正确的路径 → 光波相长，亮起来。</strong></li></ul></li></ul><p><strong>所以“并行”不是说你能读出所有 <strong>2^n</strong> 个结果，而是说：</strong> **👉 **<strong>在运算过程中，量子系统确实同时考虑了所有路径，并利用干涉让答案浮现出来。</strong></p><hr /><h2 id="5-你可以先抓住这一句话"><a class="markdownIt-Anchor" href="#5-你可以先抓住这一句话"></a> 5. 你可以先抓住这一句话</h2><p><strong>量子计算机不是一次性给你所有答案，而是能同时操作所有可能答案，并通过干涉让正确答案脱颖而出。</strong></p><hr /><p><strong>量子纠缠，这个是量子力学和量子计算的“神奇之处”，也是很多人第一次接触时最难理解的部分。我们分几个层次来拆解：</strong></p><hr /><h2 id="1-什么叫纠缠"><a class="markdownIt-Anchor" href="#1-什么叫纠缠"></a> 1. 什么叫纠缠？</h2><p>** 如果两个量子比特没有纠缠，那它们各自的状态可以独立写出来：**</p><p>**  **|\psi\rangle = |\psi_A\rangle \otimes |\psi_B\rangle</p><p>**  例如：** **  **|0\rangle_A \otimes |1\rangle_B = |01\rangle</p><p>** 但如果它们纠缠了，就不能这样分开写。比如：**</p><p>**  **|\Phi^+\rangle = \tfrac{1}{\sqrt{2}}(|00\rangle + |11\rangle)</p><p>**  这个状态就没法写成某个 <strong>|\psi_A\rangle \otimes |\psi_B\rangle</strong>。** **  也就是说：单独看 A 或单独看 B，都没办法描述清楚它们的状态，只有作为整体才能完整描述。**</p><hr /><h2 id="2-超距关联是什么意思"><a class="markdownIt-Anchor" href="#2-超距关联是什么意思"></a> 2. “超距关联”是什么意思？</h2><p><strong>假设 A 和 B 纠缠成：</strong></p><p><strong>|\Phi^+\rangle = \tfrac{1}{\sqrt{2}}(|00\rangle + |11\rangle)</strong></p><p>** 如果你测量 A 得到 0，那么 B 一定也是 0。** ** 如果你测量 A 得到 1，那么 B 一定也是 1。**</p><p><strong>无论 A 和 B 相距多远（哪怕一个在地球，一个在月球），这种相关性立刻成立。</strong> <strong>这就是爱因斯坦当年说的 “鬼魅般的远距作用”（spooky action at a distance）。</strong></p><p><strong>注意 ⚠️：这并不等于“超光速通信”。因为单独看 A 或 B，它们的结果是随机的（50% 0，50% 1），信息只能在测量后对比才显现。</strong></p><hr /><h2 id="3-为什么纠缠厉害"><a class="markdownIt-Anchor" href="#3-为什么纠缠厉害"></a> 3. 为什么纠缠厉害？</h2><p><strong>纠缠带来的特性，是经典系统没有的：</strong></p><ol><li><strong>非局域性：即使两个量子比特远隔千里，它们依然保持关联。</strong></li><li><strong>不可分割性：单个比特的状态不完整，必须整体描述。</strong></li><li><strong>量子并行性增强：纠缠让不同比特间的信息处理更高效，很多量子算法都依赖它。</strong></li></ol><hr /><h2 id="4-在量子信息中的应用"><a class="markdownIt-Anchor" href="#4-在量子信息中的应用"></a> 4. 在量子信息中的应用</h2><p>** 量子计算：很多量子算法（如 Shor 分解、Grover 搜索）需要纠缠态来进行高效计算。** ** 量子通信：量子隐形传态（quantum teleportation）就是靠纠缠把一个量子态从 A“搬运”到 B。** ** 量子安全：纠缠态的破坏很容易被检测，能用来保证量子密钥分发的安全。**</p><hr /><h2 id="5-类比帮助理解"><a class="markdownIt-Anchor" href="#5-类比帮助理解"></a> 5. 类比帮助理解</h2><p><strong>你可以这样想：</strong></p><p>** 经典关联：一对手套，一只放在袋子 A，一只放在袋子 B。打开袋子 A 看见左手套，就知道 B 里一定是右手套。** **  👉 这是普通的“相关性”。** ** 量子纠缠：不是手套，而是“神奇的手套对”。直到你打开 A 之前，它既是左手套又是右手套（叠加）。一旦你看见 A 是左，B 瞬间就确定是左；如果 A 是右，B 就是右。** **  👉 这种“结果同步”才是量子纠缠。**</p><hr /><p><strong>✅ 总结一句话：</strong> <strong>量子纠缠就是多个粒子的量子态无法分开描述，它们组成一个整体，不管相隔多远，测量结果都高度相关。这种性质是量子计算和量子通信的核心资源。</strong></p><hr /><hr /><h2 id="1-为什么需要张量积"><a class="markdownIt-Anchor" href="#1-为什么需要张量积"></a> 1. 为什么需要张量积？</h2><p>** 单个量子比特的状态可以用列向量表示：** **  <strong>|0\rangle = \begin{bmatrix}1\\0\end{bmatrix}, \quad |1\rangle = \begin{bmatrix}0\\1\end{bmatrix}</strong> ** 当有多个量子比特时，我们需要描述它们的联合状态。** ** 联合状态不是简单地把向量加在一起，而是用张量积（⊗）把它们拼起来。</p><hr /><h2 id="2-定义"><a class="markdownIt-Anchor" href="#2-定义"></a> 2. 定义</h2><p><strong>如果两个向量是：</strong></p><p><strong>|a\rangle = \begin{bmatrix}a_0\\a_1\end{bmatrix},\quad |b\rangle = \begin{bmatrix}b_0\\b_1\end{bmatrix}</strong></p><p><strong>它们的张量积是：</strong></p><p><strong>|a\rangle \otimes |b\rangle = \begin{bmatrix}a_0b_0\\ a_0b_1\\ a_1b_0\\ a_1b_1\end{bmatrix}.</strong></p><hr /><h2 id="3-举例"><a class="markdownIt-Anchor" href="#3-举例"></a> 3. 举例</h2><p>** 两个量子比特初始态：**|0\rangle \otimes |1\rangle</p><p><strong>|0\rangle \otimes |1\rangle = \begin{bmatrix}1\\0\end{bmatrix} \otimes \begin{bmatrix}0\\1\end{bmatrix} = \begin{bmatrix}0\\1\\0\\0\end{bmatrix} = |01\rangle</strong></p><p>** 三个量子比特：**|0\rangle \otimes |1\rangle \otimes |0\rangle</p><p><strong>= |010\rangle =  \begin{bmatrix}0\\0\\1\\0\\0\\0\\0\\0\end{bmatrix}</strong></p><p><strong>维度就是 <strong>2^3 = 8</strong>。</strong></p><hr /><h2 id="4-张量积的意义"><a class="markdownIt-Anchor" href="#4-张量积的意义"></a> 4. 张量积的意义</h2><ol><li><strong>多比特系统</strong><br />**n 个量子比特的状态空间就是 <strong>(\mathbb{C}<sup>2)</sup>{\otimes n}</strong>，维度 <strong>2^n</strong> **张量积把单比特空间扩展成多比特空间。</li><li><strong>可描述纠缠态</strong><br /><strong>并非所有张量积的状态都是可分的，有些态不能写成 <strong>|a\rangle \otimes |b\rangle</strong>，这就是纠缠态。</strong> <strong>例如 Bell 态：</strong> ** <strong>|\Phi^+\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)</strong> ** → 不能拆成两个独立的单比特张量积。</li><li><strong>量子操作扩展</strong><br /><strong>如果一个量子门作用在第一个比特上，它可以写成 <strong>U \otimes I \otimes I \cdots</strong>，通过张量积自然作用在多比特系统中。</strong></li></ol><hr /><h2 id="5-类比理解"><a class="markdownIt-Anchor" href="#5-类比理解"></a> 5. 类比理解</h2><p>** 单个比特 → 一条路** ** 张量积 → 多条路组合成超立方体** ** 张量积把每条单比特的“自由度”组合起来，得到一个指数级增长的空间 → 这就是为什么 n 个量子比特能同时表示 <strong>2^n</strong> 个状态。**</p><hr /><h2 id="1-贝尔态bell-state"><a class="markdownIt-Anchor" href="#1-贝尔态bell-state"></a> 1. 贝尔态（Bell state）</h2><p><strong>贝尔态是两个量子比特最简单、最标准的纠缠态。</strong> <strong>共有四种，最常见的是：</strong></p><p><strong>|\Phi^+\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)</strong></p><p><strong>|\Phi^-\rangle = \frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)</strong></p><p><strong>|\Psi^+\rangle = \frac{1}{\sqrt{2}}(|01\rangle + |10\rangle)</strong></p><p><strong>|\Psi^-\rangle = \frac{1}{\sqrt{2}}(|01\rangle - |10\rangle)</strong></p><h3 id="特点"><a class="markdownIt-Anchor" href="#特点"></a> 特点：</h3><ol><li><strong>纠缠态：不能拆成两个单独量子比特的张量积。</strong></li><li><strong>均匀叠加：两个基态的振幅相等，振幅的相位不同决定了不同贝尔态。</strong></li><li><strong>最大纠缠：它们的两比特关联性最强。</strong></li></ol><hr /><h2 id="2-非经典关联non-classical-correlation"><a class="markdownIt-Anchor" href="#2-非经典关联non-classical-correlation"></a> 2. 非经典关联（non-classical correlation）</h2><p>** 在经典物理中，两件事的关联通常可以解释为“事先约定”或者“局部因果”。** ** 贝尔态里，两个量子比特的关联无法用任何经典局部隐藏变量解释 → 非经典关联。** ** 例子：**|\Phi^+\rangle</p><p>**   测量第一个比特得到 0，第二个比特一定是 0** **   测量第一个比特得到 1，第二个比特一定是 1** ** 这种相关性比经典相关性更强，违反了贝尔不等式（Bell inequality）。**</p><hr /><h2 id="3-超距关联spooky-action-at-a-distance"><a class="markdownIt-Anchor" href="#3-超距关联spooky-action-at-a-distance"></a> 3. 超距关联（spooky action at a distance）</h2><p>** 两个纠缠量子比特即使相隔很远（米级、千里甚至更远），测量其中一个的结果会即时决定另一个的结果。** ** 这个现象叫做 超距关联。** ** 注意 ⚠️：这不意味着可以瞬间传信息，只是结果相关性立刻生效。单独看任意一个量子比特，它的结果仍然是随机的。**</p><hr /><h2 id="4-举个直观例子"><a class="markdownIt-Anchor" href="#4-举个直观例子"></a> 4. 举个直观例子</h2><p><strong>假设 Alice 和 Bob 各拿一个量子比特，初始状态是 <strong>|\Phi^+\rangle = (|00\rangle + |11\rangle)/\sqrt{2}</strong>：</strong></p><table><thead><tr><th><strong>ALICE 测量</strong></th><th><strong>BOB 测量</strong></th></tr></thead><tbody><tr><td><strong>0</strong></td><td><strong>0</strong></td></tr><tr><td><strong>1</strong></td><td><strong>1</strong></td></tr></tbody></table><p>** 非经典关联：这种 100% 相关性无法用“之前就决定好的结果”解释。** ** 超距关联：无论 Alice 和 Bob 相隔多远，测量瞬间就决定了对方的结果。**</p><hr /><h2 id="5-为什么重要"><a class="markdownIt-Anchor" href="#5-为什么重要"></a> 5. 为什么重要？</h2><ol><li><strong>量子通信：量子隐形传态（teleportation）依赖贝尔态。</strong></li><li><strong>量子密钥分发：纠缠态保证密钥的安全性。</strong></li><li><strong>量子计算：很多算法（Shor、Grover）依赖纠缠态来实现指数级并行。</strong></li></ol><hr /><p><strong>✅ 总结：</strong></p><p>** 贝尔态：两个比特的标准最大纠缠态** ** 非经典关联：关联不能被经典物理解释** ** 超距关联：量子比特之间的关联不受空间距离限制**</p><hr /><p><strong>好的，我们把你给出的****量子干涉</strong>和<strong>量子逻辑门</strong>用通俗的方式解释，让你能直观理解它们的作用。</p><hr /><h2 id="1️⃣-量子干涉quantum-interference"><a class="markdownIt-Anchor" href="#1️⃣-量子干涉quantum-interference"></a> 1️⃣ 量子干涉（Quantum Interference）</h2><h3 id="通俗理解"><a class="markdownIt-Anchor" href="#通俗理解"></a> 通俗理解</h3><ul><li><strong>想象水波或者光波，可以叠加。</strong></li><li><strong>相长干涉</strong>：波峰叠加波峰 → 波变高</li><li><strong>相消干涉</strong>：波峰叠加波谷 → 波抵消</li></ul><p><strong>在量子计算里：</strong></p><ul><li><strong>量子态的每个分量都有一个“振幅”</strong>，可以理解成波的高度和方向（正负号表示相位）。</li><li><strong>我们可以设计量子操作，让：</strong><ul><li><strong>正确答案的振幅加强</strong>（相长干涉）</li><li><strong>错误答案的振幅减弱或抵消</strong>（相消干涉）</li></ul></li></ul><p><strong>最终测量时：</strong></p><ul><li><strong>正确答案被“放大”，大概率被得到</strong></li><li><strong>错误答案被“抑制”，几乎不出现</strong></li></ul><p><strong>✅ 举例：Grover 搜索算法就是利用量子干涉，把搜索目标的概率放大到接近 1。</strong></p><hr /><h2 id="2️⃣-量子逻辑门quantum-logic-gates"><a class="markdownIt-Anchor" href="#2️⃣-量子逻辑门quantum-logic-gates"></a> 2️⃣ 量子逻辑门（Quantum Logic Gates）</h2><h3 id="通俗理解-2"><a class="markdownIt-Anchor" href="#通俗理解-2"></a> 通俗理解</h3><ul><li><strong>量子逻辑门就像****魔法开关</strong>，可以改变量子比特的状态。</li><li><strong>基本类型：</strong></li></ul><ol><li><strong>Hadamard 门（H）</strong><ul><li><strong>功能：把确定状态（0 或 1）变成****叠加态</strong></li><li><strong>比如：</strong> ** ∣0⟩→H∣0⟩+∣1⟩2|0\rangle \xrightarrow{H} \frac{|0\rangle + |1\rangle}{\sqrt{2}}** ** → 相当于同时“走 0 和 1 两条路”**</li></ul></li><li><strong>CNOT 门</strong><ul><li><strong>功能：根据控制比特（control qubit）决定是否翻转目标比特（target qubit）</strong></li><li><strong>例子：</strong><ul><li><strong>控制比特 0 → 目标比特不变</strong></li><li><strong>控制比特 1 → 目标比特翻转（0→1 或 1→0）</strong></li></ul></li><li>**用于产生 **<strong>纠缠态</strong>（比如贝尔态）</li></ul></li></ol><h3 id="组合使用"><a class="markdownIt-Anchor" href="#组合使用"></a> 组合使用</h3><ul><li><strong>多个量子逻辑门可以叠加使用</strong></li><li><strong>就像用积木搭成复杂机器，最终可以：</strong><ul><li><strong>制造叠加态</strong></li><li><strong>制造纠缠态</strong></li><li><strong>调整振幅（实现干涉）</strong></li></ul></li><li><strong>这样量子计算机就能执行复杂算法。</strong></li></ul><hr /><h3 id="总结一句话"><a class="markdownIt-Anchor" href="#总结一句话"></a> 🔑 总结一句话</h3><ul><li><strong>量子干涉</strong>：通过振幅相位叠加，把正确答案“放大”，错误答案“抵消”。</li><li><strong>量子逻辑门</strong>：操作量子比特，生成叠加态、纠缠态，并实现干涉。</li></ul><hr /><hr /><h2 id="1️⃣-门型量子计算机gate-based-quantum-computer"><a class="markdownIt-Anchor" href="#1️⃣-门型量子计算机gate-based-quantum-computer"></a> 1️⃣ 门型量子计算机（Gate-based Quantum Computer）</h2><ul><li><strong>原理</strong>：像经典计算机用逻辑门一样，量子计算机用**量子逻辑门（Hadamard、CNOT 等）**对量子比特进行操作。</li><li><strong>特点</strong>：<ol><li><strong>可实现任意量子算法（通用量子计算机就是门型的）</strong></li><li><strong>运算过程类似“搭积木”：把不同门按顺序组合，得到复杂量子电路</strong></li></ol></li><li><strong>典型应用</strong>：<ul><li><strong>Shor 因数分解</strong></li><li><strong>Grover 搜索</strong></li><li><strong>模拟量子系统</strong></li></ul></li><li><strong>优点</strong>：灵活，可通用</li><li><strong>缺点</strong>：对硬件要求高，容易出错，需要纠错</li></ul><p>**💡 类比：门型量子计算机 = **<strong>万能积木套装</strong>，你可以自由组合完成各种结构。</p><hr /><h2 id="2️⃣-非门型量子计算机non-gate-based-quantum-computer"><a class="markdownIt-Anchor" href="#2️⃣-非门型量子计算机non-gate-based-quantum-computer"></a> 2️⃣ 非门型量子计算机（Non-gate-based Quantum Computer）</h2><ul><li><strong>原理</strong>：不是通过逐个逻辑门操作，而是直接让量子系统通过自然演化找到问题的解。</li><li><strong>主要形式</strong>：量子退火（Quantum Annealing）<ul><li><strong>用于优化问题：把问题映射成量子系统能量最低的状态</strong></li><li><strong>系统自然演化到最低能量 → 得到最优解</strong></li></ul></li><li><strong>特点</strong>：<ol><li><strong>针对特定问题高效</strong></li><li><strong>硬件结构相对简单，可以做更多比特</strong></li><li><strong>不适合通用算法（无法实现任意量子逻辑门）</strong></li></ol></li></ul><p>**💡 类比：非门型量子计算机 = **<strong>滑坡式解题机器</strong>，把问题放上去，自然滚下来找到最优解，但不能随便改造解决其他问题。</p><hr /><h2 id="3️⃣-对比表"><a class="markdownIt-Anchor" href="#3️⃣-对比表"></a> 3️⃣ 对比表</h2><table><thead><tr><th><strong>特性</strong></th><th><strong>门型（GATE-BASED）</strong></th><th><strong>非门型（NON-GATE-BASED）</strong></th></tr></thead><tbody><tr><td><strong>算法范围</strong></td><td><strong>任意量子算法</strong></td><td><strong>特定问题（优化、退火）</strong></td></tr><tr><td><strong>运算方式</strong></td><td><strong>量子逻辑门操作</strong></td><td><strong>系统自然演化</strong></td></tr><tr><td><strong>灵活性</strong></td><td><strong>高</strong></td><td><strong>低</strong></td></tr><tr><td><strong>硬件难度</strong></td><td><strong>高</strong></td><td><strong>相对低</strong></td></tr><tr><td><strong>应用示例</strong></td><td><strong>Shor、Grover、量子模拟</strong></td><td><strong>组合优化、机器学习、量子退火</strong></td></tr></tbody></table><hr /><h3 id="核心理解"><a class="markdownIt-Anchor" href="#核心理解"></a> 🔑 核心理解</h3><ul><li><strong>门型 = 积木式自由组合 → 通用量子计算机</strong></li><li><strong>非门型 = 系统自然演化 → 专用量子计算机（退火类）</strong></li></ul><hr />]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;1.1 量子计算原理&lt;/strong&gt; &lt;strong&gt;量子比特概念介绍&lt;/strong&gt; &lt;strong&gt;量子计算是一种基于量子力学基本原理的信息处理范式，它利用量子叠加、量子纠缠和量子干涉等现象，解决经典计算机无法高效处理的问题。&lt;/strong&gt;&lt;/p</summary>
      
    
    
    
    <category term="开源项目" scheme="https://zjncs.github.io/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>llm前置知识-RNN</title>
    <link href="https://zjncs.github.io/2025/08/18/llm%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86-RNN/"/>
    <id>https://zjncs.github.io/2025/08/18/llm%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86-RNN/</id>
    <published>2025-08-18T08:44:31.000Z</published>
    <updated>2025-08-18T08:44:35.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>循环神经网络（Rerrent Neural Network, RNN）</strong></p><p>**是神经网络的一种，****RNN 对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息，**利用了 RNN 的这种能力，使深度学习模型在解决语音识别、语言模型、机器翻译以及时序分析等 NLP 领域的问题时有所突破。</p><h4 id="a-挖掘时序信息-mining-temporal-information"><a class="markdownIt-Anchor" href="#a-挖掘时序信息-mining-temporal-information"></a> <strong>A. 挖掘“时序信息” (Mining Temporal Information)</strong></h4><p><strong>这指的是 RNN 处理数据****顺序</strong>的能力。传统的神经网络（如全连接网络）在处理输入时，通常不考虑元素的顺序。例如，对于句子“我打你”和“你打我”，传统网络可能会得到相似的表示，因为它忽略了词序。</p><p><strong>RNN 通过其独特的****循环结构</strong>解决了这个问题：</p><ul><li><strong>链式处理</strong>：RNN 像人阅读一样，一个词一个词地处理序列。<br /><strong>隐藏状态（记忆）</strong>：RNN 的核心是一个“隐藏状态”（Hidden State），可以看作是网络的记忆。在处理序列的每一步，RNN 都会将当前的输入信息和<strong>上一步的记忆</strong>结合起来，形成新的记忆，然后传递给下一步 。</li></ul><p><strong>简单来说</strong>，当 RNN 处理到“你”这个词时，它的记忆里已经包含了“我”和“打”的信息。这种“先处理了 A，再处理 B”的机制，就是它挖掘时序信息的方式。</p><h4 id="b-挖掘语义信息-mining-semantic-information"><a class="markdownIt-Anchor" href="#b-挖掘语义信息-mining-semantic-information"></a> <strong>B. 挖掘“语义信息” (Mining Semantic Information)</strong></h4><p><strong>语言的语义（含义）与语序密切相关。正是因为 RNN 能够捕捉到时序信息，它才能更好地理解语义。</strong></p><ul><li><strong>上下文决定意义</strong>：一个词的真正含义取决于它的上下文。例如，“bank”在“river bank”（河岸）和“investment bank”（投资银行）中的意思完全不同。</li><li><strong>构建上下文表示</strong>：RNN 通过一步步处理序列，其隐藏状态会不断累积和更新整个句子的上下文信息。处理完整个句子后，RNN 最终的隐藏状态就相当于对整个句子语义的<strong>概括和编码</strong>。这个包含了丰富上下文信息的向量，就是对句子语义的深度表示。</li></ul><h2 id="二为什么要发明循环神经网络"><a class="markdownIt-Anchor" href="#二为什么要发明循环神经网络"></a> <strong>二.为什么要发明循环神经网络：</strong></h2><p><strong>我们先来看一个 NLP 很常见的问题，</strong><a href="https://zhida.zhihu.com/search?content_id=115510247&amp;content_type=Article&amp;match_order=1&amp;q=%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;zhida_source=entity">命名实体识别</a>，举个例子，现在有两句话：</p><p><strong>第一句话：I like eating apple！（我喜欢吃苹果！）</strong></p><p><strong>第二句话：The Apple is a great company！（苹果真是一家很棒的公司！）</strong></p><p>**现在的任务是要给 apple 打 Label，我们都知道第一个 apple 是一种水果，第二个 apple 是苹果公司，假设我们现在有大量的已经标记好的数据以供训练模型，当我们使用全连接的神经网络时，我们做法是把 apple 这个单词的特征向量输入到我们的模型中（如下图），在输出结果时，让我们的 label 里，正确的 label 概率最大，来训练模型，但我们的语料库中，有的 apple 的 label 是水果，有的 label 是公司，这将导致，模型在训练的过程中，预测的准确程度，取决于训练集中哪个 label 多一些，这样的模型对于我们来说完全没有作用。**<strong>问题就出在了我们没有结合上下文去训练模型，而是单独的在训练 apple 这个单词的 label，这也是全连接神经网络模型所不能做到的，于是就有了我们的循环神经网络。</strong></p><p><img src="https://pic1.zhimg.com/v2-9a86430ba17aa299ce5c44c7b75c5ece_1440w.jpg" alt="img" /></p><h2 id="三-循环神经网络的结构及原理"><a class="markdownIt-Anchor" href="#三-循环神经网络的结构及原理"></a> <strong>三。循环神经网络的结构及原理：</strong></h2><p><img src="https://pica.zhimg.com/v2-8f534b5db1f3d8a5c4ccd029be4a15b4_1440w.jpg" alt="img" /></p><p><strong>我们先来讲解一下上面这幅图，首先不要管右边的 W，只看 X,U,S,V,O，这幅图就变成了，如下：</strong></p><p><img src="https://pic1.zhimg.com/v2-9a86430ba17aa299ce5c44c7b75c5ece_1440w.jpg" alt="img" /></p><p><strong>等等，这图看着有点眼熟啊，这不就是全连接神经网络结构吗？对，没错，不看 W 的话，上面那幅图展开就是全连接神经网络，</strong></p><p><strong>其中 X 是一个向量，也就是某个字或词的特征向量，作为输入层，如上图也就是 3 维向量，U 是输入层到隐藏层的参数矩阵，在上图中其维度就是 3X4，S 是隐藏层的向量，如上图维度就是 4，V 是隐藏层到输出层的参数矩阵，在上图中就是 4X2，O 是输出层的向量，在上图中维度为 2</strong><img src="https://pic2.zhimg.com/v2-8abf977157000e6dad8589ec60ed6c3f_1440w.jpg" alt="img" /></p><p><img src="https://picx.zhimg.com/v2-9524a28210c98ed130644eb3c3002087_1440w.jpg" alt="img" /></p><p><strong>值得注意的一点是，在整个训练过程中，每一时刻所用的都是同样的 W。</strong></p><p><strong>x1 → h1 → y1</strong> <strong>x2 → h2 → y2</strong> <strong>x3 → h3 → y3</strong></p><p><strong>每个隐藏状态 <strong>h_t</strong> 不仅依赖当前输入 <strong>x_t</strong>，还依赖上一时刻的隐藏状态 <strong>h_{t-1}</strong>。</strong></p><p><strong>权重矩阵在每个时间步都是共享的，例如：</strong></p><ul><li><strong>W_{xh}</strong>：输入到隐藏层</li><li><strong>W_{hh}</strong>：隐藏层到隐藏层</li><li><strong>W_{hy}</strong>：隐藏层到输出层</li></ul><h2 id="3-rnn-的公式"><a class="markdownIt-Anchor" href="#3-rnn-的公式"></a> 3. RNN 的公式</h2><p><strong>每个时间步的计算公式如下：</strong></p><p><strong>隐藏状态更新：</strong> <strong>h_t = f(W_{xh} x_t + W_{hh} h_{t-1} + b_h)</strong></p><p><strong>输出计算：</strong> <strong>y_t = g(W_{hy} h_t + b_y)</strong></p><ul><li><strong>f</strong> 通常是 tanh 或 ReLU</li><li><strong>g</strong> 通常是 softmax（用于分类，如 NER 标签）</li></ul><h2 id="4-举例对应到-i-love-you"><a class="markdownIt-Anchor" href="#4-举例对应到-i-love-you"></a> 4. 举例对应到 “I love you”</h2><table><thead><tr><th><strong>时间步</strong>t</th><th><strong>输入</strong>x_t</th><th><strong>上一隐藏状态</strong>h_{t-1}</th><th><strong>当前隐藏状态</strong>h_t</th><th><strong>输出</strong>y_t</th></tr></thead><tbody><tr><td><strong>1</strong></td><td><strong>I</strong></td><td><strong>h_0</strong>（初始化为 0）</td><td><strong>h_1</strong></td><td><strong>y_1</strong></td></tr><tr><td><strong>2</strong></td><td><strong>love</strong></td><td><strong>h_1</strong></td><td><strong>h_2</strong></td><td><strong>y_2</strong></td></tr><tr><td><strong>3</strong></td><td><strong>you</strong></td><td><strong>h_2</strong></td><td><strong>h_3</strong></td><td><strong>y_3</strong></td></tr></tbody></table><p><strong>输出 <strong>y_t</strong> 可以预测每个单词的实体标签，如 O（非实体）、PER（人名）、LOC（地点）等。</strong></p><p><strong>每个 <strong>h_t</strong> 都 “记住” 了到目前为止的序列信息，所以 RNN 可以捕捉前后文依赖。</strong></p><h2 id="四-举个例子方便理解"><a class="markdownIt-Anchor" href="#四-举个例子方便理解"></a> <strong>四。举个例子，方便理解：</strong></h2><p><strong>假设现在我们已经训练好了一个 RNN，如图，我们假设每个单词的特征向量是二维的，也就是输入层的维度是二维，且隐藏层也假设是二维，输出也假设是二维，所有权重的值都为 1 且没有偏差且所有激活函数都是线性函数，现在输入一个序列，到该模型中，我们来一步步求解出输出序列：</strong></p><p><img src="https://picx.zhimg.com/v2-09ce45f29378cb2695b3b4fcd2015047_1440w.png" alt="img" /></p><p><strong>W 在实际的计算中，在图像中表示非常困难 ，所以我们可以想象上一时刻的隐藏层的值是被存起来，等下一时刻的隐藏层进来时，上一时刻的隐藏层的值通过与权重相乘，两者相加便得到了下一时刻真正的隐藏层</strong></p><p><strong>a_1</strong>与<strong>a_2</strong>的值初始值都是 0，可以作为每一时刻存下来的值，所以我们可以得到：<img src="https://picx.zhimg.com/v2-2c3522b9d250a44cfaeddecbcd139275_1440w.jpg" alt="img" /></p><p><strong>当我们输入第一个序列，【1,1】，如下图，其中隐藏层的值，也就是绿色神经元，是通过公式 <strong>S_t = f(U \cdot X_t + W \cdot S_{t-1})</strong> 计算得到的。因为所有权重都是 1，所以也就是 <strong>1 \cdot 1 + 1 \cdot 1 + 1 \cdot 0 + 1 \cdot 0 = 2</strong>（我把向量 X 拆开计算的，由于篇幅关系，我只详细列了其中一个神经元的计算过程，希望大家可以看懂，看不懂的请留言），输出层的值 4 是通过公式 <strong>O_t = g(V \cdot S_t)</strong> 计算得到的，也就是 <strong>2 \cdot 1 + 2 \cdot 1 = 4</strong>（同上，也是只举例其中一个神经元），得到输出向量【4,4】：</strong></p><hr /><p><img src="https://pic2.zhimg.com/v2-c01a8a5c476aa2bd189965aa149d9e85_1440w.jpg" alt="img" /></p><h2 id="当11输入过后我们的记忆里的-a1a2-已经不是-0-了而是把这一时刻的隐藏状态放在里面即变成了-2如图输入下一个向量11隐藏层的值通过公式-s_t-fu-cdot-x_t-w-cdot-s_-t-1-得到1-times-1-1-times-1-1-times-2-1-times-2-6输出层的值通过公式-o_t-gv-cdot-s_t-得到6-times-1-6-times-1-12最终得到输出向量1212"><a class="markdownIt-Anchor" href="#当11输入过后我们的记忆里的-a1a2-已经不是-0-了而是把这一时刻的隐藏状态放在里面即变成了-2如图输入下一个向量11隐藏层的值通过公式-s_t-fu-cdot-x_t-w-cdot-s_-t-1-得到1-times-1-1-times-1-1-times-2-1-times-2-6输出层的值通过公式-o_t-gv-cdot-s_t-得到6-times-1-6-times-1-12最终得到输出向量1212"></a> 当【1,1】输入过后，我们的记忆里的 (a1,a2) 已经不是 0 了，而是把这一时刻的隐藏状态放在里面，即变成了 2；如图，输入下一个向量【1,1】，隐藏层的值通过公式 <strong>S_t = f(U \cdot X_t + W \cdot S_ {t-1})</strong> 得到，<strong>1 \times 1 + 1 \times 1 + 1 \times 2 + 1 \times 2 = 6</strong>；输出层的值通过公式 <strong>O_t = g(V \cdot S_t)</strong> 得到，<strong>6 \times 1 + 6 \times 1 = 12</strong>，最终得到输出向量【12,12】</h2><p><img src="https://pic2.zhimg.com/v2-5170c41f0285a718b890979e125832ed_1440w.jpg" alt="img" /></p><p><strong>同理，该时刻过后值变成了 6，也就是输入第二个【1,1】过后所存下来的值，同理，输入第三个向量【2,2】，如图，细节过程不再描述，得到输出向量【32,32】：</strong></p><p><img src="https://pica.zhimg.com/v2-7ba6fd916892a89211b5ee6a5940d2b2_1440w.jpg" alt="img" /></p><p><strong>由此，我们得到了最终的输出序列为：</strong></p><p><img src="https://picx.zhimg.com/v2-e21cfad47c16012c38d2acd9c75039d7_1440w.jpg" alt="img" /></p><p><strong>至此，一个完整的 RNN 结构我们已经经历了一遍，我们注意到，每一时刻的输出结果都与上一时刻的输入有着非常大的关系，如果我们将输入序列换个顺序，那么我们得到的结果也将是截然不同，这就是 RNN 的特性，可以处理序列数据，同时对序列也很敏感</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;循环神经网络（Rerrent Neural Network, RNN）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**是神经网络的一种，****RNN 对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息，**利用了 RNN 的这种能力，使深度学习模型在</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
    <category term="论文" scheme="https://zjncs.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>llm神经网络深度学习</title>
    <link href="https://zjncs.github.io/2025/08/18/llm%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>https://zjncs.github.io/2025/08/18/llm%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-08-18T07:21:41.000Z</published>
    <updated>2025-08-18T07:22:03.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这个自由层的节点数呢？目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。这种方法又叫做 Grid Search（网格搜索）。</strong></p><p>**　　了解了两层神经网络的结构以后，我们就可以看懂其它类似的结构图。例如 EasyPR 字符识别网络架构（下图）。**<img src="https://i-blog.csdnimg.cn/blog_migrate/1d3e42d157b2d6714982495a97feb882.png" alt="img" /></p><p><strong>下面简单介绍一下两层神经网络的训练。</strong></p><p>**　　在 Rosenblat 提出的感知器模型中，模型中的参数可以被训练，但是使用的方法较为简单，并没有使用目前机器学习中通用的方法，这导致其扩展性与适用性非常有限。从两层神经网络开始，神经网络的研究人员开始使用机器学习相关的技术进行神经网络的训练。例如用大量的数据（1000-10000 左右），使用算法进行优化等等，从而使得模型训练可以获得性能与数据利用上的双重优势。**</p><p>**　　机器学习模型训练的目的，就是使得参数尽可能的与真实的模型逼近。具体做法是这样的。首先给所有参数赋上随机值。我们使用这些随机生成的参数值，来预测训练数据中的样本。样本的预测目标为 yp，真实目标为 y。那么，定义一个值 loss，计算公式如下。**</p><p><strong>loss = (yp - y)2</strong></p><p>**　　这个值称之为****损失**（loss），我们的目标就是使对所有训练数据的损失和尽可能的小。</p><p><strong>如果将先前的神经网络预测的矩阵公式带入到 yp 中（因为有 z=yp），那么我们可以把损失写为关于参数（parameter）的函数，这个函数称之为****损失函数</strong>（loss function）。下面的问题就是求：如何优化参数，能够让损失函数的值最小。</p><p>**　　此时这个问题就被转化为一个优化问题。一个常用方法就是高等数学中的求导，但是这里的问题由于参数不止一个，求导后计算导数等于 0 的运算量很大，所以一般来说解决这个优化问题使用的是****梯度下降**算法。</p><p>**梯度下降就是顺着函数 **<strong>下降最快的方向</strong>（即梯度的反方向）一步步走，直到找到函数的最低点（局部最小值或全局最小值）。</p><hr /><h3 id="二-基本思想"><a class="markdownIt-Anchor" href="#二-基本思想"></a> 二、基本思想</h3><p><strong>假设有一个损失函数 J(θ)J(\theta)J(θ)，其中 θ\thetaθ 表示模型的参数。</strong> ** 我们想要找到使损失函数最小的参数 θ\thetaθ。**</p><p><strong>迭代公式为：</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818143508053.png" alt="image-20250818143508053" /></p><p>**意思就是：**<strong>更新参数 θ 为 旧的 θ 减去学习率乘以梯度</strong>。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818143717968.png" alt="image-20250818143717968" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818143819978.png" alt="image-20250818143819978" /></p><p><strong>梯度下降算法每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。</strong></p><p><strong>在神经网络模型中，由于结构复杂，每次计算梯度的代价很大。因此还需要使用****反向传播</strong>算法。反向传播算法是利用了神经网络的结构进行的计算。不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。</p><p>**　　反向传播算法可以直观的理解为下图。梯度的计算从后往前，一层层反向传播。前缀 E 代表着相对导数的意思。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/1b3510e880dd4843ae54ca80ff0adb0a.png" alt="img" /></p><p><strong>反向传播（Backpropagation, BP）算法</strong></p><p><strong>在神经网络里高效计算梯度的方法</strong>。** ** 可以说：</p><ul><li><strong>梯度下降</strong> 是“怎么走路” → 不断沿着梯度的反方向更新参数。</li><li><strong>反向传播</strong> 是“怎么找到路” → 在复杂的神经网络里快速算出梯度。</li></ul><p><strong>在神经网络里，参数非常多（权重 www、偏置 bbb）。</strong> ** 我们需要知道每个参数对 <strong><strong>损失函数</strong> 的影响（即梯度），才能用梯度下降更新参数。</strong> ** 反向传播就是用 <strong>链式法则</strong> 把误差从输出层一步步传回输入层，计算所有参数的梯度。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818144205043.png" alt="image-20250818144205043" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818144253384.png" alt="image-20250818144253384" /></p><p><strong>反向传播算法的启示是数学中的****链式法则</strong>。在此需要说明的是，尽管早期神经网络的研究人员努力从生物学中得到启发，但从 BP 算法开始，研究者们更多地从数学上寻求问题的最优解。不再盲目模拟人脑网络是神经网络研究走向成熟的标志。正如科学家们可以从鸟类的飞行中得到启发，但没有必要一定要完全模拟鸟类的飞行方式，也能制造可以飞天的飞机。</p><p>**　　优化问题只是训练中的一个部分。机器学习问题之所以称为学习问题，而不是优化问题，就是因为它不仅要求数据在训练集上求得一个较小的误差，在测试集上也要表现好。**</p><p><strong>因为模型最终是要部署到没有见过训练数据的真实场景。提升模型在测试集上的预测效果的主题叫做****泛化</strong>（generalization），相关方法被称作正则化（regularization）。神经网络中常用的泛化技术有<strong>权重衰减</strong>等。</p><h2 id="泛化generalization"><a class="markdownIt-Anchor" href="#泛化generalization"></a> 泛化（Generalization）</h2><ul><li><strong>问题背景</strong>：我们训练模型的时候，模型是接触到训练数据的。但模型最终要应用在“没见过的新数据”上，比如测试集或真实环境的数据。</li><li><strong>泛化能力</strong>：指模型在新数据上的预测效果。如果一个模型在训练集上表现很好，但在测试集上表现很差，就说明 <strong>泛化能力差（过拟合）</strong>。</li></ul><p><strong>👉 所以目标是：不仅要在训练集上学得好，还要在测试集、真实环境中表现好。</strong></p><h2 id="正则化regularization"><a class="markdownIt-Anchor" href="#正则化regularization"></a> 正则化（Regularization）</h2><ul><li><strong>概念</strong>：正则化就是一类方法，用来提升模型的泛化能力，避免过拟合。</li><li><strong>为什么过拟合</strong>：当神经网络参数太多时，它可能会“死记硬背”训练数据，而不是学到真正有用的规律。</li><li><strong>正则化的作用</strong>：通过“限制模型的复杂度”或“增加训练时的约束”，让模型学到更稳定的规律，而不是死记硬背。</li></ul><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818144807879.png" alt="image-20250818144807879" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818145158283.png" alt="image-20250818145158283" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818145229147.png" alt="image-20250818145229147" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818145248395.png" alt="image-20250818145248395" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818151116266.png" alt="image-20250818151116266" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250818151133957.png" alt="image-20250818151133957" /></p><p><strong>在被人摒弃的 10 年中，有几个学者仍然在坚持研究。这其中的棋手就是加拿大多伦多大学的 Geoffery Hinton 教授。</strong></p><p>**　　2006 年，Hinton 在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念。与传统的训练方式不同，“深度信念网络”有一个“**<strong>预训练</strong>”（pre-training）的过程，这可以方便的让神经网络中的权值找到一个接近最优解的值，之后再使用“<strong>微调</strong>”(fine-tuning)技术来对整个网络进行优化训练。这两个技术的运用大幅度减少了训练多层神经网络的时间。他给多层神经网络相关的学习方法赋予了一个新名词–“<strong>深度学习</strong>”。</p><p>** 　很快，深度学习在语音识别领域暂露头角。接着，2012 年，深度学习技术又在图像识别领域大展拳脚。Hinton 与他的学生在 ImageNet 竞赛中，用多层的卷积神经网络成功地对包含一千类别的一百万张图片进行了训练，取得了分类错误率 15% 的好成绩，这个成绩比第二名高了近 11 个百分点，充分证明了多层神经网络识别效果的优越性。**</p><p>**　　在这之后，关于深度神经网络的研究与应用不断涌现。**</p><p><strong>我们延续两层神经网络的方式来设计一个多层神经网络。</strong></p><p>**　　在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/446beb41a6c3180cbac3b9907e1d00b2.png" alt="img" /></p><p><strong>多层神经网络中，输出也是按照一层一层的方式来计算。从最外面的层开始，算出所有单元的值以后，再继续计算更深一层。只有当前层所有单元的值都计算完毕以后，才会算下一层。有点像计算向前不断推进的感觉。所以这个过程叫做“正向传播”。</strong></p><p>**　　下面讨论一下多层神经网络中的参数。**</p><p>**　　首先我们看第一张图，可以看出****W**(1)中有 6 个参数，<strong>W</strong>(2)中有 4 个参数，<strong>W</strong>(3)中有 6 个参数，所以整个神经网络中的参数有 16 个（这里我们不考虑偏置节点，下同）。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/5b22532fd29fc20b299488fa55e22890.png" alt="img" /></p><p><strong>假设我们将中间层的节点数做一下调整。第一个中间层改为 3 个单元，第二个中间层改为 4 个单元。</strong></p><p>**　　经过调整以后，整个网络的参数变成了 33 个。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/66c2a2d5e23e80feed37dd9ae11bc2dd.png" alt="img" /></p><p><strong>虽然层数保持不变，但是第二个神经网络的参数数量却是第一个神经网络的接近两倍之多，从而带来了更好的表示（represention）能力。表示能力是多层神经网络的一个重要性质，下面会做介绍。</strong></p><p>**　　在参数一致的情况下，我们也可以获得一个“更深”的网络。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/24a14120a978e9a49ce2b0a9de6ba895.png" alt="img" /></p><p><strong>图 33 多层神经网络（更深的层次）</strong></p><hr /><p>**　　上图的网络中，虽然参数数量仍然是 33，但却有 4 个中间层，是原来层数的接近两倍。这意味着一样的参数数量，可以用更深的层次去表达。**</p><p>**　　**<strong>3.效果</strong></p><p>**　　与两层层神经网络不同。多层神经网络中的层数增加了很多。**</p><p>**　　增加更多的层次有什么好处？更深入的表示特征，以及更强的函数模拟能力。**</p><p>**　　更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。**</p><p>**　　关于逐层特征学习的例子，可以参考下图。**<img src="https://i-blog.csdnimg.cn/blog_migrate/f10bcb5f682714d1b388506514784550.png" alt="img" /></p><p><strong>在单层神经网络时，我们使用的激活函数是 sgn 函数。到了两层神经网络时，我们使用的最多的是 sigmoid 函数。而到了多层神经网络时，通过一系列的研究发现，ReLU 函数在训练多层神经网络时，更容易收敛，并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是 ReLU 函数。ReLU 函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是 y=max(x,0)。简而言之，在 x 大于 0，输出就是输入，而在 x 小于 0 时，输出就保持为 0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。</strong></p><p>**　　在多层神经网络中，训练的主题仍然是优化和泛化。当使用足够强的计算芯片（例如 GPU 图形加速卡）时，梯度下降算法以及反向传播算法在多层神经网络中的训练中仍然工作的很好。目前学术界主要的研究既在于开发新的算法，也在于对这两个算法进行不断的优化，例如，增加了一种带动量因子（momentum）的梯度下降算法。　**</p><p>**　　在深度学习中，泛化技术变的比以往更加的重要。这主要是因为神经网络的层数增加了，参数也增加了，表示能力大幅度增强，很容易出现****过拟合现象**。因此正则化技术就显得十分重要。目前，Dropout 技术，以及数据扩容（Data-Augmentation）技术是目前使用的最多的正则化技术。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
    <category term="论文" scheme="https://zjncs.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>llm-神经网络</title>
    <link href="https://zjncs.github.io/2025/08/14/llm-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://zjncs.github.io/2025/08/14/llm-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2025-08-14T05:47:33.000Z</published>
    <updated>2025-08-14T05:47:42.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>由于实习等一系列事情，leetcode 更新暂时延缓，只保留每日刷一道题，知识点学习暂且搁置</strong></p><p><strong>下面是 llm 前置知识，在这部分结束后，我将更新经典论文阅读。</strong></p><p><strong>神经网络：</strong></p><p><strong>让我们来看一个经典的神经网络。这是一个包含三个层次的神经网络。红色的是****输入层</strong>，绿色的是<strong>输出层</strong>，紫色的是<strong>中间层</strong>（也叫<strong>隐藏层</strong>）。输入层有 3 个输入单元，隐藏层有 4 个单元，输出层有 2 个单元。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/ec01486fd81a42733d3acef52a95c907.png" alt="img" /></p><p><strong>在开始介绍前，有一些知识可以先记在心里：</strong></p><ol><li><strong>设计一个神经网络时，输入层与输出层的节点数往往是固定的，中间层则可以自由指定；</strong></li><li><strong>神经网络结构图中的拓扑与箭头代表着****预测</strong>过程时数据的流向，跟<strong>训练</strong>时的数据流有一定的区别；</li><li><strong>结构图里的关键不是圆圈（代表“神经元”），而是连接线（代表“神经元”之间的连接）。每个连接线对应一个不同的****权重</strong>（其值称为<strong>权值</strong>），这是需要训练得到的。</li></ol><p><strong>除了从左到右的形式表达的结构图，还有一种常见的表达形式是从下到上来表示一个神经网络。这时候，输入层在图的最下方。输出层则在图的最上方，如下图：</strong></p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/b65bc032792c3cc4e8949dc2b066ac93.png" alt="img" /></p><p><strong>神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。</strong></p><p>**　　下图是一个典型的神经元模型：包含有 3 个输入，1 个输出，以及 2 个计算功能。**</p><p>**　　注意中间的箭头线。这些线称为“连接”。每个上有一个“权值”。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/75b9760fdd6dc27daf143454b9749fd1.png" alt="img" /></p><p>**图 6 神经元模型 **</p><p>**　　连接是神经元中最重要的东西。每一个连接上都有一个权重。**</p><p>**　　一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。**</p><p>**　　我们使用 a 来表示输入，用 w 来表示权值。一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是 a，端中间有加权参数 w，经过这个加权后的信号会变成 a***<strong>w，因此在连接的末端，信号的大小就变成了 a*w。</strong></p><p><strong>如果我们将神经元图中的所有变量用符号表示，并且写出输出的计算公式的话，就是下图。</strong></p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/5edde0590ebecbb366852259ce371054.png" alt="img" /></p><p><strong>可见 z 是在输入和权值的线性加权和叠加了一个****函数 g</strong> 的值。在 MP 模型里，函数 g 是 sgn 函数，也就是取符号函数。这个函数当输入大于 0 时，输出 1，否则输出 0。</p><p><strong>下面对神经元模型的图进行一些扩展。首先将 sum 函数与 sgn 函数合并到一个圆圈里，代表神经元的内部计算。其次，把输入 a 与输出 z 写到连接线的左上方，便于后面画复杂的网络。最后说明，一个神经元可以引出多个代表输出的有向箭头，但值都是一样的。</strong></p><p>**　　神经元可以看作一个计算与存储单元。计算是神经元对其的输入进行计算功能。存储是神经元会暂存计算结果，并传递到下一层。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/1159ca7927d03a090e353bf2377deb02.png" alt="img" /></p><p>**图 9 神经元扩展 **</p><p><strong>神经元模型的使用可以这样理解：</strong></p><p>**　　我们有一个数据，称之为样本。样本有四个属性，其中三个属性已知，一个属性未知。我们需要做的就是通过三个已知属性****预测**未知属性。</p><p>**　　具体办法就是使用神经元的公式进行计算。三个已知属性的值是 a1，a2，a3，未知属性的值是 z。z 可以通过公式计算出来。**</p><p>**　　这里，已知的属性称之为****特征**，未知的属性称之为<strong>目标</strong>。假设特征与目标之间确实是线性关系，并且我们已经得到表示这个关系的权值 w1，w2，w3。那么，我们就可以通过神经元模型预测新样本的目标。</p><p><strong>这里虽然简单，但已经建立了神经网络大厦的地基。但是，MP 模型中，权重的值都是预先设置的，因此不能学习。</strong></p><p><strong>单层神经网络（感知机）</strong></p><p>**　在原来 MP 模型的“输入”位置添加神经元节点，标志其为“输入单元”。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/938b7c669240a4250c46f46cde645aab.png" alt="img" /></p><p><strong>在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。</strong></p><p><strong>我们把需要计算的层次称之为“计算层”，并把拥有一个计算层的网络称之为“单层神经网络”。我们根据计算层的数量来命名。</strong></p><p><strong>因此感知机是单层神经网络。</strong></p><p><strong>假如我们要预测的目标不再是一个值，而是一个向量，例如[2,3]。那么可以在输出层再增加一个“输出单元”。</strong></p><p>**　　下图显示了带有两个输出单元的单层神经网络，其中输出单元 z1 的计算公式如下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/53c8c4855619cd0dc1515864c7eb00fe.png" alt="img" /></p><p><strong>图 13 单层神经网络(Z1)</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814110911355.png" alt="image-20250814110911355" /></p><p><strong>可以看到，z2 的计算中除了三个新的权值：w4，w5，w6 以外，其他与 z1 是一样的。</strong></p><p>**　　整个网络的输出如下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/24e9956cc367ed4e8d21d8d39394ec2a.png" alt="img" /></p><p><strong>图 15 单层神经网络(Z1 和 Z2)</strong></p><p>**　　目前的表达公式有一点不让人满意的就是：w4，w5，w6 是后来加的，很难表现出跟原先的 w1，w2，w3 的关系。**</p><p><strong>目前的表达公式有一点不让人满意的就是：w4，w5，w6 是后来加的，很难表现出跟原先的 w1，w2，w3 的关系。</strong></p><p>**　　因此我们改用二维的下标，用 wx,y 来表达一个权值。下标中的 x 代表后一层神经元的序号，而 y 代表前一层神经元的序号（序号的顺序从上到下）。**</p><p>**　　例如，w1,2 代表后一层的第 1 个神经元与前一层的第 2 个神经元的连接的权值（这种标记方式参照了 Andrew Ng 的课件）。根据以上方法标记，我们有了下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/8d37f29e30331a1367b9c4156f9ba1a9.png" alt="img" /></p><p><strong>图 16 单层神经网络(扩展)</strong></p><p>** 如果我们仔细看输出的计算公式，会发现这两个公式就是线性代数方程组。因此可以用矩阵乘法来表达这两个公式。**</p><p>**　　例如，输入的变量是[a1，a2，a3]T（代表由 a1，a2，a3 组成的列向量），用向量****a** 来表示。方程的左边是[z1，z2]T，用向量 <strong>z</strong> 来表示。</p><p>**　　系数则是矩阵****W**（2 行 3 列的矩阵，排列形式与公式中的一样）。</p><p>**　　于是，输出公式可以改写成：**</p><p>****g(<strong>W</strong> * <strong>a</strong>) = <strong>z</strong>;</p><p>**　　这个公式就是神经网络中从前一层计算后一层的****矩阵运算。**</p><p><strong>3.效果</strong></p><p>**　　与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个****逻辑回归**模型，可以做线性分类任务。</p><p>**　　我们可以用****决策分界**来形象的表达分类的效果。决策分界就是在二维的数据平面中划出一条直线，当数据的维度是 3 维的时候，就是划出一个平面，当数据的维度是 n 维时，就是划出一个 n-1 维的超平面。</p><p>**　　下图显示了在二维平面中划出决策分界的效果，也就是感知器的分类效果。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/d8ac48846e6e18911b3a9869d7be5301.png" alt="img" /></p><p><strong>图 17 单层神经网络（决策分界）</strong></p><p><strong>权值 w 并不是事先人为设定好的，而是模型****根据数据自动学出来的参数</strong>，就像学生通过做题不断修正自己的解题方法。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814111819961.png" alt="image-20250814111819961" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814111834727.png" alt="image-20250814111834727" /></p><p><strong>偏置就是一个额外的权重，对应输入恒为 1，用来调整神经元的输出基准，让模型的决策边界更灵活。</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814112554503.png" alt="image-20250814112554503" /></p><p><strong>感知器能做的事情：</strong></p><ul><li><strong>它可以把空间分成两部分。</strong></li><li><strong>所以它只能处理****线性可分</strong>问题（比如 AND、OR）。</li></ul><p><strong>XOR 不满足线性可分条件，因此单层感知器无法找到一组权重 w 和偏置 b 使得输出完全正确。</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814113057424.png" alt="image-20250814113057424" /></p><p><strong>四. 两层神经网络（多层感知器）</strong></p><p>**　　**<strong>1.引子</strong></p><p>**　　两层神经网络是本文的重点，因为正是在这时候，神经网络开始了大范围的推广与使用。**</p><p>**　　Minsky 说过单层神经网络无法解决异或问题。但是当增加一个计算层以后，两层神经网络不仅可以解决异或问题，而且具有非常好的非线性分类效果。不过两层神经网络的计算是一个问题，没有一个较好的解法。**</p><p>**　　1986 年，Rumelhar 和 Hinton 等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。目前，大量的教授神经网络的教材，都是重点介绍两层（带一个隐藏层）神经网络的内容。 **</p><p>**　　这时候的 Hinton 还很年轻，30 年以后，正是他重新定义了神经网络，带来了神经网络复苏的又一春。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/bd5d018f58f101c7b8341a0bc996cc1c.png" alt="img" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814113925679.png" alt="image-20250814113925679" /></p><p>**　计算最终输出 z 的方式是利用了中间层的 a1(2)，a2(2)和第二个权值矩阵计算得到的，如下图。**</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/ff6b58c6dc41f9f439a8ceaa9393757c.png" alt="img" /></p><p><strong>图 21 两层神经网络（输出层计算）</strong></p><p>**　　假设我们的预测目标是一个向量，那么与前面类似，只需要在“输出层”再增加节点即可。**</p><p>**　　我们使用向量和矩阵来表示层次中的变量。**<strong>a</strong>(1)，<strong>a</strong>(2)，<strong>z</strong> 是网络中传输的向量数据。<strong>W</strong>(1)和 <strong>W</strong>(2)是网络的矩阵参数。如下图。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/7b83ef7d2f2eeb3be332a0f60bc1509c.png" alt="img" /></p><p><strong>图 22 两层神经网络（向量形式）</strong></p><p>**　　使用矩阵运算来表达整个计算公式的话如下：**</p><p>** g(**<strong>W</strong>(1) * <strong>a</strong>(1)) = <strong>a</strong>(2);</p><p>**g(**<strong>W</strong>(2) * <strong>a</strong>(2)) = <strong>z</strong>;</p><p>** 需要说明的是，至今为止，我们对神经网络的结构图的讨论中都没有提到偏置节点（bias unit）。事实上，这些节点是默认存在的。它本质上是一个只含有存储功能，且存储值永远为 1 的单元。在神经网络的每个层次中，除了输出层以外，都会含有这样一个偏置单元。正如线性回归模型与逻辑回归模型中的一样。**</p><p>**　　偏置单元与后一层的所有节点都有连接，我们设这些参数值为向量****b**，称之为偏置。如下图。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/c2c8420cff26253a2a0ff71ed9b9ab2c.png" alt="img" /></p><p><strong>图 23 两层神经网络（考虑偏置节点）</strong></p><hr /><p>**　　可以看出，偏置节点很好认，因为其没有输入（前一层中没有箭头指向它）。有些神经网络的结构图中会把偏置节点明显画出来，有些不会。一般情况下，我们都不会明确画出偏置节点。 **</p><p>**　　在考虑了偏置以后的一个神经网络的矩阵运算如下：**</p><p>** g(**<strong>W</strong>(1) * <strong>a</strong>(1) + <strong>b</strong>(1)) = <strong>a</strong>(2);</p><p>**g(**<strong>W</strong>(2) * <strong>a</strong>(2) + <strong>b</strong>(2)) = <strong>z</strong>;</p><hr /><p>**　　需要说明的是，在两层神经网络中，我们不再使用 sgn 函数作为函数 g，而是使用平滑函数 sigmoid 作为函数 g。我们把函数 g 也称作激活函数（active function）。**</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250814131412701.png" alt="image-20250814131412701" /></p><p><strong>3.效果</strong></p><p>**　　与单层神经网络不同。理论证明，两层神经网络可以无限逼近任意连续函数。**</p><p>**　　这是什么意思呢？也就是说，面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。**</p><p>**　　下面就是一个例子（此两图来自 colah 的**<a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">博客</a>），红色的线与蓝色的线代表数据。而红色区域和蓝色区域代表由神经网络划开的区域，两者的分界线就是决策分界。</p><p><img src="https://i-blog.csdnimg.cn/blog_migrate/05fc87cd4485eb8a9291a26812596766.png" alt="img" /></p><p><strong>图 24 两层神经网络（决策分界）</strong></p><p>**　　**</p><p>**　　可以看到，这个两层神经网络的决策分界是非常平滑的曲线，而且分类的很好。有趣的是，前面已经学到过，单层网络只能做线性分类任务。而两层神经网络中的后一层也是线性分类层，应该只能做线性分类任务。为什么两个线性分类任务结合就可以做非线性分类任务？**</p><p>**　　我们可以把输出层的决策分界单独拿出来看一下。就是下图。**</p><h3 id="第二步隐藏层的魔术-空间变换-spatial-transformation"><a class="markdownIt-Anchor" href="#第二步隐藏层的魔术-空间变换-spatial-transformation"></a> 第二步：隐藏层的“魔术”—— 空间变换 (Spatial Transformation)</h3><p><strong>现在，我们在输入层和输出层之间加入一个“隐藏层”，就构成了两层神经网络。这个隐藏层究竟做了什么？</strong></p><p><strong>它对原始数据的坐标空间进行了一次非线性变换。</strong></p><p><strong>这个变换可以想象成将原始的坐标纸（特征空间）进行“拉伸”、“弯曲”、“折叠”，使得原本挤在一起、无法用直线分开的数据点，在一个新的坐标系下，变得可以用直线轻易分开了。</strong></p><p><strong>这个变换具体是通过两个操作完成的：</strong></p><ol><li><strong>线性计算</strong>：输入数据与隐藏层的权重矩阵 (W) 进行矩阵乘法，再加上偏置 (b)。这本质上是对坐标空间进行旋转、缩放、平移等线性变换。</li><li><strong>非线性激活</strong>：对上一步的线性计算结果，施加一个<strong>非线性激活函数</strong>（如 Sigmoid, ReLU, Tanh 等）。<strong>这是实现非线性变换的关键！</strong> 如果没有这个非线性激活函数，那么无论多少个隐藏层叠加，最终都等价于一个单层的线性模型，无法学习到非线性的关系。</li></ol><p><img src="https://i-blog.csdnimg.cn/blog_migrate/c2a4059fd628588ad7f2a5d4aa60758b.png" alt="img" /></p><p><strong>图中的灰色网格线，实际上就是原始空间中标准的直线网格（比如 x=0.1, 0.2… 和 y=0.1, 0.2…）经过隐藏层****变换后</strong>的样子。您可以看到，原本笔直的网格线被“掰弯”了。这直观地展示了空间本身被扭曲了。</p><p><strong>可以看到，输出层的决策分界仍然是直线。关键就是，从输入层到隐藏层时，数据发生了空间变换。也就是说，两层神经网络中，隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;由于实习等一系列事情，leetcode 更新暂时延缓，只保留每日刷一道题，知识点学习暂且搁置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面是 llm 前置知识，在这部分结束后，我将更新经典论文阅读。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>芯片验证（一）</title>
    <link href="https://zjncs.github.io/2025/08/14/%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://zjncs.github.io/2025/08/14/%E8%8A%AF%E7%89%87%E9%AA%8C%E8%AF%81%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2025-08-14T02:10:06.000Z</published>
    <updated>2025-08-14T02:10:38.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>芯片验证是确保芯片设计正确性的关键环节。随着芯片复杂度的不断提升，验证工作在整个设计流程中所占比重越来越大，已成为芯片成功与否的决定性因素。这一讲我们将从基础概念入手，系统介绍验证的重要性、基本流程与方法、验证层次和评估指标，探讨实际项目流程中可能遇到的挑战与敏捷验证的应对思路，分析当前验证领域面临的困境以及使用高级语言进行验证的价值，并展望芯片验证众包这一未来解决方案。</strong></p><p><strong>接下来，你将了解：</strong></p><ul><li><strong>芯片验证的基本概念</strong>：什么是芯片验证，为什么它对芯片设计至关重要，以及验证不足可能导致的严重后果。</li><li><strong>验证流程与敏捷方法</strong>：完整的验证流程是如何开展的，敏捷验证的原则与实践，以及从计划到报告的完整验证步骤。</li><li><strong>验证层次体系</strong>：从单元测试到系统测试的不同验证层次及其特点。</li><li><strong>验证质量评估</strong>：如何通过功能正确性、代码/功能覆盖率、缺陷密度等关键指标来评估验证质量。</li><li><strong>当前验证挑战与高级语言价值</strong>：验证面临的工作量、成本、人才等挑战，以及使用高级语言（如 Python）的优势及其对验证的推动作用。</li><li><strong>芯片验证众包前景</strong>：作为应对挑战的创新方案，众包验证的可行性、技术路线，以及 Picker 等工具在其中的作用。</li></ul><h2 id="芯片验证的定义"><a class="markdownIt-Anchor" href="#芯片验证的定义"></a> 芯片验证的定义</h2><p><strong>芯片验证是芯片开发流程中的关键环节，它的目标是确保设计的芯片在功能、性能和功耗等方面都满足预定的规范要求。</strong></p><p><strong>在本课程中，我们主要关注的是****功能验证</strong>，也就是验证设计的电路逻辑是否满足既定需求，回答的核心问题是：<strong>“这个设计真的能按照预期工作吗？”</strong></p><p><strong>芯片验证并不等同于芯片测试。验证发生在设计阶段，通过各种方法（如仿真）在芯片制造前发现问题；而测试则是在芯片制造后，通过物理手段检查实际芯片是否工作正常。</strong></p><p><strong>想象一下，如果你的手机突然无法计算，或者自动驾驶汽车的导航系统出现了错误，这将是多么可怕的事情！芯片验证正是为了防止这些问题发生。</strong></p><p><strong>一旦芯片被制造出来，修改错误的成本将会非常高昂。以下是几个验证不足导致灾难性后果的经典案例：</strong></p><ul><li><strong>Intel Pentium FDIV Bug （1994）</strong>: 浮点单元的一个计算错误导致 Intel 不得不召回大量处理器，造成约 4.75 亿美元的损失。</li><li><strong>AMD Barcelona Bug （2007）</strong>: TLB 错误导致系统不稳定，AMD 不得不降低处理器频率并推迟产品发布。</li><li><strong>Intel Sandy Bridge 芯片组缺陷（2011）</strong>：缺陷源于芯片组电路设计中的问题，SATA 端口可能在某些情况下退化，影响设备性能。根据<a href="https://www.cnet.com/science/intels-sandy-bridge-chipset-flaw-the-fallout/"> CNET - Intel’s Sandy Bridge chipset flaw: The fallout</a>，Intel 预计 2011 年第一季度损失约 3 亿美元的销售收入，并支付 7 亿美元的维修和更换费用，总计约 10 亿美元的损失。</li></ul><h1 id="3-验证流程与敏捷方法"><a class="markdownIt-Anchor" href="#3-验证流程与敏捷方法"></a> 3. 验证流程与敏捷方法</h1><h2 id="验证与设计的关系"><a class="markdownIt-Anchor" href="#验证与设计的关系"></a> 验证与设计的关系</h2><p><strong>芯片验证并不是设计完成后的一个简单检查步骤，而是与设计过程并行进行的关键活动。</strong></p><p><strong>设计团队和验证团队通常从同一份规范出发，但有着不同的实现方式和关注点：</strong></p><ul><li><strong>设计团队</strong>：开发 DUT，关注功能实现、代码的可综合性和电路效率。<br /><strong>DUT（Design Under Test）是****待测设备</strong> ，通常是一个模块或子系统。</li><li><strong>验证团队</strong>：开发验证平台，专注于验证功能的正确实现。</li></ul><p><strong>这种设计与验证的分离确保了两个团队能够独立理解规范，从而提高发现潜在错误的概率。</strong></p><p><img src="https://open-verify.cc/beginner/course/1-basis/assets/flow.png" alt="img" /></p><h2 id="完整的验证流程"><a class="markdownIt-Anchor" href="#完整的验证流程"></a> 完整的验证流程</h2><p><strong>芯片验证是一个系统工程，确保设计按预期工作。其主要流程概括如下：</strong></p><ol><li><strong>制定验证计划：此阶段是验证工作的起点，旨在明确“验证什么”和“如何验证”。主要任务是定义验证的总体范围、目标、采用的验证方法、所需资源、整理功能点等。</strong></li><li><strong>搭建验证平台：根据验证计划，此阶段专注于构建用于执行测试的验证环境，包含测试输入产生、信号收集和结果检查等组件。平台搭建的初步成功通常以通过基本的“冒烟测试”为标志，证明环境主要功能通路工作正常。</strong></li><li><strong>编写测试用例：在验证平台基础上，此阶段的核心是依据验证计划，编写实现具体的测试用例，用以全面覆盖预定的功能点、边界条件及异常场景。</strong></li><li><strong>收集 Bug 和覆盖率：此阶段将运行已开发的测试用例，识别并记录设计中出现的缺陷，同时收集代码覆盖率和功能覆盖率数据以评估验证的完备程度。这是一个包含调试和分析的迭代过程。</strong></li><li><strong>进行回归测试：在设计代码发生变更（如缺陷修复或功能更新）后，重新运行相关测试用例，确保修改的正确性且未引入新问题。</strong></li><li><strong>撰写验证报告：在验证达到特定节点或结束时，总结整个验证过程、测试结果、缺陷状态、覆盖率达成情况及存在的风险，为项目决策提供依据。</strong></li></ol><p><strong>功能点</strong>是指芯片设计中需要验证的具体功能或特性，通常从设计规范和要求文档中提取。</p><p><strong>测试点</strong>是从功能点派生出的具体测试用例或场景，用于确保功能点的每个方面都被彻底测试。</p><p><strong>功能点（Functional Point）是验证的“目标”，而测试点（Test Point）是为达成这个目标而采取的“具体行动和步骤”</strong></p><p><strong>假设我们正在设计一个芯片，其中包含一个 DMA（Direct Memory Access，直接内存访问）模块。</strong></p><h4 id="第-1-步从设计规范中提取功能点"><a class="markdownIt-Anchor" href="#第-1-步从设计规范中提取功能点"></a> <strong>第 1 步：从设计规范中提取“功能点”</strong></h4><p><strong>翻开设计规范文档，关于 DMA 的部分有这样一条要求：</strong></p><ul><li><strong>功能点 1</strong>：DMA 模块必须支持**突发传输（Burst Transfer）**模式。</li></ul><p><strong>这是一个很明确的功能点。项目经理和验证负责人在看进度时，会关注“突发传输”这个功能点是否已经验证。</strong></p><h4 id="第-2-步将功能点分解为具体的测试点"><a class="markdownIt-Anchor" href="#第-2-步将功能点分解为具体的测试点"></a> <strong>第 2 步：将“功能点”分解为具体的“测试点”</strong></h4><p><strong>现在，验证工程师拿到这个功能点，他需要思考：“为了证明 DMA 的突发传输功能是完全正确的，我需要测试哪些场景？” 他会从不同维度进行分解：</strong></p><ul><li><strong>正常工作场景 (Happy Path)</strong>：<ul><li><strong>测试点 1.1</strong>：测试突发长度为 4（Burst Length=4）的传输。</li><li><strong>测试点 1.2</strong>：测试突发长度为 8（Burst Length=8）的传输。</li><li><strong>测试点 1.3</strong>：测试不同的数据位宽（32 位，64 位）下的突发传输。</li></ul></li><li><strong>边界条件场景 (Boundary Conditions)</strong>：<ul><li><strong>测试点 1.4</strong>：测试<strong>最小</strong>突发长度（例如 1）的传输。</li><li><strong>测试点 1.5</strong>：测试<strong>最大</strong>突发长度（例如 16）的传输。</li><li><strong>测试点 1.6</strong>：测试传输的数据总量恰好等于一个突发包的大小。</li><li><strong>测试点 1.7</strong>：测试源地址或目标地址未对齐（Unaligned）的情况。</li></ul></li><li><strong>异常和错误场景 (Exception/Error Scenarios)</strong>：<ul><li><strong>测试点 1.8</strong>：在突发传输过程中，外部总线（Bus）返回一个错误信号，看 DMA 是否能正确中止并上报错误。</li><li><strong>测试点 1.9</strong>：配置一个不支持的突发长度，看 DMA 是否能报错或不工作。</li><li><strong>测试点 1.10</strong>：在传输过程中，尝试通过软件中止（abort）任务。</li></ul></li><li><strong>组合和压力场景 (Corner Cases)</strong>：<ul><li><strong>测试点 1.11</strong>：一个突发传输刚结束，立即启动下一个突发传输（背靠背，Back-to-Back）。</li><li><strong>测试点 1.12</strong>：同时启动多个 DMA 通道进行突发传输，测试仲裁和带宽压力。</li></ul></li></ul><p><strong>现在，您可以看到，为了验证“支持突发传输”这一个功能点，我们派生出了十几个具体的、可操作的测试点。只有当所有这些测试点都成功通过后，我们才能有信心地说，这个功能点已经得到了充分和彻底的验证。</strong></p><p><strong>第一阶段：需求理解与规划</strong></p><ol><li><p><strong>深入研究规范文档</strong></p><ol><li><strong>反复、仔细地阅读功能规范、架构规范。</strong></li><li><strong>在需要时参考详细设计规范，以挖掘和覆盖边界情况。</strong></li><li><strong>目标是全面理解设计意图、功能、接口、性能指标和操作模式。</strong></li></ol></li><li><p><strong>跨部门协作与澄清</strong></p><ol><li><p><strong>与架构师、设计师以及其他验证工程师紧密合作。</strong></p></li><li><p><strong>采用多种沟通方式确保理解一致：</strong></p><ul><li><strong>串讲：</strong> 由需求提出者（如架构师）向验证/设计团队讲解需求。</li><li><strong>反串讲：</strong> 由验证/设计团队向需求提出者复述他们的理解，以确认无误。</li><li><strong>评审：</strong> 组织正式的会议，共同审查需求的准确性、完整性和可测试性。</li></ul></li><li><p><strong>此阶段的目标是消除歧义，就需求达成共识。</strong></p></li></ol></li><li><p><strong>确定组织方法</strong><br /><strong>当我们完成上一阶段之后，需要开始制定验证计划。在制定验证计划时，我们需要组织需求和功能点，主要有两种方法：</strong></p><ul><li><strong>自下而上</strong><ol><li><strong>核心</strong>：设计的具体模块或接口出发，强调设计视角。</li><li><strong>优点</strong>：易提取具体需求，便于链接到代码覆盖点，适合模块级验证。</li><li><strong>缺点</strong>：能产生大量低层需求，不易把握系统全局。</li><li><strong>适用</strong>：模块验证、控制逻辑复杂的单元、有详细实现文档时。</li></ol></li><li><strong>自上而下</strong><ol><li><strong>核心</strong>：系统级的使用场景或数据流出发，强调客户/验证视角。</li><li><strong>优点</strong>：能更好地把握系统级功能和性能，可在早期进行。</li><li><strong>缺点</strong>：需要清晰的高层规划，用例可能非常多，覆盖点可能偏宏观。</li><li><strong>适用</strong>：SoC（片上系统）验证、数据流为主的设计、有清晰架构或用例定义时。</li></ol></li><li><strong>实践中，</strong> 常常将两者结合，先用“自上而下”定义整体框架和主要场景，再用“自下而上”细化关键模块或接口的需求 。选择哪种方式取决于项目特点和可用信息。</li></ul></li></ol><p><strong>第二阶段：功能点识别与测试点细化</strong></p><ol><li><strong>识别功能点</strong><ol><li><strong>明确需求之后，我们需要识别设计规范和文档中需要验证的内容，例如关键功能、配置组合方式、操作模式、数据流、时序关系、协议规则等。它们构成了需要验证的功能点。</strong></li><li><strong>对功能点进行优先级排序，重点关注高风险、新设计、关键性能或客户要求的部分。</strong></li></ol></li><li><strong>分解与细化测试点</strong>：<ol><li><p><strong>将每个功能点进一步分解为具体的、可测量的****测试点</strong>或<strong>覆盖项</strong>。这是定义如何衡量功能点是否被覆盖的关键步骤。</p></li><li><p><strong>我们可以从不同维拆分测试点，例如：</strong></p><ul><li><strong>场景</strong>：不同的特权状态，如 RISC-V 中某条指令在 M、S、U 特权模式下的行为，应该是什么样的。</li><li><strong>功能</strong>：设计的核心操作，如算法计算、数据转换、控制逻辑。</li><li><strong>白盒</strong>：关注内部实现细节，如状态机状态和跳转、内部计数器边界值、流水线状态等。</li><li><strong>接口</strong>：模块或芯片与外部的交互，如总线协议时序、握手信号、中断处理。</li><li><strong>异常</strong>：错误处理、故障注入、超时、边界条件下的行为、非法配置或输入。</li><li><strong>复位与初始化</strong>：注复位后所有相关逻辑都恢复到预期默认值。</li></ul></li><li><p><strong>链接测试点与需求</strong>：在验证计划中，把每个需求明确地链接到一个或多个具体的测试点其实现类型。</p></li></ol></li></ol><p><strong>第三阶段：覆盖实现与迭代</strong></p><p>**此阶段，我们通过“**<strong>覆盖率</strong>”这一量化指标来评定验证的完备性。</p><p><strong>在仿真过程中，我们需要了解各个****测试点</strong>是否被测试激励有效“命中”。为准确获取并体现这一覆盖情况，我们会针对这些测试点编写专门的覆盖代码，用以在仿真时监测和记录它们的激活状态，最终得到覆盖率信息。</p><p>**关于覆盖率的具体技术细节，后续课程将详细介绍，此处不作展开。但我们需要知道的是，**<strong>验证是一个持续迭代的过程</strong>。这意味着需要分析覆盖率报告，找出“覆盖盲区”（即未被充分测试的部分），并据此指导后续的测试用例开发，如此循环，直至各项覆盖率达到预设的验收目标。</p><h2 id="敏捷验证"><a class="markdownIt-Anchor" href="#敏捷验证"></a> 敏捷验证</h2><p><strong>然而，在实践中</strong>，尤其是在追求快速迭代和市场响应的 <strong>创业公司或新兴业务</strong> 中，情况往往更加复杂。有时，为了快速验证想法或抢占市场先机，<strong>芯片开发本身也越来越多地借鉴和实践“敏捷开发”的原则</strong>：设计实现可能在规范细节尚未完全冻结时就已经开始，甚至出现“设计先行，规范后补”或者设计与规范频繁迭代的情况。</p><p><strong>在这种快速变化、规范可能不完全成熟的环境下，传统的、依赖稳定规范的验证方法会面临巨大挑战。如果严格等待规范最终确定再开始验证，可能会错失市场窗口；而如果基于不稳定的规范进行验证，则可能需要大量的重复工作。 因此，****敏捷验证</strong>的概念应运而生。</p><p><strong>敏捷验证强调：</strong></p><ul><li><strong>早期介入与持续集成</strong>：验证工作尽早开始，与设计紧密迭代，持续集成和测试新功能。</li><li><strong>适应性与灵活性</strong>：能够快速响应需求和设计的变更，调整验证计划和策略。</li><li><strong>风险驱动</strong>：优先验证最高风险或最不确定的部分。</li><li><strong>紧密协作</strong>：设计与验证团队之间需要更频繁、更紧密的沟通与协作。</li></ul><p><strong>虽然敏捷验证带来了灵活性，但也对验证团队的技术能力、工具链的自动化程度以及团队协作模式提出了更高的要求。如何在快速迭代和保证质量之间找到平衡点，是许多现代芯片开发团队需要面对的课题。</strong></p><h1 id="4-芯片验证的层次"><a class="markdownIt-Anchor" href="#4-芯片验证的层次"></a> 4. 芯片验证的层次</h1><p><strong>芯片验证可以按照验证对象的规模分为四个主要层次，从小到大依次为：</strong></p><ol><li><strong>单元测试（Unit Testing，UT）</strong>：单元测试关注的是最小的功能单元，即单个模块或组件。</li><li><strong>块测试（Block Testing，BT）</strong>：当多个模块之间存在紧密耦合关系时，单独测试每个模块可能效率不高。块测试将这些相互关联的模块组合在一起进行测试。</li><li><strong>集成测试（Integration Testing，IT）</strong>：集成测试将多个功能块组合在一起，验证它们能否正确协同工作，通常用于验证子系统级别的功能。</li><li><strong>系统测试（System Testing，ST）</strong>：系统测试也称为 Top 验证，是将所有子系统组合起来，验证整个芯片系统的功能是否符合预期。</li></ol><blockquote><p><strong>🧩 在实际项目中，验证层次的选择应根据项目规模、团队经验和时间预算灵活调整。对于小型项目，可能只需要 UT 和 ST 两个层次；而对于复杂的 SoC 设计，通常需要所有四个层次的验证。</strong></p></blockquote><hr /><h1 id="5-芯片验证指标"><a class="markdownIt-Anchor" href="#5-芯片验证指标"></a> 5. 芯片验证指标</h1><p><strong>如何知道我们的验证工作做得是否足够充分？这就需要一系列指标来评估验证质量，下面是芯片验证中的一些关键指标：</strong></p><h2 id="功能正确性"><a class="markdownIt-Anchor" href="#功能正确性"></a> 功能正确性</h2><p><strong>功能正确性</strong>是最基本也是最重要的指标，即芯片是否能正确执行设计规范中定义的所有功能。功能正确性是一个定性指标（无法直接用数值来衡量），通常通过以下方式验证：</p><ul><li><strong>正常工作条件下的功能测试。</strong></li><li><strong>极端条件下的边界测试。</strong></li><li><strong>异常情况下的健壮性测试。</strong></li></ul><h2 id="测试覆盖率"><a class="markdownIt-Anchor" href="#测试覆盖率"></a> 测试覆盖率</h2><p><strong>测试覆盖率是评估验证进展和验证完整性****最重要的量化指标</strong>，主要包括代码覆盖率和功能覆盖率。</p><h3 id="代码覆盖率"><a class="markdownIt-Anchor" href="#代码覆盖率"></a> 代码覆盖率</h3><p><strong>代码覆盖率是一种****隐式覆盖率指标</strong>，用于衡量在仿真过程中设计源代码的执行情况。它通过分析代码结构（如行、语句、分支等）来识别哪些部分在测试中被激活，哪些未被执行。</p><p><strong>代码覆盖率包括以下几种常见类型：</strong></p><ul><li><strong>翻转覆盖率</strong>：跟踪寄存器或连线中每一位从 0 到 1 和从 1 到 0 的翻转情况，用于检查基本连接性。</li><li><strong>行覆盖率</strong>：记录哪些代码行在模拟中被执行。</li><li><strong>语句覆盖率</strong>：比行覆盖率更细粒度，跟踪每个语句的执行情况。</li><li><strong>分支覆盖率</strong>：确保控制结构（如 if、case）的布尔表达式在测试中评估为真和假。</li><li><strong>表达式覆盖率</strong>：验证表达式中的每个条件独立地评估为真和假。</li><li><strong>有限状态机覆盖率</strong>：测量状态机的状态访问和状态间转换情况。</li></ul><h5 id="优点"><a class="markdownIt-Anchor" href="#优点"></a> <strong>优点</strong></h5><ul><li><strong>自动化生成</strong>：代码覆盖率可以由工具自动提取并分析，无需手动定义，易于集成到现有验证流程。</li><li><strong>识别未执行代码</strong>：帮助发现测试中未覆盖的代码区域，提示需要调整输入激励。</li></ul><h5 id="局限性"><a class="markdownIt-Anchor" href="#局限性"></a> <strong>局限性</strong></h5><ul><li><strong>不保证功能正确性</strong>：即使达到 100% 的代码覆盖率，也无法确保设计没有错误或功能符合规范，因为它不涉及功能需求的验证。</li><li><strong>缺乏规范关联</strong>：无法判断是否测试了规范中定义的所有功能，仅关注代码的结构执行。</li></ul><h3 id="功能覆盖率"><a class="markdownIt-Anchor" href="#功能覆盖率"></a> 功能覆盖率</h3><p><strong>功能覆盖率是一种****显式覆盖率指标</strong>，用于衡量在验证仿真的过程中，设计规范中定义的功能需求是否被测试到。与代码覆盖率不同，功能覆盖率需要手动创建，通常基于设计规范或设计的实现细节完成功能点、测试点的划分后，再编写测试点的触发条件在仿真时采样，然后收集结果得到功能覆盖率。</p><p><strong>功能覆盖率主要分为以下两种模型：</strong></p><ul><li><strong>覆盖组模型</strong>：在特定时间点采样状态值，例如使用 Toffee 的 <code>CovGroup</code> 收集功能点和测试点。</li><li><strong>覆盖属性模型</strong>：观察事件序列的时间关系，例如使用断言验证总线协议的握手序列或状态机的状态转换。</li></ul><h5 id="功能覆盖率的优点"><a class="markdownIt-Anchor" href="#功能覆盖率的优点"></a> <strong>功能覆盖率的优点</strong></h5><ul><li><strong>与规范直接关联</strong>：能够追踪功能需求的测试进度。</li><li><strong>识别未测试功能</strong>：帮助发现规范中定义但未被测试的功能。</li></ul><h5 id="功能覆盖率的局限性"><a class="markdownIt-Anchor" href="#功能覆盖率的局限性"></a> <strong>功能覆盖率的局限性</strong></h5><ul><li><strong>手动创建</strong>：需要工程师根据规范定义覆盖模型，过程复杂且耗时。</li><li><strong>可能遗漏功能</strong>：如果覆盖模型设计不全面，可能无法覆盖所有功能需求。</li></ul><blockquote><p><strong>🔍 思考：如果功能覆盖率很高，但是代码覆盖率不是很高，说明什么？</strong></p></blockquote><h3 id="两者的关系"><a class="markdownIt-Anchor" href="#两者的关系"></a> 两者的关系</h3><p><strong>代码覆盖率和功能覆盖率****相辅相成</strong>，共同提供更全面的验证视图：</p><ul><li><strong>代码覆盖率</strong>从底层视角检查代码执行的完整性，但无法验证功能是否符合设计意图。例如，100% 的代码覆盖率可能仍遗漏关键功能测试。</li><li><strong>功能覆盖率</strong>从顶层视角确保规范中的需求被测试，但可能无法发现未实现的代码或冗余代码。</li><li><strong>结合使用</strong>：通过结合两者，验证团队可以同时识别未执行的代码（通过代码覆盖率）和未测试的功能（通过功能覆盖率），从而更准确地评估验证质量和进度。</li></ul><h3 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h3><p><strong>代码覆盖率</strong>是一种自动化的指标，关注设计实现的执行情况，帮助发现测试中的盲点，但不涉及功能正确性。</p><p><strong>功能覆盖率</strong>是一种手动的指标，关注设计规范的测试情况，确保功能需求的实现和验证，但依赖于覆盖模型的完备性。</p><p><strong>在实际验证中，这两者应协同使用，以实现从代码结构到功能需求的全面覆盖，确保设计的可靠性和规范符合性。通常认为代码覆盖率达到 90% 以上，功能覆盖率达到 100% 时，验证工作才算充分。</strong></p><blockquote><p>**⚖️ ****覆盖率 100% 是否意味着设计没有错误？**答案是否定的。</p><p><strong>高覆盖率是必要条件，但不是充分条件。我们无法测试所有可能的输入组合和状态，因此即使达到 100% 的覆盖率，设计中仍可能存在未被发现的错误。这也是为什么验证工作需要综合运用多种方法和技术。</strong></p></blockquote><h2 id="缺陷密度"><a class="markdownIt-Anchor" href="#缺陷密度"></a> 缺陷密度</h2><p><strong>缺陷密度是指在单位代码量中发现的缺陷数量。随着验证的深入，新发现的缺陷应该逐渐减少，缺陷密度曲线应趋于平稳。如果在项目后期仍然有大量新缺陷被发现，这通常意味着验证工作不够充分。</strong></p><h2 id="验证效率与成本"><a class="markdownIt-Anchor" href="#验证效率与成本"></a> 验证效率与成本</h2><p><strong>验证效率是指在有限的时间和资源下完成的验证工作量。验证成本则包括人力、设备、时间等各类资源消耗。</strong></p><p><strong>提高验证效率、降低验证成本是芯片设计企业的重要目标。</strong></p><h1 id="7-高级语言在芯片验证中的价值"><a class="markdownIt-Anchor" href="#7-高级语言在芯片验证中的价值"></a> 7. 高级语言在芯片验证中的价值</h1><p>**面对验证复杂性、成本和人才方面的挑战，业界也在不断探索新的方法和工具。其中，****在验证中使用高级编程语言（如 Python、Java、C++ 等）**显示出越来越大的价值，原因在于：</p><ol><li><strong>更广泛的人才基础和生态系统</strong>：相比传统的硬件描述/验证语言，高级语言拥有更庞大的开发者社区、更丰富的学习资源和成熟的软件库（生态系统），这有助于降低学习门槛，吸引更多不同背景的人才进入验证领域。学术界也认识到，<a href="https://aha.stanford.edu/life-post-moores-law-new-cad-frontier">吸引软件工程师参与硬件领域</a>对于应对后摩尔定律时代挑战的重要性。</li><li>**与软件测试实践的共通性：**虽然领域不同，但芯片功能验证与软件测试在目标（发现缺陷）、流程（测试规划、用例编写、Bug 管理）、度量（覆盖率）以及环境（大多基于软件仿真）等方面存在诸多共通之处。高级语言及其测试框架（如 pytest）可以更容易地引入软件工程中的最佳实践（如单元测试、持续集成、自动化测试等），提升验证的效率和规范性。</li><li>**提升抽象层次和开发效率：**高级语言通常提供更强的抽象能力和更简洁的语法，使得验证工程师可以更专注于验证逻辑本身，而不是底层的信号交互细节（尽管这需要如 Picker 这样的工具进行桥接），从而可能提高验证环境的开发效率和可维护性。</li></ol><p><strong>正是这些优势，使得基于高级语言的验证方法成为降低验证门槛、提高效率、促进验证众包模式发展的关键推动力之一。</strong></p><blockquote><p><strong>💡</strong><a href="https://github.com/XS-MLVP/picker">Picker</a> 正是实现这一目标的关键工具之一，它能够将 RTL 设计代码转换为多种高级语言（如 Python、C++、Java 等）的接口，让开发者可以使用自己熟悉的语言来驱动和验证硬件设计。</p></blockquote><h2 id="芯片验证众包的技术路线"><a class="markdownIt-Anchor" href="#芯片验证众包的技术路线"></a> 芯片验证众包的技术路线</h2><p><strong>为了推动芯片验证众包的发展，我们提出以下技术路线：</strong></p><ol><li><strong>多语言验证工具</strong>：开发如 <strong>Picker</strong> 等工具，允许验证人员使用自己熟悉的编程语言（如 Python、Java、C++ 或 Go）参与验证，降低入门门槛。</li><li><strong>开放学习资源</strong>：提供全面、系统的在线学习材料，让任何人都能自学芯片验证知识。</li><li><strong>真实验证案例</strong>：基于开源处理器（如&quot;香山昆明湖&quot;RISC-V 处理器）提供实际验证案例，让学习者能够实践所学。</li><li><strong>众包验证平台</strong>：建立专门的众包验证平台，连接芯片设计公司和验证人才，组织验证任务的分发和管理。</li></ol><p><img src="https://open-verify.cc/beginner/course/1-basis/assets/opensource-chip-steps.png" alt="img" /></p><blockquote><p>**🚀 **<strong>未来展望</strong>：我们的愿景是&quot;打开传统验证模式的黑盒，让所有感兴趣的人可以随时随地的，用自己擅长的编程语言参与芯片验证&quot;。这将极大地扩展验证人才池，降低芯片验证成本，加速芯片创新周期。</p></blockquote><h1 id="9-小结"><a class="markdownIt-Anchor" href="#9-小结"></a> 9. 小结</h1><p><strong>在本节课中，我们学习了芯片验证的基础知识，包括：</strong></p><ul><li><strong>芯片验证的定义及其在芯片设计中的关键作用。</strong></li><li><strong>完整的芯片验证流程，从验证计划到验证报告。</strong></li><li><strong>芯片验证的不同层次，从单元测试到系统测试。</strong></li><li><strong>评估验证质量的关键指标，特别是覆盖率指标。</strong></li><li><strong>当前芯片验证面临的挑战。</strong></li><li><strong>芯片验证众包作为未来解决方案的潜力。</strong></li></ul><p><strong>芯片验证是确保芯片质量的关键环节，也是芯片设计中最耗时和耗资的部分。掌握验证知识不仅能够帮助你成为一名优秀的验证工程师，还能为推动芯片验证方法的创新做出贡献。</strong></p><p><strong>通过参与芯片验证众包，你不仅可以学以致用，还能为半导体产业的发展贡献自己的力量。无论你是大学生、软件开发者还是对硬件感兴趣的爱好者，都可以参与到这一激动人心的领域中来。</strong></p><p><strong>下一节课，我们将讲解 Picker 的使用，并尝试用它尝试验证环境的搭建和简单测试用例的编写。</strong></p><h1 id="10-课程后续需要的预备知识"><a class="markdownIt-Anchor" href="#10-课程后续需要的预备知识"></a> 10. 课程后续需要的预备知识</h1><p><strong>为了后续的学习，您还需要确保学习过以下知识：</strong></p><h2 id="linux-基础"><a class="markdownIt-Anchor" href="#linux-基础"></a> Linux 基础</h2><ol><li><strong>Linux 的基本命令和环境配置</strong></li><li><strong>Git 的使用</strong></li><li><strong>gcc 和常用的二进制工具：重点是如何源码编译安装</strong></li></ol><blockquote><p><strong>可以看</strong><a href="https://missing-semester-cn.github.io/">计算机教育中缺失的一课</a></p></blockquote><h2 id="python-基础"><a class="markdownIt-Anchor" href="#python-基础"></a> Python 基础</h2><ol><li><strong>Python 的安装、环境配置和</strong><code>pip</code> 的使用</li><li><strong>Python 基础</strong></li><li><strong>基础的 Python 面向对象编程</strong></li><li><strong>Python 协程相关的内容（</strong><code>asyncio</code>）</li></ol><blockquote><p><strong>可以看</strong><a href="https://liaoxuefeng.com/books/python/introduction/index.html">廖雪峰的 Python 教程</a>：</p><ul><li><strong>4</strong></li><li><strong>5</strong></li><li><strong>6</strong></li><li><strong>7.1~7.4</strong></li><li><strong>8.2~8.4</strong></li><li><strong>9</strong></li><li><strong>10</strong></li><li><strong>23.1~23.2</strong></li></ul></blockquote><p><strong>上述内容是本教程的验证开发环境和使用的编程语言。</strong></p><h2 id="数字电路基础"><a class="markdownIt-Anchor" href="#数字电路基础"></a> 数字电路基础</h2><p><strong>学习数字电路是芯片验证的核心基础。它能帮工程师透彻理解芯片设计原理、精准对接规范要求，同时解决时序冲突和信号完整性问题，高效排查逻辑漏洞，并设计出覆盖全场景的测试用例。可以说，数字电路知识贯穿验证全流程，是确保芯片功能可靠的关键底层能力。</strong></p><p><strong>这就要求我们掌握：</strong></p><ol><li><strong>Verilog 基础</strong><ul><li><strong>推荐视频：</strong><a href="https://www.bilibili.com/video/BV1PS4y1s7XW">从电路设计的角度入门 VerilogHDL</a></li></ul></li><li><strong>Chisel 基础</strong></li></ol><p><strong>Chisel 可以等到后续的果壳 Cache 实战再开始学习，但下一讲的例子我们会用到使用 Verilog 描述的模块。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;芯片验证是确保芯片设计正确性的关键环节。随着芯片复杂度的不断提升，验证工作在整个设计流程中所占比重越来越大，已成为芯片成功与否的决定性因素。这一讲我们将从基础概念入手，系统介绍验证的重要性、基本流程与方法、验证层次和评估指标，探讨实际项目流程中可能遇到的挑战</summary>
      
    
    
    
    <category term="开源项目" scheme="https://zjncs.github.io/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
    <category term="GLCC" scheme="https://zjncs.github.io/tags/GLCC/"/>
    
  </entry>
  
  <entry>
    <title>eoh环境配置</title>
    <link href="https://zjncs.github.io/2025/08/13/eoh%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>https://zjncs.github.io/2025/08/13/eoh%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</id>
    <published>2025-08-13T13:20:18.000Z</published>
    <updated>2025-08-18T08:39:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>by zjn</p><p>1.克隆一下源码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/FeiLiu36/EOH/</span><br></pre></td></tr></table></figure><p>2.进入源码目录，创建虚拟环境</p><p>我家里的电脑没有装conda，所以我用的是Python自带的<code>venv</code>，如果你有conda，可以用conda创建虚拟环境。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m venv eoh_env</span><br></pre></td></tr></table></figure><p>然后激活虚拟环境:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> eoh_env/Scripts/activate</span><br></pre></td></tr></table></figure><p>记得虚拟环境的Python版本要&gt;3.10</p><p>可以确定一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python --version</span><br></pre></td></tr></table></figure><p>3.安装依赖</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#基础依赖</span></span><br><span class="line">pip install numpy numba joblib</span><br></pre></td></tr></table></figure><p><img src="C:%5CUsers%5C22692%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250812234415782.png" alt="image-20250812234415782" /></p><p>在这个目录下，直接</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>也可以</p><p>4.配置llm参数</p><p><img src="C:%5CUsers%5C22692%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250812234524030.png" alt="image-20250812234524030" /></p><p>按照官网的指示，我选择了</p><h6 id="示例1旅行商问题的构造算法"><a class="markdownIt-Anchor" href="#示例1旅行商问题的构造算法"></a> 示例1：旅行商问题的构造算法</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd examples/tsp_construct</span><br><span class="line"></span><br><span class="line">python runEoH.py</span><br></pre></td></tr></table></figure><p>但是需要先去买api</p><p><a href="https://platform.deepseek.com/usage">DeepSeek 开放平台</a></p><p><img src="C:%5CUsers%5C22692%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250813000015718.png" alt="image-20250813000015718" /></p><p>在runEoH里面改一下参数</p><p>理论上就可以跑</p><p>但是，可能会遇到timeout</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">PS C:\Users\zny\Desktop\eoh\EoH-main\eoh&gt; &amp; C:\Users\zny\Desktop\eoh\eoh_env\Scripts\python.exe c:/Users/zny/Desktop/eoh/EoH-main/examples/tsp_construct/runEoH.py</span><br><span class="line">----------------------------------------- </span><br><span class="line">---              Start EoH            ---</span><br><span class="line">-----------------------------------------</span><br><span class="line">- output folder created -</span><br><span class="line">-  parameters loaded -</span><br><span class="line">- Prob tsp_construct loaded </span><br><span class="line">- EoH parameters loaded -</span><br><span class="line">- Evolution Start -</span><br><span class="line">- check LLM API</span><br><span class="line">remote llm api is used ...</span><br><span class="line">creating initial population:</span><br><span class="line">Parallel <span class="keyword">time</span> out .</span><br><span class="line">Parallel <span class="keyword">time</span> out .</span><br><span class="line">Pop initial: </span><br><span class="line"></span><br><span class="line">initial population has been created!</span><br><span class="line"> OP: e1, [1 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line"> OP: e2, [2 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line"> OP: m1, [3 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line"> OP: m2, [4 / 4] | Obj:  None| Obj:  None| Obj:  None| Obj:  None|</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;c:\Users\zny\Desktop\eoh\EoH-main\examples\tsp_construct\runEoH.py&quot;</span>, line 22, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    evolution.run()</span><br><span class="line">  File <span class="string">&quot;C:\Users\zny\Desktop\eoh\EoH-main\eoh\src\eoh\eoh.py&quot;</span>, line 42, <span class="keyword">in</span> run</span><br><span class="line">    method.run()</span><br><span class="line">  File <span class="string">&quot;C:\Users\zny\Desktop\eoh\EoH-main\eoh\src\eoh\methods\eoh\eoh.py&quot;</span>, line 177, <span class="keyword">in</span> run</span><br><span class="line">    json.dump(population[0], f, indent=5)</span><br><span class="line">              ~~~~~~~~~~^^^</span><br><span class="line">IndexError: list index out of range</span><br></pre></td></tr></table></figure><p><img src="C:%5CUsers%5C22692%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250813000210705.png" alt="image-20250813000210705" /></p><p>找到utils getParas</p><p><img src="C:%5CUsers%5C22692%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20250813000238820.png" alt="image-20250813000238820" /></p><p>timeout设的高一点，但没有完全解决问题，推测可能是r1模型不是很聪明，因为花了大几万token只找到一个解</p><p>或许也可以降低tsp问题的复杂度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">(eoh_env) PS C:\Users\zny\Desktop\eoh\EoH-main\eoh&gt; &amp; C:\Users\zny\Desktop\eoh\eoh_env\Scripts\python.exe c:/Users/zny/Desktop/eoh/EoH-main/examples/tsp_construct/runEoH.py</span><br><span class="line">-----------------------------------------</span><br><span class="line">---              Start EoH            ---</span><br><span class="line">-----------------------------------------</span><br><span class="line">- output folder created -</span><br><span class="line">-  parameters loaded -</span><br><span class="line">- Prob tsp_construct loaded</span><br><span class="line">- EoH parameters loaded -</span><br><span class="line">- Evolution Start -</span><br><span class="line">- check LLM API</span><br><span class="line">remote llm api <span class="keyword">is</span> used ...</span><br><span class="line">creating initial population:</span><br><span class="line">Pop initial: </span><br><span class="line"> Obj:  <span class="number">7.03416</span>| Obj:  <span class="number">7.50039</span>| Obj:  <span class="number">11.58909</span>|</span><br><span class="line">initial population has been created!</span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="number">7.65304</span>| Obj:  <span class="number">7.59725</span>| Obj:  <span class="number">9.37639</span>| Obj:  <span class="number">7.45505</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="number">7.6436</span>| Obj:  <span class="number">8.47352</span>| Obj:  <span class="number">8.59245</span>| Obj:  <span class="number">8.47352</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">1</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">30.6</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.59725</span></span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">2</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">36.9</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.59725</span></span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="number">7.45505</span>| Obj:  <span class="number">10.23619</span>| Obj:  <span class="number">7.57794</span>| Obj:  <span class="number">8.05993</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">3</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">50.8</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.57794</span></span><br><span class="line"> OP: e1, [<span class="number">1</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: e2, [<span class="number">2</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m1, [<span class="number">3</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line"> OP: m2, [<span class="number">4</span> / <span class="number">4</span>] | Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>| Obj:  <span class="literal">None</span>|</span><br><span class="line">--- <span class="number">4</span> of <span class="number">4</span> populations finished. Time Cost:  <span class="number">57.1</span> m</span><br><span class="line">Pop Objs:  <span class="number">7.03416</span> <span class="number">7.45505</span> <span class="number">7.50039</span> <span class="number">7.57794</span></span><br><span class="line">&gt; End of Evolution!</span><br><span class="line">-----------------------------------------</span><br><span class="line">---     EoH successfully finished !   ---</span><br></pre></td></tr></table></figure><p>虽然成功finish</p><p>但是m1和m2的obj都是None</p><p>说明修改策略都超时了，因为e1和e2都简单一些所以成功了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;by zjn&lt;/p&gt;
&lt;p&gt;1.克隆一下源码&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;t</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="环境配置" scheme="https://zjncs.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>EoH文章阅读</title>
    <link href="https://zjncs.github.io/2025/08/13/EoH%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/"/>
    <id>https://zjncs.github.io/2025/08/13/EoH%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/</id>
    <published>2025-08-13T02:07:21.000Z</published>
    <updated>2025-08-13T02:08:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>源码及文章：<a href="https://github.com/FeiLiu36/EoH/blob/main/README_CN.md">EoH/README_CN.md at main · FeiLiu36/EoH</a></p><p><strong>Evolution of Heuristic 启发式进化：</strong></p><p><strong>Evolutionary Computation 进化计算：</strong></p><p><strong>Automatic Heuristic Design 自动启发式设计</strong></p><p><strong>EoH 将自然语言中的启发式思维转化为可执行代码，通过优化搜索框架对思维与代码的持续演化，显著提升了高性能启发式算法的生成效率。</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250811094659600.png" alt="image-20250811094659600" /></p><p><strong>创新点</strong>：</p><p><strong>双重演进</strong>：EoH 利用 LLM 不仅演进代码，更重要的是它还演进“思想”。LLM 首先根据现有的优秀启发式（包含思想和代码），生成一个改进的或全新的“思想” 。</p><p><strong>思想指导代码</strong>：随后，LLM 再将这个新生成的“思想”作为指导，翻译成具体的“代码” 。</p><p><strong>提示策略 (Prompt Strategies)</strong>：整个演进过程并非盲目进行，而是由一系列精心设计的提示策略来引导，分为两大类：探索（Exploration: E1, E2）和修改（Modification: M1, M2, M3），以确保生成更多样化和更有效的启发式算法 。</p><p><strong>通过构建 thought 来表征启发式算法的核心逻辑。随后借助语言模型生成代码实现。随后协同进化逐步优化思想域代码</strong></p><p><strong>三大贡献：</strong></p><p><strong>框架上提出 EoH</strong></p><p><strong>设计了高效的 prompt</strong></p><p><strong>通过组合优化问题对 EoH 进行了全面评估</strong></p><p><strong>与本研究最相关的是 FunSearch 框架：</strong></p><p><strong>FunSearch 是由 Google DeepMind 开发的一种创新的方法，其名称是 “在函数空间中搜索”（Searching in the ****Fun</strong>ction Space）的缩写。它旨在利用大型语言模型（LLM）来解决数学和计算机科学领域的难题，甚至做出全新的科学发现。</p><p><strong>FunSearch 的核心思想是将一个预训练的大型语言模型（LLM）的创造力与一个自动评估系统结合起来。它并不直接让 LLM 给出问题的最终答案，而是让 LLM 生成解决问题的“程序”或“函数”。这种方法的巧妙之处在于：</strong></p><ul><li><strong>规避“幻觉”</strong>：LLM 常常会“一本正经地胡说八道”（产生幻觉）。但 FunSearch 生成的是代码，这些代码可以通过一个自动评估器（Evaluator）来运行和打分，从而有效过滤掉所有不正确或无效的想法。</li><li><strong>输出可解释的知识</strong>：FunSearch 最终产出的是一个能够解决问题的程序。人类科学家可以阅读和理解这个程序，从而洞察问题是如何被解决的，而不仅仅是知道答案是什么。这有助于激发新的研究思路。</li></ul><p><strong>FunSearch 的工作方式可以看作是一种由 LLM 驱动的“演化算法”或“遗传编程”。其基本流程如下：</strong></p><ol><li><strong>定义问题</strong>：用户首先需要用代码来描述一个问题。这通常包括一个用于评估解决方案好坏的 <code>evaluate</code> 函数，以及一个非常简单的初始程序作为“种子”。</li><li><strong>演化循环</strong>：<ul><li><strong>选择与提示</strong>：系统从一个“程序数据库”（Program Database）中挑选出一些当前最高效的程序。</li><li><strong>LLM 生成新代码</strong>：将这些高效程序作为“范例”输入给 LLM（一个专门训练用于编码的 LLM，如 Codey），并提示它在此基础上进行创新，生成新的、可能更好的函数代码。</li><li><strong>评估与筛选</strong>：新生成的代码会被自动评估器运行和打分。</li><li><strong>更新数据库</strong>：如果新程序的表现优于现有的程序，它就会被添加到程序数据库中，用于下一轮的演化。</li></ul></li><li><strong>持续迭代</strong>：这个“生成-评估-筛选”的循环会不断重复，推动程序从一个简单的“种子”逐步“演化”成一个非常高效的解决方案。</li></ol><p><strong>FunSearch 已经在一些长期存在的数学开放性问题上取得了突破性的成果：</strong></p><ul><li><strong>上限集问题（Cap Set Problem）</strong>：这是一个困扰了数学家几十年的组合数学难题。FunSearch 发现了比人类已知方法更大的上限集构造方案，这是首次由 LLM 在这类具有挑战性的科学问题上做出新发现。</li><li><strong>在线装箱问题（Bin Packing Problem）</strong>：这是一个经典的组合优化问题，旨在找到最有效的方式将不同大小的物品装入有限数量的箱子。FunSearch 发现了一种比人类常用启发式算法更优的策略。</li></ul><p><strong>EoH 旨在通过进化思想和代码，模拟人类专家进行启发式开发的过程，从而实现高效的自动启发式设计。</strong></p><p><strong>1.每次实验，系统允许大语言模型以自然语言形式生成启发式算法与对应的代码实现。</strong></p><p><strong>2.采用五种提示策略来指导 LLM 对现有思想和代码进行推理</strong></p><p><strong>3.进化出一组候选启发式算法，它利用大语言模型在遗传算子（如交叉变异）种生成新的启发式算法，并通过选择机制引导搜索过程并评估</strong></p><p><strong>与大多数进化算法中个体是优化问题的候选解不同，我们认为“思想”的进化应该是一个重要的研究方向</strong></p><p><strong>进化框架：</strong></p><p><strong>第 0 步：初始化 (Initialization)</strong></p><ul><li><strong>通过特定的“初始化提示”（Initialization prompt）来请求大型语言模型（LLM），生成一个包含 N 个初始启发式算法的种群 P。</strong></li><li><strong>每个生成的启发式算法都会被评估其性能，并被赋予一个适应度值（fitness value）。</strong></li></ul><p><strong>第 1 步：生成新的启发式算法 (Generation of Heuristics)</strong></p><ul><li><strong>只要未达到停止条件（例如，预设的代数），系统就会同时使用五种不同的“演化提示策略”（Evolution prompt strategies）来生成总共 5N 个新的启发式算法。</strong></li><li><strong>对于这五种策略中的每一种，都会重复执行 N 次以下子流程：</strong><ul><li><strong>第 1.1 步：选择父辈</strong>：从当前种群中选择一个或多个父辈启发式算法来构建提示。父辈的选择是基于其适应度排名，排名越高的个体被选中的概率越低（公式为 pi∝1/(ri+N)，其中 ri 是排名），这鼓励了对种群中更多样化个体的探索。</li><li><strong>第 1.2 步：生成新个体</strong>：请求 LLM 根据提示生成一个新的启发式算法，包括其“思想”（自然语言描述）和对应的“代码”实现。</li><li><strong>第 1.3 步：评估</strong>：在指定的评估实例集上运行新生成的启发式算法，以确定其适应度值。</li><li><strong>第 1.4 步：加入种群</strong>：如果新生成的启发式算法及其代码是可行的（例如，没有语法错误），就将其添加到当前种群中。</li></ul></li></ul><p><strong>第 2 步：种群管理 (Population Management)</strong></p><ul><li><strong>在生成了多达 5N 个新个体后，将它们与原有的 N 个个体合并。</strong></li><li><strong>从这个扩大的种群中，选择出适应度值最高的 N 个启发式算法，形成下一代的种群。</strong></li><li><strong>之后，返回第 1 步，开始新一轮的演化。</strong></li></ul><h4 id="步骤-0-初始化-initialization"><a class="markdownIt-Anchor" href="#步骤-0-初始化-initialization"></a> <strong>步骤 0: 初始化 (Initialization)</strong></h4><ul><li><strong>目标</strong>：创建初始种群。</li><li><strong>过程</strong>：框架首先会创建一个包含 <code>N</code> 个启发式算法的初始种群 <code>P</code> 。这些初始算法并非由人类专家提供，而是通过向 LLM 发送“初始化提示”（Initialization prompt）自动生成的，从而减少了对专家知识的依赖 。这个过程会重复<br /><code>N</code> 次，以获得 <code>N</code> 个初始启发式算法 。</li></ul><h4 id="步骤-1-新启发式算法的生成-generation-of-heuristics"><a class="markdownIt-Anchor" href="#步骤-1-新启发式算法的生成-generation-of-heuristics"></a> <strong>步骤 1: 新启发式算法的生成 (Generation of Heuristics)</strong></h4><ul><li><strong>目标</strong>：通过进化操作产生新的、可能更优的启发式算法。</li><li><strong>过程</strong>：只要未达到停止条件（例如，预设的代数），框架就会利用五种不同的“进化提示策略”（Evolution prompt strategies）来生成新的启发式算法 。这些策略分为两大类 ：<ul><li><strong>探索 (Exploration)</strong>：如 E1 和 E2 策略，旨在通过类似交叉的操作探索启发式算法空间，产生与父代差异较大的新想法 。</li><li><strong>修改 (Modification)</strong>：如 M1, M2, M3 策略，旨在通过微调、修改参数或简化冗余部分来优化某个父代启发式算法 。</li></ul></li><li>**在每一代中，这五种策略会同时被使用，每个策略均被调用 **<br /><code>N</code> 次，从而生成最多 <code>5N</code> 个新的启发式算法 。</li><li><strong>生成每一个新算法的具体流程如下：</strong><ol><li><strong>选择父代 (Parent Selection)</strong>：从当前种群中选择一个或多个父代启发式算法 。选择过程可以基于适应度排名，适应度高的个体有更高的被选中概率 。</li><li><strong>生成新个体 (Generation)</strong>：将选定的父代（包括其“思想”和“代码”）和相应的策略指令构建成一个提示，请求 LLM 生成一个新的启发式算法（包括新的“思想”和“代码”） 。</li><li><strong>评估 (Evaluation)</strong>：在新生成代码可行的情况下，将其在一组评估实例上运行，以计算出其适应度值 。</li><li><strong>加入种群 (Addition)</strong>：将这个经过评估且可行的新启发式算法添加到当前种群中 。</li></ol></li></ul><h4 id="步骤-2-种群管理-population-management"><a class="markdownIt-Anchor" href="#步骤-2-种群管理-population-management"></a> <strong>步骤 2: 种群管理 (Population Management)</strong></h4><ul><li><strong>目标</strong>：为下一代选择优胜者。</li><li><strong>过程</strong>：在 <code>5N</code> 个新个体生成并加入后，种群规模会临时扩大。此时，框架会从扩大的种群中选择适应度最高的 <code>N</code> 个启发式算法，形成下一代的种群 。</li><li><strong>之后，算法返回****步骤 1</strong>，开始新一代的进化 。<br /><strong>Heuristic Representation：</strong></li></ul><ol><li><strong>自然语言描述 (Natural Language Description)</strong><ul><li><strong>这部分由几句自然语言组成，被称作“思想”（thought） 。</strong></li><li><strong>它由大型语言模型（LLM）创建，用于呈现启发式算法的高级思想和核心逻辑 。</strong></li></ul></li><li><strong>代码块 (Code Block)</strong><ul><li><strong>这是对上述“思想”的具体编程实现 。</strong></li><li><strong>代码必须遵循预定义的格式，以便 EoH 框架能够自动识别和无缝集成 。在实验中，这通常实现为一个 Python 函数 。</strong></li><li><strong>为了格式化代码块，需要明确指定三个基本组成部分：函数名称、输入变量和输出变量 。</strong></li></ul></li><li><strong>适应度值 (Fitness Value)</strong><ul><li><strong>每个启发式算法都会被赋予一个适应度值 。</strong></li><li><strong>这个值是通过在指定问题的一组实例上运行该启发式算法，并评估其性能而获得的 。</strong></li></ul></li></ol><h1 id="提示词"><a class="markdownIt-Anchor" href="#提示词"></a> 提示词</h1><p><strong>初始化提示在我们的实验中，我们使用语言模型 （LLMs）生成所有初始启发式算法，无需依赖专家知识。</strong></p><h3 id="探索策略-exploration-strategies"><a class="markdownIt-Anchor" href="#探索策略-exploration-strategies"></a> 探索策略 (Exploration Strategies)</h3><p><strong>探索策略专注于通过对父代启发式算法进行类似交叉的操作来探索更广阔的算法空间 。</strong></p><ul><li><strong>E1: 差异化探索</strong><br /><strong>目标</strong>: 生成与父代尽可能不同的新启发式算法 。<br /><strong>过程</strong>: 首先，从当前种群中选择 <code>p</code> 个父代启发式算法 。然后，提示大型语言模型（LLM）设计一个在思想上与这些父代尽可能不同的新算法，以探索全新的思路 。</li><li><strong>E2: 共同思想探索</strong><br /><strong>目标</strong>: 探索与父代共享相同核心思想但实现方式不同的新启发式算法 。<br /><strong>过程</strong>: 首先，从当前种群中选择 <code>p</code> 个父代 。然后，指令 LLM 识别这些算法背后的共同思想 。接着，要求 LLM 在这些共同思想的基础上，通过引入新元素来设计一个尽可能与父代不同的新算法 。</li></ul><h3 id="修改策略-modification-strategies"><a class="markdownIt-Anchor" href="#修改策略-modification-strategies"></a> 修改策略 (Modification Strategies)</h3><p><strong>修改策略专注于通过调整、修改参数或简化来优化单个父代启发式算法 。</strong></p><ul><li><strong>M1: 性能改进</strong><br /><strong>目标</strong>: 修改一个启发式算法以获得更好的性能 。<br /><strong>过程</strong>: 从种群中选择一个启发式算法 。然后，提示 LLM 对其进行修改，以产生一个新的版本 。</li><li><strong>M2: 参数调整</strong><br /><strong>目标</strong>: 修改一个已选启发式算法的参数 。<br /><strong>过程</strong>: 从种群中选择一个启发式算法 。然后，提示 LLM 尝试在该算法中调整参数，而不是设计一个全新的算法 。</li><li><strong>M3: 简化与去冗余</strong><br /><strong>目标</strong>: 通过移除冗余组件来简化启发式算法 。<br /><strong>过程</strong>: 从种群中选择一个启发式算法 。然后，提示 LLM 分析并识别其主要组成部分，并判断是否存在冗余 。最后，要求 LLM 根据其分析结果来简化该算法的代码实现 。</li></ul><p><strong>选择机制：</strong></p><h3 id="排序与排名"><a class="markdownIt-Anchor" href="#排序与排名"></a> 排序与排名</h3><ul><li><strong>把种群中的所有启发式算法按****适应度</strong>从好到坏排序。</li><li><strong>排名 <strong>r_i</strong> 是启发式算法 i 的位置（最好的是 1，最差是 N）。</strong></li></ul><p><strong>选择的概率公式：<strong>p_i</strong>∝1/(<strong>r_i</strong>+N)</strong></p><p><strong>概率与排名与 N 的和成反比</strong></p><p><strong>也就是排名越好，概率越大</strong></p><p><strong>排名越差，值越小，但永远不会是零（所以最差的启发式也有机会被选中）。</strong></p><p><strong>加上 N 可以让概率差距变小，保证****探索性</strong>，防止过早陷入局部最优。</p><h1 id="实验"><a class="markdownIt-Anchor" href="#实验"></a> 实验</h1><p><strong>在线装箱问题：</strong></p><p>**这个问题的目标是将一系列不同大小的物品，放入尽可能少的、具有固定容量 **</p><p><code>C</code> 的箱子中 。实验重点关注的是“在线场景”，即物品是依次到达的，每当一个物品到达时，必须立即决定将其放入哪个箱子，而不能等待后续物品的信息 。</p><p><strong>评估实例</strong>: 在启发式算法的进化过程中，其性能是在五个大小为 5k（即 5000 个物品）、容量为 100 的 Weibull 实例上进行评估的 。</p><p><strong>Weibull 实例是指物品大小遵循 Weibull 分布的装箱问题实例，这种分布常用于模拟实际应用中的物品大小。</strong></p><p><strong>适应度计算</strong>: 一个启发式算法的适应度值被设定为在这五个实例上 lb/n 的平均值 。</p><ul><li><strong>其中，</strong> lb ** 代表理论上最优解（即最少箱子数）的下限 。比如直接总容量除以单个容量**</li><li><strong>n 是被评估的启发式算法完成所有物品装箱后，实际使用的箱子总数 。</strong><br /><strong>这个比率越高，说明算法使用的箱子数越接近理论最优值，性能也就越好。</strong></li></ul><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813091735990.png" alt="image-20250813091735990" /></p><p><strong>比较方法即 人工 +funsearch</strong></p><p><strong>tsp</strong></p><h3 id="目标-objective"><a class="markdownIt-Anchor" href="#目标-objective"></a> 目标 (Objective)</h3><p><strong>旅行商问题（TSP）的目标是找到一条最短的路线，这条路线需要访问所有给定的地点各一次，并最终返回到出发点 。它是一个被广泛研究的组合优化问题，也是一个常用的启发式算法测试平台 。</strong></p><h3 id="评估设置-evaluation-setup"><a class="markdownIt-Anchor" href="#评估设置-evaluation-setup"></a> 评估设置 (Evaluation Setup)</h3><p><strong>评估实例</strong>: 启发式算法的进化（训练）过程是在一组 64 个 TSP100（即 100 个地点）的实例上进行的 。这些实例中的地点位置是从一个 [0, 1]² 的二维空间中随机抽样生成的 。</p><p><strong>也就是六十四个场景。边长为 1 的正方形区域，100 个地点的位置（即 X, Y 坐标）都是在这个 1x1 的正方形地图上****随机生成</strong>的</p><p><strong>适应度计算</strong>: 一个启发式算法的适应度值，是根据其解法与最优解之间的“平均差距”（average gap）来确定的 。这个用于计算差距的最优解是由一个名为“Concorde”的精确求解器生成的 。</p><p><strong>最优解 (Optimal Solution)</strong>: 对于每一个 TSP 问题，理论上都存在一个唯一的最短路径。研究人员使用一个叫做 <strong>Concorde</strong> 的顶尖求解器，它非常强大，可以计算出这 100 个地点问题的精确最优解</p><p><strong>差距 (Gap)</strong>: 当一个待评估的启发式算法对某个问题给出一个解（一条路径）后，研究人员会计算这个解的长度与“标准答案”的长度之间的百分比差异。这个差异就是“差距（Gap）”。例如，如果标准答案是 100 公里，算法算出来是 102 公里，那么差距就是 2%。</p><p><strong>平均差距 (Average Gap)</strong>: 算法会在全部 64 个实例上运行，得到 64 个“差距”值。最后，计算这 64 个值的<strong>平均数</strong>。</p><p><strong>适应度值 (Fitness Value)</strong>: 这个最终的<strong>平均差距</strong>就被用作该算法的适应度值。这个值越小，说明算法的解越接近最优解，性能就越好。</p><p><strong>比较方法是最近插入法和最远插入法，加上 ORtools</strong></p><p><strong>AI 方面</strong><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813092505786.png" alt="image-20250813092505786" /></p><p><strong>实验细节</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813092653598.png" alt="image-20250813092653598" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813093043080.png" alt="image-20250813093043080" /></p><p><strong>感觉就是人类定了大方向与框架，然后 llm 负责实现与迭代</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813090211212.png" alt="image-20250813090211212" /></p><p><strong>结果：</strong></p><p><strong>X 轴</strong> 代表“进化代数”（Number of generations），从第 1 代到第 20 代。</p><p><strong>Y 轴</strong> 代表“性能”（Performance），这个值越高，说明算法的效果越好。</p><p><strong>红色的折线</strong> 显示了在每一代中发现的最佳启发式算法的性能。您可以看到，性能从最初的 0.9620，经过 20 代的持续优化，最终达到了 0.9932。</p><p><strong>折线上的每个红点都代表一个性能上的“飞跃”，即发现了一个更好的启发式算法。</strong></p><p>**旁边的标注（如 **<strong>E1, E2, M1</strong>）指明了这是由哪一种“提示策略”实现的突破。</p><p>**标注的文字（如 **<code>E2, utilization of cubic root</code>）则是对这个新算法核心思想的简要描述，也就是“思想”（Thought）。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094028517.png" alt="image-20250813094028517" /></p><p><strong>人类想到的，算出一个物品大小和容量，然后做差，差最大的说明放完东西后，箱子剩下的空间最小</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094351634.png" alt="image-20250813094351634" /></p><p><strong>AI 想到的，</strong><code>comb1</code> 项通过 <code>(bins - max_bin)**2</code> 惩罚那些容量较大（较空）的箱子，鼓励利用已部分填充的箱子。</p><p><code>comb2</code> 和 <code>comb3</code> 项则包含了物品大小和箱子容量的二次方和三次方关系。</p><p><strong>但是物理意义不直观</strong></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094544302.png" alt="image-20250813094544302" /></p><p><strong>EoH，显式地融合了多种启发式思想：</strong></p><ol><li><strong>利用率 (<code>ulti</code>)</strong>: 衡量放入物品后箱子有多满。</li><li><strong>动态调整 (<code>adjust</code>)</strong>: 使用 <code>where</code> 条件语句，根据剩余空间和物品大小的关系，采取不同的策略，实现了“惩罚大箱子”的逻辑。</li><li><strong>混合分数 (<code>hybrid_exp</code>, <code>adjust</code>)</strong>: 将多个不同来源的启发式思想（如指数衰减、利用率、条件惩罚）组合成最终的得分。</li></ol><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813094817807.png" alt="image-20250813094817807" /></p><p><strong>消融研究指的是，为了理解一个复杂模型或系统的各个组成部分的重要性，而系统性地“移除”或“简化”其中一个或多个组件，然后观察整个系统性能变化的一种实验方法。</strong></p><p><strong>根据论文 4.3 节的描述，作者进行消融研究的目的是“为了更好地理解 EoH 中主要组成部分的贡献” 。</strong></p><p><strong>具体做法是，他们创建了几个“被削弱”的 EoH 版本，并与完整的 EoH 模型进行性能比较：</strong></p><p><strong>移除了“思想”部分</strong>: 他们创建了一个名为 <code>EoC</code> (Evolution of Codes) 的版本。这个版本只进化代码，完全没有自然语言的“思想”部分，以此来验证“思想”这个组件的价值 。</p><p><strong>移除了部分“提示策略”</strong>: 他们还创建了 <code>EoH-e1</code> 和 <code>EoH-e2</code> 版本。这些版本虽然保留了“思想”，但只使用了五种提示策略中的一种或两种 。</p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813095229016.png" alt="image-20250813095229016" /></p><p><img src="https://raw.githubusercontent.com/zjncs/TyporaPic/main/imaimage-20250813095444591.png" alt="image-20250813095444591" /></p><h1 id="讨论"><a class="markdownIt-Anchor" href="#讨论"></a> 讨论</h1><p><strong>为了证明 EoH 中“思想”（自然语言描述）和“代码”共同进化是其核心优势，研究者进行了对比实验 。</strong></p><p><strong>实验设置</strong>: 他们将完整的 EoH 与几个变体进行了比较 ：</p><p><code>C2C</code>: 只进化代码，没有“思想”部分 。</p><p><code>T2T2C</code>: 只在进化中使用“思想”表示，需要时再由 LLM 生成代码用于评估 。</p><p><code>T&amp;C2T2C</code>: 进化时同时使用“思想”和“代码”作为输入，但只让 LLM 输出新的“思想”</p><p><strong>结论</strong>: 实验结果（表 6）明确表明，只进化代码（C2C）或只进化思想（T2T2C）的效果远不如完整的 EoH 。这有力地证明了**“思想”和“代码”的共同进化对 EoH 的成功做出了重大贡献** 。</p><h4 id="不同大型语言模型的影响-different-llms"><a class="markdownIt-Anchor" href="#不同大型语言模型的影响-different-llms"></a> <strong>不同大型语言模型的影响 (Different LLMs)</strong></h4><p><strong>研究者测试了 EoH 在使用不同 LLM 时的性能，包括 GPT-3.5、Gemini Pro、CodeLlama 和 Deepseek 。</strong></p><ul><li><strong>结论</strong>:<ul><li><strong>EoH 在使用这些不同的 LLM 时，都能够生成性能良好的启发式算法 。</strong></li><li><strong>即使只进行 2000 次查询，其性能也优于随机查询 GPT-3.5 一万次的结果 。</strong></li><li><strong>尽管如此，实验结果也显示，使用更强大的 LLM（如 GPT-3.5 和 Gemini Pro）能带来更好的性能 。</strong></li></ul></li></ul><h4 id="利用专家启发式算法-use-of-expert-heuristic"><a class="markdownIt-Anchor" href="#利用专家启发式算法-use-of-expert-heuristic"></a> <strong>利用专家启发式算法 (Use of Expert Heuristic)</strong></h4><p><strong>研究者探究了将一个已知的、由人类专家或其它 AI 系统设计的优秀算法（专家启发式算法）放入 EoH 的初始种群中会产生什么影响 。</strong></p><p><strong>实验设置</strong>: 他们将 FunSearch 论文中提供的优秀启发式算法放入 EoH 的初始种群，并将这个版本称为 <code>EoH expert</code> 。</p><p><strong>结论</strong>: 结果显示，<code>EoH expert</code> 的性能明显超过了原始的 EoH 和 FunSearch 。这表明，<strong>EoH 框架可以有效地继承和进化已有的专家知识，从而产生更优秀的下一代算法</strong> 。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;源码及文章：&lt;a href=&quot;https://github.com/FeiLiu36/EoH/blob/main/README_CN.md&quot;&gt;EoH/README_CN.md at main · FeiLiu36/EoH&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Evoluti</summary>
      
    
    
    
    <category term="llm+" scheme="https://zjncs.github.io/categories/llm/"/>
    
    
    <category term="论文" scheme="https://zjncs.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>链表双指针0808</title>
    <link href="https://zjncs.github.io/2025/08/08/%E9%93%BE%E8%A1%A8%E5%8F%8C%E6%8C%87%E9%92%880808/"/>
    <id>https://zjncs.github.io/2025/08/08/%E9%93%BE%E8%A1%A8%E5%8F%8C%E6%8C%87%E9%92%880808/</id>
    <published>2025-08-08T07:17:53.000Z</published>
    <updated>2025-08-08T07:18:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="3"><a class="markdownIt-Anchor" href="#3"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.09-Exercises?id=_3-0019-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%AC-n-%E4%B8%AA%E7%BB%93%E7%82%B9">3.</a><a href="https://leetcode.cn/problems/remove-nth-node-from-end-of-list/">0019. 删除链表的倒数第 N 个结点</a></h2><h3 id="31-题目大意"><a class="markdownIt-Anchor" href="#31-题目大意"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.09-Exercises?id=_31-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">3.1 题目大意</a></h3><p><strong>描述</strong>：给定一个链表的头节点 <code>head</code>。</p><p><strong>要求</strong>：删除链表的倒数第 <code>n</code> 个节点，并且返回链表的头节点。</p><p><strong>说明</strong>：</p><ul><li><strong>要求使用一次遍历实现。</strong></li><li>**链表中结点的数目为 **<code>sz</code>。</li></ul><p><strong>示例</strong>：</p><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024001901.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2,3,4,5], n = 2</span><br><span class="line"> 输出：[1,2,3,5]</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> 输入：head = [1], n = 1</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">     def removeNthFromEnd(self, head: Optional[ListNode], n: int) -&gt; Optional[ListNode]:</span><br><span class="line">         slow, fast = head, head</span><br><span class="line">         </span><br><span class="line">         # fast 先走 n 步</span><br><span class="line">         for _ in range(n):</span><br><span class="line">             fast = fast.next</span><br><span class="line">         </span><br><span class="line">         # 如果 fast 走到 None，说明删除的是头节点</span><br><span class="line">         if not fast:</span><br><span class="line">             return head.next</span><br><span class="line">         </span><br><span class="line">         # 同步移动，直到 fast 到最后一个节点</span><br><span class="line">         while fast.next:</span><br><span class="line">             slow = slow.next</span><br><span class="line">             fast = fast.next</span><br><span class="line">         </span><br><span class="line">         # 删除 slow.next 节点</span><br><span class="line">         slow.next = slow.next.next</span><br><span class="line">         return head</span><br><span class="line"> </span><br></pre></td></tr></table></figure><ul><li><a href="https://leetcode.cn/problems/middle-of-the-linked-list/">876. 链表的中间结点 - 力扣（LeetCode）</a></li></ul><h4 id="342-题目大意"><a class="markdownIt-Anchor" href="#342-题目大意"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.08-Linked-List-Two-Pointers?id=_342-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">3.4.2 题目大意</a></h4><p><strong>描述</strong>：给定一个单链表的头节点 <code>head</code>。</p><p><strong>要求</strong>：返回链表的中间节点。如果有两个中间节点，则返回第二个中间节点。</p><p><strong>说明</strong>：</p><ul><li>**给定链表的结点数介于 **<code>1</code> 和 <code>100</code> 之间。</li></ul><p><strong>示例</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> 输入：[1,2,3,4,5]</span><br><span class="line"> 输出：此列表中的结点 3 (序列化形式：[3,4,5])</span><br><span class="line"> 解释：返回的结点值为 3 。</span><br><span class="line"> 注意，我们返回了一个 ListNode 类型的对象 ans，这样：</span><br><span class="line"> ans.val = 3, ans.next.val = 4, ans.next.next.val = 5, 以及 ans.next.next.next = NULL.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> 输入：[1,2,3,4,5,6]</span><br><span class="line"> 输出：此列表中的结点 4 (序列化形式：[4,5,6])</span><br><span class="line"> 解释：由于该列表有两个中间结点，值分别为 3 和 4，我们返回第二个结点。</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">     def middleNode(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         slow, fast = head, head</span><br><span class="line">         while fast and fast.next:</span><br><span class="line">             slow = slow.next</span><br><span class="line">             fast = fast.next.next</span><br><span class="line">         return slow</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;3&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.09-Exerci</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>链表排序0807</title>
    <link href="https://zjncs.github.io/2025/08/07/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0807/"/>
    <id>https://zjncs.github.io/2025/08/07/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0807/</id>
    <published>2025-08-07T08:32:08.000Z</published>
    <updated>2025-08-07T09:05:02.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="2"><a class="markdownIt-Anchor" href="#2"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_2-0021-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8">2.</a><a href="https://leetcode.cn/problems/merge-two-sorted-lists/">0021. 合并两个有序链表</a></h2><h3 id="21-题目大意"><a class="markdownIt-Anchor" href="#21-题目大意"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_21-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">2.1 题目大意</a></h3><p><strong>描述</strong>：给定两个升序链表的头节点 <code>list1</code> 和 <code>list2</code>。</p><p><strong>要求</strong>：将其合并为一个升序链表。</p><p><strong>说明</strong>：</p><ul><li><strong>两个链表的节点数目范围是 。</strong></li><li><code>list1</code> 和 <code>list2</code> 均按 <strong>非递减顺序</strong> 排列</li></ul><p><strong>示例</strong>：</p><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024002101.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> 输入：list1 = [1,2,4], list2 = [1,3,4]</span><br><span class="line"> 输出：[1,1,2,3,4,4]</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> 输入：list1 = [], list2 = []</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> class ListNode:</span><br><span class="line">     def __init__(self, val=0, next=None):</span><br><span class="line">         self.val = val</span><br><span class="line">         self.next = next</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> class Solution:</span><br><span class="line">     def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         # 创建一个哑节点 dummy，它的 next 最后会指向合并后的链表头</span><br><span class="line">         dummy = ListNode(-1)</span><br><span class="line">         current = dummy</span><br><span class="line"> </span><br><span class="line">         # 遍历两个链表，哪个值小就接到 current 后面</span><br><span class="line">         while list1 and list2:</span><br><span class="line">             if list1.val &lt;= list2.val:</span><br><span class="line">                 current.next = list1</span><br><span class="line">                 list1 = list1.next</span><br><span class="line">             else:</span><br><span class="line">                 current.next = list2</span><br><span class="line">                 list2 = list2.next</span><br><span class="line">             current = current.next  # 移动 current 指针</span><br><span class="line"> </span><br><span class="line">         # 把剩余的链表接上（最多只有一个不为 None）</span><br><span class="line">         current.next = list1 if list1 else list2</span><br><span class="line"> </span><br><span class="line">         # 返回合并后的链表头</span><br><span class="line">         return dummy.next</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p>**在新建链表的时候，我们可以选择用哑节点加指针的方式来简化代码逻辑。哑节点是一个不存储实际数据的节点，它的 **<code>next</code> 最终会指向合并后的链表头。</p><h2 id="3"><a class="markdownIt-Anchor" href="#3"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_3-0148-%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8">3.</a><a href="https://leetcode.cn/problems/sort-list/">0148. 排序链表</a></h2><h3 id="31-题目大意"><a class="markdownIt-Anchor" href="#31-题目大意"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_31-%E9%A2%98%E7%9B%AE%E5%A4%A7%E6%84%8F">3.1 题目大意</a></h3><p><strong>描述</strong>：给定链表的头节点 <code>head</code>。</p><p><strong>要求</strong>：按照升序排列并返回排序后的链表。</p><p><strong>说明</strong>：</p><ul><li><strong>链表中节点的数目在范围 内。</strong></li></ul><p><strong>示例</strong>：</p><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024014801.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [4,2,1,3]</span><br><span class="line"> 输出：[1,2,3,4]Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><p><img src="https://datawhalechina.github.io/leetcode-notes/images/20201024014802.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [-1,5,3,4,0]</span><br><span class="line"> 输出：[-1,0,3,4,5]</span><br></pre></td></tr></table></figure><p><strong>解法：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"> class Solution:</span><br><span class="line">     def sortList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         # Base case</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return head</span><br><span class="line"> </span><br><span class="line">         # Step 1: Split the list into two halves</span><br><span class="line">         slow, fast = head, head.next</span><br><span class="line">         while fast and fast.next:</span><br><span class="line">             slow = slow.next</span><br><span class="line">             fast = fast.next.next</span><br><span class="line"> </span><br><span class="line">         mid = slow.next</span><br><span class="line">         slow.next = None  # Cut the list</span><br><span class="line"> </span><br><span class="line">         # Step 2: Sort each half recursively</span><br><span class="line">         left = self.sortList(head)</span><br><span class="line">         right = self.sortList(mid)</span><br><span class="line"> </span><br><span class="line">         # Step 3: Merge the sorted halves</span><br><span class="line">         return self.merge(left, right)</span><br><span class="line"> </span><br><span class="line">     def merge(self, list1: ListNode, list2: ListNode) -&gt; ListNode:</span><br><span class="line">         dummy = ListNode(0)</span><br><span class="line">         tail = dummy</span><br><span class="line"> </span><br><span class="line">         while list1 and list2:</span><br><span class="line">             if list1.val &lt;= list2.val:</span><br><span class="line">                 tail.next = list1</span><br><span class="line">                 list1 = list1.next</span><br><span class="line">             else:</span><br><span class="line">                 tail.next = list2</span><br><span class="line">                 list2 = list2.next</span><br><span class="line">             tail = tail.next</span><br><span class="line"> </span><br><span class="line">         # Connect remaining nodes</span><br><span class="line">         tail.next = list1 if list1 else list2</span><br><span class="line">         return dummy.next</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p><strong>这里其实用到了上一题的函数，也就是合并链表并排序。我们先将链表分成两半，然后递归地对每一半进行排序，最后再合并两个已排序的链表。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;2&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exerci</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>链表排序0806</title>
    <link href="https://zjncs.github.io/2025/08/06/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0806/"/>
    <id>https://zjncs.github.io/2025/08/06/%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F0806/</id>
    <published>2025-08-06T01:49:32.000Z</published>
    <updated>2025-08-06T01:51:12.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-链表排序简介"><a class="markdownIt-Anchor" href="#1-链表排序简介"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.05-Linked-List-Sort?id=_1-%E9%93%BE%E8%A1%A8%E6%8E%92%E5%BA%8F%E7%AE%80%E4%BB%8B">1. 链表排序简介</a></h2><p><strong>在数组排序中，常见的排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序、计数排序、桶排序、基数排序等。</strong></p><p>**而对于链表排序而言，因为链表不支持随机访问，访问链表后面的节点只能依靠 **<code>next</code> 指针从头部顺序遍历，所以相对于数组排序问题来说，链表排序问题会更加复杂一点。</p><p><strong>下面先来总结一下适合链表排序与不适合链表排序的算法：</strong></p><ul><li>**适合链表的排序算法：**<strong>冒泡排序</strong>、<strong>选择排序</strong>、<strong>插入排序</strong>、<strong>归并排序</strong>、<strong>快速排序</strong>、<strong>计数排序</strong>、<strong>桶排序</strong>、<strong>基数排序</strong>。</li><li>**不适合链表的排序算法：**<strong>希尔排序</strong>。</li><li>**可以用于链表排序但不建议使用的排序算法：**<strong>堆排序</strong>。</li></ul><blockquote><p><strong>希尔排序为什么不适合链表排序？</strong></p></blockquote><p><strong>希尔排序</strong>：希尔排序中经常涉及到对序列中第 <code>i + gap</code> 的元素进行操作，其中 <code>gap</code> 是希尔排序中当前的步长。而链表不支持随机访问的特性，导致这种操作不适合链表，因而希尔排序算法不适合进行链表排序。</p><blockquote><p><strong>为什么不建议使用堆排序？</strong></p></blockquote><p><strong>堆排序</strong>：堆排序所使用的最大堆 / 最小堆结构本质上是一棵完全二叉树。而完全二叉树适合采用顺序存储结构（数组）。因为数组存储的完全二叉树可以很方便的通过下标序号来确定父亲节点和孩子节点，并且可以极大限度的节省存储空间。</p><p><strong>而链表用在存储完全二叉树的时候，因为不支持随机访问的特性，导致其寻找子节点和父亲节点会比较耗时，如果增加指向父亲节点的变量，又会浪费大量存储空间。所以堆排序算法不适合进行链表排序。</strong></p><p><strong>如果一定要对链表进行堆排序，则可以使用额外的数组空间表示堆结构。然后将链表中各个节点的值依次添加入堆结构中，对数组进行堆排序。排序后，再按照堆中元素顺序，依次建立链表节点，构建新的链表并返回新链表头节点。</strong></p><h2 id="1"><a class="markdownIt-Anchor" href="#1"></a> <a href="https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/02.01.06-Exercises?id=_1-0147-%E5%AF%B9%E9%93%BE%E8%A1%A8%E8%BF%9B%E8%A1%8C%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F">1.</a><a href="https://leetcode.cn/problems/insertion-sort-list/">0147. 对链表进行插入排序</a></h2><p>**给定单个链表的头 **<code>head</code> ，使用 <strong>插入排序</strong> 对链表进行排序，并返回 <em>排序后链表的头</em> 。</p><p><strong>插入排序</strong> 算法的步骤:</p><ol><li><strong>插入排序是迭代的，每次只移动一个元素，直到所有元素可以形成一个有序的输出列表。</strong></li><li><strong>每次迭代中，插入排序只从输入数据中移除一个待排序的元素，找到它在序列中适当的位置，并将其插入。</strong></li><li><strong>重复直到所有输入数据插入完为止。</strong></li></ol><p><strong>下面是插入排序算法的一个图形示例。部分排序的列表(黑色)最初只包含列表中的第一个元素。每次迭代时，从输入数据中删除一个元素(红色)，并就地插入已排序的列表中。</strong></p><p><strong>对链表进行插入排序。</strong></p><p><img src="https://pic.leetcode.cn/1724130387-qxfMwx-Insertion-sort-example-300px.gif" alt="img" /></p><hr /><p><strong>示例 1：</strong></p><p><img src="https://pic.leetcode.cn/1724130414-QbPAjl-image.png" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [4,2,1,3]</span><br><span class="line"> 输出: [1,2,3,4]</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><p><img src="https://pic.leetcode.cn/1724130432-zoOvdI-image.png" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [-1,5,3,4,0]</span><br><span class="line"> 输出: [-1,0,3,4,5]</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> </span><br><span class="line"> class Solution:</span><br><span class="line">     def insertionSortList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return head</span><br><span class="line">         </span><br><span class="line">         # 创建一个哨兵节点（虚拟头节点）</span><br><span class="line">         dummy = ListNode(0)</span><br><span class="line">         dummy.next = head</span><br><span class="line">         </span><br><span class="line">         # 已排序部分的最后一个节点</span><br><span class="line">         last_sorted = head</span><br><span class="line">         # 当前要插入的节点</span><br><span class="line">         current = head.next</span><br><span class="line">         </span><br><span class="line">         while current:</span><br><span class="line">             if current.val &gt;= last_sorted.val:</span><br><span class="line">                 # 当前节点已经在正确位置，无需移动</span><br><span class="line">                 last_sorted = last_sorted.next</span><br><span class="line">             else:</span><br><span class="line">                 # 从头开始找插入位置</span><br><span class="line">                 prev = dummy</span><br><span class="line">                 while prev.next and prev.next.val &lt; current.val:</span><br><span class="line">                     prev = prev.next</span><br><span class="line">                 </span><br><span class="line">                 # 插入 current 节点到 prev 和 prev.next 之间</span><br><span class="line">                 last_sorted.next = current.next  # 断开 current</span><br><span class="line">                 current.next = prev.next</span><br><span class="line">                 prev.next = current</span><br><span class="line"> </span><br><span class="line">             # 移动 current 指针</span><br><span class="line">             current = last_sorted.next</span><br><span class="line">         </span><br><span class="line">         return dummy.next</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-链表排序简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#1-链表排序简介&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://datawhalechina.github.io/leetcode-notes/#/ch02/02.01/0</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>链表0805</title>
    <link href="https://zjncs.github.io/2025/08/05/%E9%93%BE%E8%A1%A80805/"/>
    <id>https://zjncs.github.io/2025/08/05/%E9%93%BE%E8%A1%A80805/</id>
    <published>2025-08-05T08:42:50.000Z</published>
    <updated>2025-08-06T01:50:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0203-移除链表元素"><a class="markdownIt-Anchor" href="#0203-移除链表元素"></a> <a href="https://leetcode.cn/problems/remove-linked-list-elements/">0203. 移除链表元素</a></h2><p>**给你一个链表的头节点 **<code>head</code> 和一个整数 <code>val</code> ，请你删除链表中所有满足 <code>Node.val == val</code> 的节点，并返回 <strong>新的头节点</strong> 。</p><p><strong>示例 1：</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/06/removelinked-list.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2,6,3,4,5,6], val = 6</span><br><span class="line"> 输出：[1,2,3,4,5]</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [], val = 1</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p><strong>示例 3：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [7,7,7,7], val = 7</span><br><span class="line"> 输出：[]</span><br></pre></td></tr></table></figure><p>** **<strong>提示：</strong></p><ul><li>**列表中的节点数目在范围 **<code>[0, 104]</code> 内</li><li><code>1 &lt;= Node.val &lt;= 50</code></li><li><code>0 &lt;= val &lt;= 50</code></li></ul><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> class Solution:</span><br><span class="line">     def removeElements(self, head: Optional[ListNode], val: int) -&gt; Optional[ListNode]:</span><br><span class="line">         dummy = ListNode(0)</span><br><span class="line">         dummy.next = head</span><br><span class="line">         current = dummy</span><br><span class="line">         #创建了虚拟头结点</span><br><span class="line">         while current and current.next:</span><br><span class="line">             if current.next.val==val:</span><br><span class="line">                 current.next=current.next.next</span><br><span class="line">             else : current=current.next</span><br><span class="line">         return dummy.next</span><br><span class="line">         </span><br></pre></td></tr></table></figure><p><strong>这里创建了虚拟头结点，目的就是为了方便删除头结点的情况，便于统一管理所有结点</strong></p><h2 id="0328-奇偶链表"><a class="markdownIt-Anchor" href="#0328-奇偶链表"></a> <a href="https://leetcode.cn/problems/odd-even-linked-list/">0328. 奇偶链表</a></h2><p>**给定单链表的头节点 **<code>head</code> ，将所有索引为奇数的节点和索引为偶数的节点分别分组，保持它们原有的相对顺序，然后把偶数索引节点分组连接到奇数索引节点分组之后，返回重新排序的链表。</p><p><strong>第一个</strong>节点的索引被认为是 <strong>奇数</strong> ， <strong>第二个</strong>节点的索引为 <strong>偶数</strong> ，以此类推。</p><p><strong>请注意，偶数组和奇数组内部的相对顺序应该与输入时保持一致。</strong></p><p>**你必须在 **<code>O(1)</code> 的额外空间复杂度和 <code>O(n)</code> 的时间复杂度下解决这个问题。</p><hr /><p><strong>示例 1:</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/10/oddeven-linked-list.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [1,2,3,4,5]</span><br><span class="line"> 输出: [1,3,5,2,4]</span><br></pre></td></tr></table></figure><p><strong>示例 2:</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/10/oddeven2-linked-list.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入: head = [2,1,3,5,6,4,7]</span><br><span class="line"> 输出: [2,3,6,7,1,5,4]</span><br></pre></td></tr></table></figure><hr /><p><strong>提示:</strong></p><ul><li><code>n == </code> 链表中的节点数</li><li><code>0 &lt;= n &lt;= 104</code></li><li><code>-106 &lt;= Node.val &lt;= 106</code></li></ul><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> class Solution:</span><br><span class="line">     def oddEvenList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return head</span><br><span class="line">         odd = head</span><br><span class="line">         even = head.next</span><br><span class="line">         even_head = even  # 保存偶数链的起点</span><br><span class="line">         while even and even.next:</span><br><span class="line">             odd.next = even.next</span><br><span class="line">             odd = odd.next</span><br><span class="line"> </span><br><span class="line">             even.next = odd.next</span><br><span class="line">             even = even.next</span><br><span class="line"> </span><br><span class="line">         # 连接奇数链尾部到偶数链头</span><br><span class="line">         odd.next = even_head</span><br><span class="line">         return head</span><br></pre></td></tr></table></figure><p><strong>很容易想到快慢指针，但是要先保存偶数链起点的引用，不然就容易丢失</strong></p><h2 id="0234-回文链表"><a class="markdownIt-Anchor" href="#0234-回文链表"></a> <a href="https://leetcode.cn/problems/palindrome-linked-list/">0234. 回文链表</a></h2><p>**给你一个单链表的头节点 **<code>head</code> ，请你判断该链表是否为回文链表。如果是，返回 <code>true</code> ；否则，返回 <code>false</code> 。</p><p><strong>示例 1：</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/03/pal1linked-list.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2,2,1]</span><br><span class="line"> 输出：true</span><br></pre></td></tr></table></figure><p><strong>示例 2：</strong></p><p><img src="https://assets.leetcode.com/uploads/2021/03/03/pal2linked-list.jpg" alt="img" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> 输入：head = [1,2]</span><br><span class="line"> 输出：false</span><br></pre></td></tr></table></figure><p><strong>题解：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"> # Definition for singly-linked list.</span><br><span class="line"> # class ListNode:</span><br><span class="line"> #     def __init__(self, val=0, next=None):</span><br><span class="line"> #         self.val = val</span><br><span class="line"> #         self.next = next</span><br><span class="line"> class Solution:</span><br><span class="line">     def isPalindrome(self, head: Optional[ListNode]) -&gt; bool:</span><br><span class="line">         # 特殊情况：空链表或只有一个节点，必然是回文</span><br><span class="line">         if not head or not head.next:</span><br><span class="line">             return True</span><br><span class="line">         dummy=ListNode(0)</span><br><span class="line">         dummy.next=head</span><br><span class="line">         left,right=dummy,dummy</span><br><span class="line">         while right and right.next:</span><br><span class="line">             right=right.next.next</span><br><span class="line">             left=left.next</span><br><span class="line">         current=head</span><br><span class="line">         second_half_list = []</span><br><span class="line">         while left.next:</span><br><span class="line">             </span><br><span class="line">             second_half_list.append(left.next.val)</span><br><span class="line">             left = left.next</span><br><span class="line">         while second_half_list:</span><br><span class="line">             if current.val != second_half_list.pop():</span><br><span class="line">                 return False</span><br><span class="line">             current = current.next</span><br><span class="line"> </span><br><span class="line">         return True</span><br><span class="line">                      </span><br><span class="line"> </span><br></pre></td></tr></table></figure><p><strong>其实可以直接将整个链表转换成列表，然后用双指针判断是否为回文。</strong></p><p><strong>也可以构造辅助函数，实现原地翻转，这样的空间复杂度是 O(1)。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> # 反转链表的辅助函数</span><br><span class="line">     def reverse(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:</span><br><span class="line">         prev = None</span><br><span class="line">         curr = head</span><br><span class="line">         while curr:</span><br><span class="line">             next_temp = curr.next</span><br><span class="line">             curr.next = prev</span><br><span class="line">             prev = curr</span><br><span class="line">             curr = next_temp</span><br><span class="line">         return prev</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;0203-移除链表元素&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#0203-移除链表元素&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://leetcode.cn/problems/remove-linked-list-elements</summary>
      
    
    
    
    <category term="leetcode" scheme="https://zjncs.github.io/categories/leetcode/"/>
    
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
  <entry>
    <title>Blog搭建指南</title>
    <link href="https://zjncs.github.io/2025/08/05/Blog%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/"/>
    <id>https://zjncs.github.io/2025/08/05/Blog%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/</id>
    <published>2025-08-05T03:28:22.000Z</published>
    <updated>2025-08-05T05:03:01.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>这篇文章将手把手记录我如何搭建自己的技术博客，涵盖 Hexo 博客初始化、主题美化、内容管理到自动部署的完整流程，希望对也想打造自己博客的你有所帮助。</strong></p><hr /><h2 id="一-hexo-初始化与基础配置"><a class="markdownIt-Anchor" href="#一-hexo-初始化与基础配置"></a> 一、Hexo 初始化与基础配置</h2><p><strong>Hexo 是一款基于 Node.js 的静态博客框架，轻量、快速，非常适合开发者记录技术文章。</strong></p><h3 id="初始化项目结构"><a class="markdownIt-Anchor" href="#初始化项目结构"></a> 初始化项目结构</h3><p><strong>确保本地安装了 Node.js 和 Git，然后全局安装 Hexo：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> npm install -g hexo-cli</span><br><span class="line"> hexo init my-blog</span><br><span class="line"> cd my-blog</span><br><span class="line"> npm install</span><br></pre></td></tr></table></figure><p><strong>项目初始化完成后，会看到几个关键目录和文件，比如：</strong></p><ul><li><code>source/</code>：文章目录</li><li><code>themes/</code>：主题目录</li><li><code>_config.yml</code>：博客全局配置文件</li></ul><h3 id="基本信息配置"><a class="markdownIt-Anchor" href="#基本信息配置"></a> 基本信息配置</h3><p>**打开根目录下的 **<code>_config.yml</code>，修改以下内容来设置站点信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> title: Johnny-Zhao&#x27;s TechBlog</span><br><span class="line"> subtitle: KEEP FIGHTING</span><br><span class="line"> author: Johnny-Zhao</span><br><span class="line"> language: zh-CN</span><br><span class="line"> url: https://zjncs.github.io</span><br></pre></td></tr></table></figure><p><strong>接着，安装依赖（推荐使用 yarn）：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> yarn install</span><br></pre></td></tr></table></figure><p><strong>这样 Hexo 的核心环境就搭好了。</strong></p><hr /><h2 id="二-美化博客butterfly-主题配置"><a class="markdownIt-Anchor" href="#二-美化博客butterfly-主题配置"></a> 二、美化博客：Butterfly 主题配置</h2><p><strong>一个好看的博客主题，不光提升观感，还能激发写作动力。我选择的是 Butterfly —— 颜值高、功能全、社区活跃。</strong></p><h3 id="启用主题"><a class="markdownIt-Anchor" href="#启用主题"></a> 启用主题</h3><p>**从 **<a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 仓库</a> 克隆到 <code>themes</code> 目录，并在 <code>_config.yml</code> 中指定：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> theme: butterfly</span><br></pre></td></tr></table></figure><h3 id="个性化配置"><a class="markdownIt-Anchor" href="#个性化配置"></a> 个性化配置</h3><p>**主题的详细配置写在 **<code>_config.butterfly.yml</code> 中，这里记录几个关键改动：</p><ul><li><strong>夜间模式</strong>：支持自动/手动切换</li><li><strong>首页背景图 + 动态头像</strong>：加点动画效果，看着更灵动</li><li><strong>副标题打字机效果</strong>：配上「愿你历尽千帆，归来仍是少年」等短句</li><li><strong>侧边栏组件</strong>：作者简介、公告栏、分类、标签、归档一应俱全</li><li><strong>评论系统</strong>：集成 Giscus，评论数据保存在 GitHub 仓库中</li><li><strong>代码块美化</strong>：mac 风格 + 一键复制 + 语言标识</li><li><strong>数学公式支持</strong>：开启 KaTeX，写公式不再痛苦</li></ul><h3 id="hexo-pro桌面端可视化管理利器"><a class="markdownIt-Anchor" href="#hexo-pro桌面端可视化管理利器"></a> Hexo Pro：桌面端可视化管理利器</h3><p>**除了传统命令行操作，我还使用了 **<a href="https://github.com/jiangtj/hexo-pro">Hexo Pro</a> —— 一款基于 Electron 的桌面客户端。它支持：</p><ul><li><strong>图形化管理文章、分类、标签；</strong></li><li><strong>一键新建、编辑、发布文章；</strong></li><li><strong>直接预览博客样式；</strong></li><li><strong>支持 Hexo 插件管理与主题切换；</strong></li><li><strong>提供 Windows/macOS 版本，开箱即用。</strong></li></ul><p><strong>这对不熟悉命令行或希望更高效率地管理博客内容的用户非常友好，特别适合日常频繁写作的技术人。</strong></p><hr /><h3 id="qexo极致轻量的后端服务推荐"><a class="markdownIt-Anchor" href="#qexo极致轻量的后端服务推荐"></a> Qexo：极致轻量的后端服务推荐</h3><p>**如果你想更进一步，让博客拥有完整的后台管理系统，不妨试试 **<a href="https://github.com/anyesu/qexo">Qexo</a>。</p><p><strong>Qexo 是一个为 Hexo 博客设计的轻量级后台，它的特点包括：</strong></p><ul><li><strong>支持在线创建/修改文章；</strong></li><li><strong>自带图床功能，方便插入图片；</strong></li><li><strong>可搭配 Cloudflare Pages、Vercel、GitHub Pages 等平台部署；</strong></li><li><strong>极简风格 UI，操作直观、性能出色；</strong></li><li><strong>支持 GitHub/Gitee 登录；</strong></li><li><strong>与 Hexo 博客仓库无缝连接，自动提交 PR 实现文章管理。</strong></li></ul><p><strong>这对于想在手机或浏览器上随时写作的朋友来说，非常实用。</strong></p><hr /><blockquote><p>**💡 **<strong>个人建议</strong>：Hexo Pro 更适合桌面端写作和内容管理，Qexo 则提供了一个轻量在线 CMS 管理界面，两者可以结合使用，让你的博客写作体验更上一层楼。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;这篇文章将手把手记录我如何搭建自己的技术博客，涵盖 Hexo 博客初始化、主题美化、内容管理到自动部署的完整流程，希望对也想打造自己博客的你有所帮助。&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;一-hexo-初始化与基础配置&quot;&gt;&lt;a class</summary>
      
    
    
    
    <category term="杂类" scheme="https://zjncs.github.io/categories/%E6%9D%82%E7%B1%BB/"/>
    
    
    <category term="环境配置" scheme="https://zjncs.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    <category term="2508" scheme="https://zjncs.github.io/tags/2508/"/>
    
  </entry>
  
</feed>
